{
  "corpus": "information_retrieval",
  "source": "arxiv",
  "search_query": "cat:cs.IR AND (retrieval OR ranking OR search OR embeddings)",
  "curated_at": "2025-12-26T18:57:29.430757+00:00",
  "total_papers": 200,
  "papers_evaluated": 528,
  "acceptance_rate": 0.3787878787878788,
  "papers": [
    {
      "arxiv_id": "2512.21021v1",
      "title": "Towards Better Search with Domain-Aware Text Embeddings for C2C Marketplaces",
      "authors": [
        {
          "name": "Andre Rusli"
        },
        {
          "name": "Miao Cao"
        },
        {
          "name": "Shoma Ishimoto"
        },
        {
          "name": "Sho Akiyama"
        },
        {
          "name": "Max Frenzel"
        }
      ],
      "abstract": "Consumer-to-consumer (C2C) marketplaces pose distinct retrieval challenges: short, ambiguous queries; noisy, user-generated listings; and strict production constraints. This paper reports our experiment to build a domain-aware Japanese text-embedding approach to improve the quality of search at Mercari, Japan's largest C2C marketplace. We experimented with fine-tuning on purchase-driven query-title pairs, using role-specific prefixes to model query-item asymmetry. To meet production constraints, we apply Matryoshka Representation Learning to obtain compact, truncation-robust embeddings. Offline evaluation on historical search logs shows consistent gains over a strong generic encoder, with particularly large improvements when replacing PCA compression with Matryoshka truncation. A manual assessment further highlights better handling of proper nouns, marketplace-specific semantics, and term-importance alignment. Additionally, an initial online A/B test demonstrates statistically significant improvements in revenue per user and search-flow efficiency, with transaction frequency maintained. Results show that domain-aware embeddings improve relevance and efficiency at scale and form a practical foundation for richer LLM-era search experiences.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.LG"
      ],
      "published": "2025-12-24T07:35:17+00:00",
      "updated": "2025-12-24T07:35:17+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.21021v1",
      "file": "papers/2512.21021v1.pdf"
    },
    {
      "arxiv_id": "2512.20950v1",
      "title": "MultiMind at SemEval-2025 Task 7: Crosslingual Fact-Checked Claim Retrieval via Multi-Source Alignment",
      "authors": [
        {
          "name": "Mohammad Mahdi Abootorabi"
        },
        {
          "name": "Alireza Ghahramani Kure"
        },
        {
          "name": "Mohammadali Mohammadkhani"
        },
        {
          "name": "Sina Elahimanesh"
        },
        {
          "name": "Mohammad Ali Ali Panah"
        }
      ],
      "abstract": "This paper presents our system for SemEval-2025 Task 7: Multilingual and Crosslingual Fact-Checked Claim Retrieval. In an era where misinformation spreads rapidly, effective fact-checking is increasingly critical. We introduce TriAligner, a novel approach that leverages a dual-encoder architecture with contrastive learning and incorporates both native and English translations across different modalities. Our method effectively retrieves claims across multiple languages by learning the relative importance of different sources in alignment. To enhance robustness, we employ efficient data preprocessing and augmentation using large language models while incorporating hard negative sampling to improve representation learning. We evaluate our approach on monolingual and crosslingual benchmarks, demonstrating significant improvements in retrieval accuracy and fact-checking performance over baselines.",
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "published": "2025-12-24T05:14:40+00:00",
      "updated": "2025-12-24T05:14:40+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.20950v1",
      "file": "papers/2512.20950v1.pdf"
    },
    {
      "arxiv_id": "2512.20854v1",
      "title": "How important is Recall for Measuring Retrieval Quality?",
      "authors": [
        {
          "name": "Shelly Schwartz"
        },
        {
          "name": "Oleg Vasilyev"
        },
        {
          "name": "Randy Sawaya"
        }
      ],
      "abstract": "In realistic retrieval settings with large and evolving knowledge bases, the total number of documents relevant to a query is typically unknown, and recall cannot be computed. In this paper, we evaluate several established strategies for handling this limitation by measuring the correlation between retrieval quality metrics and LLM-based judgments of response quality, where responses are generated from the retrieved documents. We conduct experiments across multiple datasets with a relatively low number of relevant documents (2-15). We also introduce a simple retrieval quality measure that performs well without requiring knowledge of the total number of relevant documents.",
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.IR"
      ],
      "published": "2025-12-24T00:16:31+00:00",
      "updated": "2025-12-24T00:16:31+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.20854v1",
      "file": "papers/2512.20854v1.pdf"
    },
    {
      "arxiv_id": "2512.20781v1",
      "title": "Soft Filtering: Guiding Zero-shot Composed Image Retrieval with Prescriptive and Proscriptive Constraints",
      "authors": [
        {
          "name": "Youjin Jung"
        },
        {
          "name": "Seongwoo Cho"
        },
        {
          "name": "Hyun-seok Min"
        },
        {
          "name": "Sungchul Choi"
        }
      ],
      "abstract": "Composed Image Retrieval (CIR) aims to find a target image that aligns with user intent, expressed through a reference image and a modification text. While Zero-shot CIR (ZS-CIR) methods sidestep the need for labeled training data by leveraging pretrained vision-language models, they often rely on a single fused query that merges all descriptive cues of what the user wants, tending to dilute key information and failing to account for what they wish to avoid. Moreover, current CIR benchmarks assume a single correct target per query, overlooking the ambiguity in modification texts. To address these challenges, we propose Soft Filtering with Textual constraints (SoFT), a training-free, plug-and-play filtering module for ZS-CIR. SoFT leverages multimodal large language models (LLMs) to extract two complementary constraints from the reference-modification pair: prescriptive (must-have) and proscriptive (must-avoid) constraints. These serve as semantic filters that reward or penalize candidate images to re-rank results, without modifying the base retrieval model or adding supervision. In addition, we construct a two-stage dataset pipeline that refines CIR benchmarks. We first identify multiple plausible targets per query to construct multi-target triplets, capturing the open-ended nature of user intent. Then guide multimodal LLMs to rewrite the modification text to focus on one target, while referencing contrastive distractors to ensure precision. This enables more comprehensive and reliable evaluation under varying ambiguity levels. Applied on top of CIReVL, a ZS-CIR retriever, SoFT raises R@5 to 65.25 on CIRR (+12.94), mAP@50 to 27.93 on CIRCO (+6.13), and R@50 to 58.44 on FashionIQ (+4.59), demonstrating broad effectiveness.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2025-12-23T21:29:45+00:00",
      "updated": "2025-12-23T21:29:45+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.20781v1",
      "file": "papers/2512.20781v1.pdf"
    },
    {
      "arxiv_id": "2512.20612v1",
      "title": "Making Large Language Models Efficient Dense Retrievers",
      "authors": [
        {
          "name": "Yibin Lei"
        },
        {
          "name": "Shwai He"
        },
        {
          "name": "Ang Li"
        },
        {
          "name": "Andrew Yates"
        }
      ],
      "abstract": "Recent work has shown that directly fine-tuning large language models (LLMs) for dense retrieval yields strong performance, but their substantial parameter counts make them computationally inefficient. While prior studies have revealed significant layer redundancy in LLMs for generative tasks, it remains unclear whether similar redundancy exists when these models are adapted for retrieval tasks, which require encoding entire sequences into fixed representations rather than generating tokens iteratively. To this end, we conduct a comprehensive analysis of layer redundancy in LLM-based dense retrievers. We find that, in contrast to generative settings, MLP layers are substantially more prunable, while attention layers remain critical for semantic aggregation. Building on this insight, we propose EffiR, a framework for developing efficient retrievers that performs large-scale MLP compression through a coarse-to-fine strategy (coarse-grained depth reduction followed by fine-grained width reduction), combined with retrieval-specific fine-tuning. Across diverse BEIR datasets and LLM backbones, EffiR achieves substantial reductions in model size and inference cost while preserving the performance of full-size models.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.CL"
      ],
      "published": "2025-12-23T18:58:25+00:00",
      "updated": "2025-12-23T18:58:25+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.20612v1",
      "file": "papers/2512.20612v1.pdf"
    },
    {
      "arxiv_id": "2512.20174v1",
      "title": "Towards Natural Language-Based Document Image Retrieval: New Dataset and Benchmark",
      "authors": [
        {
          "name": "Hao Guo"
        },
        {
          "name": "Xugong Qin"
        },
        {
          "name": "Jun Jie Ou Yang"
        },
        {
          "name": "Peng Zhang"
        },
        {
          "name": "Gangyan Zeng"
        },
        {
          "name": "Yubo Li"
        },
        {
          "name": "Hailun Lin"
        }
      ],
      "abstract": "Document image retrieval (DIR) aims to retrieve document images from a gallery according to a given query. Existing DIR methods are primarily based on image queries that retrieve documents within the same coarse semantic category, e.g., newspapers or receipts. However, these methods struggle to effectively retrieve document images in real-world scenarios where textual queries with fine-grained semantics are usually provided. To bridge this gap, we introduce a new Natural Language-based Document Image Retrieval (NL-DIR) benchmark with corresponding evaluation metrics. In this work, natural language descriptions serve as semantically rich queries for the DIR task. The NL-DIR dataset contains 41K authentic document images, each paired with five high-quality, fine-grained semantic queries generated and evaluated through large language models in conjunction with manual verification. We perform zero-shot and fine-tuning evaluations of existing mainstream contrastive vision-language models and OCR-free visual document understanding (VDU) models. A two-stage retrieval method is further investigated for performance improvement while achieving both time and space efficiency. We hope the proposed NL-DIR benchmark can bring new opportunities and facilitate research for the VDU community. Datasets and codes will be publicly available at huggingface.co/datasets/nianbing/NL-DIR.",
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.CL",
        "cs.IR"
      ],
      "published": "2025-12-23T09:14:16+00:00",
      "updated": "2025-12-23T09:14:16+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.20174v1",
      "file": "papers/2512.20174v1.pdf"
    },
    {
      "arxiv_id": "2512.19360v1",
      "title": "Generative vector search to improve pathology foundation models across multimodal vision-language tasks",
      "authors": [
        {
          "name": "Markus Ekvall"
        },
        {
          "name": "Ludvig Bergenstråhle"
        },
        {
          "name": "Patrick Truong"
        },
        {
          "name": "Ben Murrell"
        },
        {
          "name": "Joakim Lundeberg"
        }
      ],
      "abstract": "Retrieval-augmented generation improves large language models by grounding outputs in external knowledge sources, reducing hallucinations and addressing knowledge cutoffs. However, standard embedding-based retrieval fails to capture the complexity of multi-concept queries, particularly in domains like biomedicine, where biological data are inherently high-dimensional. For example,omics datasets, and clinical reports simultaneously exhibit numerous molecular, cellular, and physiological features. We present Stochastic Latent Matching (STHLM), a generative vector search method that samples query-conditioned embeddings from text or image inputs to enhance retrieval performance. Analogous to how Chain-of-Thought reasoning enables language models to \"think longer\" on complex problems, STHLM allows retrieval systems to \"search wider\" through iterative sampling. STHLM demonstrates critical improvements over classical vector retrieval across diverse benchmarks, including scientific literature, clinical notes, and tissue images, boosting retrieval performance by 10-30% through test-time compute (trading latency for accuracy), while enabling up to a 10-fold compression of embedding dimensions.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2025-12-22T12:59:23+00:00",
      "updated": "2025-12-22T12:59:23+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.19360v1",
      "file": "papers/2512.19360v1.pdf"
    },
    {
      "arxiv_id": "2512.19134v1",
      "title": "QuCo-RAG: Quantifying Uncertainty from the Pre-training Corpus for Dynamic Retrieval-Augmented Generation",
      "authors": [
        {
          "name": "Dehai Min"
        },
        {
          "name": "Kailin Zhang"
        },
        {
          "name": "Tongtong Wu"
        },
        {
          "name": "Lu Cheng"
        }
      ],
      "abstract": "Dynamic Retrieval-Augmented Generation adaptively determines when to retrieve during generation to mitigate hallucinations in large language models (LLMs). However, existing methods rely on model-internal signals (e.g., logits, entropy), which are fundamentally unreliable because LLMs are typically ill-calibrated and often exhibit high confidence in erroneous outputs. We propose QuCo-RAG, which shifts from subjective confidence to objective statistics computed from pre-training data. Our method quantifies uncertainty through two stages: (1) before generation, we identify low-frequency entities indicating long-tail knowledge gaps; (2) during generation, we verify entity co-occurrence in the pre-training corpus, where zero co-occurrence often signals hallucination risk. Both stages leverage Infini-gram for millisecond-latency queries over 4 trillion tokens, triggering retrieval when uncertainty is high. Experiments on multi-hop QA benchmarks show QuCo-RAG achieves EM gains of 5--12 points over state-of-the-art baselines with OLMo-2 models, and transfers effectively to models with undisclosed pre-training data (Llama, Qwen, GPT), improving EM by up to 14 points. Domain generalization on biomedical QA further validates the robustness of our paradigm. These results establish corpus-grounded verification as a principled, practically model-agnostic paradigm for dynamic RAG. Our code is publicly available at https://github.com/ZhishanQ/QuCo-RAG.",
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.IR"
      ],
      "published": "2025-12-22T08:28:05+00:00",
      "updated": "2025-12-22T08:28:05+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.19134v1",
      "file": "papers/2512.19134v1.pdf"
    },
    {
      "arxiv_id": "2512.18434v1",
      "title": "Efficient Optimization of Hierarchical Identifiers for Generative Recommendation",
      "authors": [
        {
          "name": "Federica Valeau"
        },
        {
          "name": "Odysseas Boufalis"
        },
        {
          "name": "Polytimi Gkotsi"
        },
        {
          "name": "Joshua Rosenthal"
        },
        {
          "name": "David Vos"
        }
      ],
      "abstract": "SEATER is a generative retrieval model that improves recommendation inference efficiency and retrieval quality by utilizing balanced tree-structured item identifiers and contrastive training objectives. We reproduce and validate SEATER's reported improvements in retrieval quality over strong baselines across all datasets from the original work, and extend the evaluation to Yambda, a large-scale music recommendation dataset. Our experiments verify SEATER's strong performance, but show that its tree construction step during training becomes a major bottleneck as the number of items grows. To address this, we implement and evaluate two alternative construction algorithms: a greedy method optimized for minimal build time, and a hybrid method that combines greedy clustering at high levels with more precise grouping at lower levels. The greedy method reduces tree construction time to less than 2% of the original with only a minor drop in quality on the dataset with the largest item collection. The hybrid method achieves retrieval quality on par with the original, and even improves on the largest dataset, while cutting construction time to just 5-8%. All data and code are publicly available for full reproducibility at https://github.com/joshrosie/re-seater.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2025-12-20T17:21:41+00:00",
      "updated": "2025-12-20T17:21:41+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.18434v1",
      "file": "papers/2512.18434v1.pdf"
    },
    {
      "arxiv_id": "2512.18384v1",
      "title": "Datasets for machine learning and for assessing the intelligence level of automatic patent search systems",
      "authors": [
        {
          "name": "Boris Genin"
        },
        {
          "name": "Alexander Gorbunov"
        },
        {
          "name": "Dmitry Zolkin"
        },
        {
          "name": "Igor Nekrasov"
        }
      ],
      "abstract": "The key to success in automating prior art search in patent research using artificial intelligence lies in developing large datasets for machine learning and ensuring their availability. This work is dedicated to providing a comprehensive solution to the problem of creating infrastructure for research in this field, including datasets and tools for calculating search quality criteria. The paper discusses the concept of semantic clusters of patent documents that determine the state of the art in a given subject, as proposed by the authors. A definition of such semantic clusters is also provided. Prior art search is presented as the task of identifying elements within a semantic cluster of patent documents in the subject area specified by the document under consideration. A generator of user-configurable datasets for machine learning, based on collections of U.S. and Russian patent documents, is described. The dataset generator creates a database of links to documents in semantic clusters. Then, based on user-defined parameters, it forms a dataset of semantic clusters in JSON format for machine learning. To evaluate machine learning outcomes, it is proposed to calculate search quality scores that account for semantic clusters of the documents being searched. To automate the evaluation process, the paper describes a utility developed by the authors for assessing the quality of prior art document search.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "published": "2025-12-20T14:51:57+00:00",
      "updated": "2025-12-20T14:51:57+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.18384v1",
      "file": "papers/2512.18384v1.pdf"
    },
    {
      "arxiv_id": "2512.18117v1",
      "title": "Factorized Transport Alignment for Multimodal and Multiview E-commerce Representation Learning",
      "authors": [
        {
          "name": "Xiwen Chen"
        },
        {
          "name": "Yen-Chieh Lien"
        },
        {
          "name": "Susan Liu"
        },
        {
          "name": "María Castaños"
        },
        {
          "name": "Abolfazl Razi"
        },
        {
          "name": "Xiaoting Zhao"
        },
        {
          "name": "Congzhe Su"
        }
      ],
      "abstract": "The rapid growth of e-commerce requires robust multimodal representations that capture diverse signals from user-generated listings. Existing vision-language models (VLMs) typically align titles with primary images, i.e., single-view, but overlook non-primary images and auxiliary textual views that provide critical semantics in open marketplaces such as Etsy or Poshmark. To this end, we propose a framework that unifies multimodal and multi-view learning through Factorized Transport, a lightweight approximation of optimal transport, designed for scalability and deployment efficiency. During training, the method emphasizes primary views while stochastically sampling auxiliary ones, reducing training cost from quadratic in the number of views to constant per item. At inference, all views are fused into a single cached embedding, preserving the efficiency of two-tower retrieval with no additional online overhead. On an industrial dataset of 1M product listings and 0.3M interactions, our approach delivers consistent improvements in cross-view and query-to-item retrieval, achieving up to +7.9% Recall@500 over strong multimodal baselines. Overall, our framework bridges scalability with optimal transport-based learning, making multi-view pretraining practical for large-scale e-commerce search.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2025-12-19T22:50:49+00:00",
      "updated": "2025-12-19T22:50:49+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.18117v1",
      "file": "papers/2512.18117v1.pdf"
    },
    {
      "arxiv_id": "2512.17164v1",
      "title": "TCDE: Topic-Centric Dual Expansion of Queries and Documents with Large Language Models for Information Retrieval",
      "authors": [
        {
          "name": "Yu Yang"
        },
        {
          "name": "Feng Tian"
        },
        {
          "name": "Ping Chen"
        }
      ],
      "abstract": "Query Expansion (QE) enriches queries and Document Expansion (DE) enriches documents, and these two techniques are often applied separately. However, such separate application may lead to semantic misalignment between the expanded queries (or documents) and their relevant documents (or queries). To address this serious issue, we propose TCDE, a dual expansion strategy that leverages large language models (LLMs) for topic-centric enrichment on both queries and documents. In TCDE, we design two distinct prompt templates for processing each query and document. On the query side, an LLM is guided to identify distinct sub-topics within each query and generate a focused pseudo-document for each sub-topic. On the document side, an LLM is guided to distill each document into a set of core topic sentences. The resulting outputs are used to expand the original query and document. This topic-centric dual expansion process establishes semantic bridges between queries and their relevant documents, enabling better alignment for downstream retrieval models. Experiments on two challenging benchmarks, TREC Deep Learning and BEIR, demonstrate that TCDE achieves substantial improvements over strong state-of-the-art expansion baselines. In particular, on dense retrieval tasks, it outperforms several state-of-the-art methods, with a relative improvement of 2.8\\% in NDCG@10 on the SciFact dataset. Experimental results validate the effectiveness of our topic-centric and dual expansion strategy.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2025-12-19T01:57:17+00:00",
      "updated": "2025-12-19T01:57:17+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.17164v1",
      "file": "papers/2512.17164v1.pdf"
    },
    {
      "arxiv_id": "2512.17027v1",
      "title": "Unexpected Knowledge: Auditing Wikipedia and Grokipedia Search Recommendations",
      "authors": [
        {
          "name": "Erica Coppolillo"
        },
        {
          "name": "Simone Mungari"
        }
      ],
      "abstract": "Encyclopedic knowledge platforms are key gateways through which users explore information online. The recent release of Grokipedia, a fully AI-generated encyclopedia, introduces a new alternative to traditional, well-established platforms like Wikipedia. In this context, search engine mechanisms play an important role in guiding users exploratory paths, yet their behavior across different encyclopedic systems remains underexplored. In this work, we address this gap by providing the first comparative analysis of search engine in Wikipedia and Grokipedia.\n  Using nearly 10,000 neutral English words and their substrings as queries, we collect over 70,000 search engine results and examine their semantic alignment, overlap, and topical structure. We find that both platforms frequently generate results that are weakly related to the original query and, in many cases, surface unexpected content starting from innocuous queries. Despite these shared properties, the two systems often produce substantially different recommendation sets for the same query. Through topical annotation and trajectory analysis, we further identify systematic differences in how content categories are surfaced and how search engine results evolve over multiple stages of exploration.\n  Overall, our findings show that unexpected search engine outcomes are a common feature of both the platforms, even though they exhibit discrepancies in terms of topical distribution and query suggestions.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "published": "2025-12-18T19:41:58+00:00",
      "updated": "2025-12-18T19:41:58+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.17027v1",
      "file": "papers/2512.17027v1.pdf"
    },
    {
      "arxiv_id": "2512.16661v2",
      "title": "Microsoft Academic Graph Information Retrieval for Research Recommendation and Assistance",
      "authors": [
        {
          "name": "Shikshya Shiwakoti"
        },
        {
          "name": "Samuel Goldsmith"
        },
        {
          "name": "Ujjwal Pandit"
        }
      ],
      "abstract": "In today's information-driven world, access to scientific publications has become increasingly easy. At the same time, filtering through the massive volume of available research has become more challenging than ever. Graph Neural Networks (GNNs) and graph attention mechanisms have shown strong effectiveness in searching large-scale information databases, particularly when combined with modern large language models. In this paper, we propose an Attention-Based Subgraph Retriever, a GNN-as-retriever model that applies attention-based pruning to extract a refined subgraph, which is then passed to a large language model for advanced knowledge reasoning.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "published": "2025-12-18T15:29:18+00:00",
      "updated": "2025-12-21T15:17:01+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.16661v2",
      "file": "papers/2512.16661v2.pdf"
    },
    {
      "arxiv_id": "2512.16425v1",
      "title": "Introducing ORKG ASK: an AI-driven Scholarly Literature Search and Exploration System Taking a Neuro-Symbolic Approach",
      "authors": [
        {
          "name": "Allard Oelen"
        },
        {
          "name": "Mohamad Yaser Jaradeh"
        },
        {
          "name": "Sören Auer"
        }
      ],
      "abstract": "As the volume of published scholarly literature continues to grow, finding relevant literature becomes increasingly difficult. With the rise of generative Artificial Intelligence (AI), and particularly Large Language Models (LLMs), new possibilities emerge to find and explore literature. We introduce ASK (Assistant for Scientific Knowledge), an AI-driven scholarly literature search and exploration system that follows a neuro-symbolic approach. ASK aims to provide active support to researchers in finding relevant scholarly literature by leveraging vector search, LLMs, and knowledge graphs. The system allows users to input research questions in natural language and retrieve relevant articles. ASK automatically extracts key information and generates answers to research questions using a Retrieval-Augmented Generation (RAG) approach. We present an evaluation of ASK, assessing the system's usability and usefulness. Findings indicate that the system is user-friendly and users are generally satisfied while using the system.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "published": "2025-12-18T11:25:14+00:00",
      "updated": "2025-12-18T11:25:14+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.16425v1",
      "file": "papers/2512.16425v1.pdf"
    },
    {
      "arxiv_id": "2512.16236v1",
      "title": "The Evolution of Reranking Models in Information Retrieval: From Heuristic Methods to Large Language Models",
      "authors": [
        {
          "name": "Tejul Pandit"
        },
        {
          "name": "Sakshi Mahendru"
        },
        {
          "name": "Meet Raval"
        },
        {
          "name": "Dhvani Upadhyay"
        }
      ],
      "abstract": "Reranking is a critical stage in contemporary information retrieval (IR) systems, improving the relevance of the user-presented final results by honing initial candidate sets. This paper is a thorough guide to examine the changing reranker landscape and offer a clear view of the advancements made in reranking methods. We present a comprehensive survey of reranking models employed in IR, particularly within modern Retrieval Augmented Generation (RAG) pipelines, where retrieved documents notably influence output quality.\n  We embark on a chronological journey through the historical trajectory of reranking techniques, starting with foundational approaches, before exploring the wide range of sophisticated neural network architectures such as cross-encoders, sequence-generation models like T5, and Graph Neural Networks (GNNs) utilized for structural information. Recognizing the computational cost of advancing neural rerankers, we analyze techniques for enhancing efficiency, notably knowledge distillation for creating competitive, lighter alternatives. Furthermore, we map the emerging territory of integrating Large Language Models (LLMs) in reranking, examining novel prompting strategies and fine-tuning tactics. This survey seeks to elucidate the fundamental ideas, relative effectiveness, computational features, and real-world trade-offs of various reranking strategies. The survey provides a structured synthesis of the diverse reranking paradigms, highlighting their underlying principles and comparative strengths and weaknesses.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "published": "2025-12-18T06:29:37+00:00",
      "updated": "2025-12-18T06:29:37+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.16236v1",
      "file": "papers/2512.16236v1.pdf"
    },
    {
      "arxiv_id": "2512.15372v1",
      "title": "Image Complexity-Aware Adaptive Retrieval for Efficient Vision-Language Models",
      "authors": [
        {
          "name": "Mikel Williams-Lekuona"
        },
        {
          "name": "Georgina Cosma"
        }
      ],
      "abstract": "Vision transformers in vision-language models apply uniform computational effort across all images, expending 175.33 GFLOPs (ViT-L/14) whether analysing a straightforward product photograph or a complex street scene. We propose ICAR (Image Complexity-Aware Retrieval), which enables vision transformers to use less compute for simple images whilst processing complex images through their full network depth. The key challenge is maintaining cross-modal alignment: embeddings from different processing depths must remain compatible for text matching. ICAR solves this through dual-path training that produces compatible embeddings from both reduced-compute and full-compute processing. This maintains compatibility between image representations and text embeddings in the same semantic space, whether an image exits early or processes fully. Unlike existing two-stage approaches that require expensive reranking, ICAR enables direct image-text matching without additional overhead. To determine how much compute to use, we develop ConvNeXt-IC, which treats image complexity assessment as a classification task. By applying modern classifier backbones rather than specialised architectures, ConvNeXt-IC achieves state-of-the-art performance with 0.959 correlation with human judgement (Pearson) and 4.4x speedup. Evaluated on standard benchmarks augmented with real-world web data, ICAR achieves 20% practical speedup while maintaining category-level performance and 95% of instance-level performance, enabling sustainable scaling of vision-language systems.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.MM"
      ],
      "published": "2025-12-17T12:19:54+00:00",
      "updated": "2025-12-17T12:19:54+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.15372v1",
      "file": "papers/2512.15372v1.pdf"
    },
    {
      "arxiv_id": "2512.15365v1",
      "title": "ArcBERT: An LLM-based Search Engine for Exploring Integrated Multi-Omics Metadata",
      "authors": [
        {
          "name": "Gajendra Doniparthi"
        },
        {
          "name": "Shashank Balu Pandhare"
        },
        {
          "name": "Stefan Deßloch"
        },
        {
          "name": "Timo Mühlhaus"
        }
      ],
      "abstract": "Traditional search applications within Research Data Management (RDM) ecosystems are crucial in helping users discover and explore the structured metadata from the research datasets. Typically, text search engines require users to submit keyword-based queries rather than using natural language. However, using Large Language Models (LLMs) trained on domain-specific content for specialized natural language processing (NLP) tasks is becoming increasingly common. We present ArcBERT, an LLM-based system designed for integrated metadata exploration. ArcBERT understands natural language queries and relies on semantic matching, unlike traditional search applications. Notably, ArcBERT also understands the structure and hierarchies within the metadata, enabling it to handle diverse user querying patterns effectively.",
      "primary_category": "cs.DB",
      "categories": [
        "cs.DB",
        "cs.IR"
      ],
      "published": "2025-12-17T12:11:14+00:00",
      "updated": "2025-12-17T12:11:14+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.15365v1",
      "file": "papers/2512.15365v1.pdf"
    },
    {
      "arxiv_id": "2512.14313v1",
      "title": "Dynamic Context Selection for Retrieval-Augmented Generation: Mitigating Distractors and Positional Bias",
      "authors": [
        {
          "name": "Malika Iratni"
        },
        {
          "name": "Mohand Boughanem"
        },
        {
          "name": "Taoufiq Dkaki"
        }
      ],
      "abstract": "Retrieval Augmented Generation (RAG) enhances language model performance by incorporating external knowledge retrieved from large corpora, which makes it highly suitable for tasks such as open domain question answering. Standard RAG systems typically rely on a fixed top k retrieval strategy, which can either miss relevant information or introduce semantically irrelevant passages, known as distractors, that degrade output quality. Additionally, the positioning of retrieved passages within the input context can influence the model attention and generation outcomes. Context placed in the middle tends to be overlooked, which is an issue known as the \"lost in the middle\" phenomenon. In this work, we systematically analyze the impact of distractors on generation quality, and quantify their effects under varying conditions. We also investigate how the position of relevant passages within the context window affects their influence on generation. Building on these insights, we propose a context-size classifier that dynamically predicts the optimal number of documents to retrieve based on query-specific informational needs. We integrate this approach into a full RAG pipeline, and demonstrate improved performance over fixed k baselines.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2025-12-16T11:30:40+00:00",
      "updated": "2025-12-16T11:30:40+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.14313v1",
      "file": "papers/2512.14313v1.pdf"
    },
    {
      "arxiv_id": "2512.14102v1",
      "title": "Neurosymbolic Inference On Foundation Models For Remote Sensing Text-to-image Retrieval With Complex Queries",
      "authors": [
        {
          "name": "Emanuele Mezzi"
        },
        {
          "name": "Gertjan Burghouts"
        },
        {
          "name": "Maarten Kruithof"
        }
      ],
      "abstract": "Text-to-image retrieval in remote sensing (RS) has advanced rapidly with the rise of large vision-language models (LVLMs) tailored for aerial and satellite imagery, culminating in remote sensing large vision-language models (RS-LVLMS). However, limited explainability and poor handling of complex spatial relations remain key challenges for real-world use. To address these issues, we introduce RUNE (Reasoning Using Neurosymbolic Entities), an approach that combines Large Language Models (LLMs) with neurosymbolic AI to retrieve images by reasoning over the compatibility between detected entities and First-Order Logic (FOL) expressions derived from text queries. Unlike RS-LVLMs that rely on implicit joint embeddings, RUNE performs explicit reasoning, enhancing performance and interpretability. For scalability, we propose a logic decomposition strategy that operates on conditioned subsets of detected entities, guaranteeing shorter execution time compared to neural approaches. Rather than using foundation models for end-to-end retrieval, we leverage them only to generate FOL expressions, delegating reasoning to a neurosymbolic inference module. For evaluation we repurpose the DOTA dataset, originally designed for object detection, by augmenting it with more complex queries than in existing benchmarks. We show the LLM's effectiveness in text-to-logic translation and compare RUNE with state-of-the-art RS-LVLMs, demonstrating superior performance. We introduce two metrics, Retrieval Robustness to Query Complexity (RRQC) and Retrieval Robustness to Image Uncertainty (RRIU), which evaluate performance relative to query complexity and image uncertainty. RUNE outperforms joint-embedding models in complex RS retrieval tasks, offering gains in performance, robustness, and explainability. We show RUNE's potential for real-world RS applications through a use case on post-flood satellite image retrieval.",
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.IR"
      ],
      "published": "2025-12-16T05:33:44+00:00",
      "updated": "2025-12-16T05:33:44+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.14102v1",
      "file": "papers/2512.14102v1.pdf"
    },
    {
      "arxiv_id": "2512.13511v1",
      "title": "TARA: Simple and Efficient Time Aware Retrieval Adaptation of MLLMs for Video Understanding",
      "authors": [
        {
          "name": "Piyush Bagad"
        },
        {
          "name": "Andrew Zisserman"
        }
      ],
      "abstract": "Our objective is to build a general time-aware video-text embedding model for retrieval. To that end, we propose a simple and efficient recipe, dubbed TARA (Time Aware Retrieval Adaptation), to adapt Multimodal LLMs (MLLMs) to a time-aware video-text embedding model without using any video data at all. For evaluating time-awareness in retrieval, we propose a new benchmark with temporally opposite (chiral) actions as hard negatives and curated splits for chiral and non-chiral actions. We show that TARA outperforms all existing video-text models on this chiral benchmark while also achieving strong results on standard benchmarks. Furthermore, we discover additional benefits of TARA beyond time-awareness: (i) TARA embeddings are negation-aware as shown in NegBench benchmark that evaluates negation in video retrieval, (ii) TARA achieves state of the art performance on verb and adverb understanding in videos. Overall, TARA yields a strong, versatile, time-aware video-text embedding model with state of the art zero-shot performance.",
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.IR"
      ],
      "published": "2025-12-15T16:38:59+00:00",
      "updated": "2025-12-15T16:38:59+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.13511v1",
      "file": "papers/2512.13511v1.pdf"
    },
    {
      "arxiv_id": "2512.13237v1",
      "title": "Learning to Retrieve with Weakened Labels: Robust Training under Label Noise",
      "authors": [
        {
          "name": "Arnab Sharma"
        }
      ],
      "abstract": "Neural Encoders are frequently used in the NLP domain to perform dense retrieval tasks, for instance, to generate the candidate documents for a given query in question-answering tasks. However, sparse annotation and label noise in the training data make it challenging to train or fine-tune such retrieval models. Although existing works have attempted to mitigate these problems by incorporating modified loss functions or data cleaning, these approaches either require some hyperparameters to tune during training or add substantial complexity to the training setup. In this work, we consider a label weakening approach to generate robust retrieval models in the presence of label noise. Instead of enforcing a single, potentially erroneous label for each query document pair, we allow for a set of plausible labels derived from both the observed supervision and the model's confidence scores. We perform an extensive evaluation considering two retrieval models, one re-ranking model, considering four diverse ranking datasets. To this end, we also consider a realistic noisy setting by using a semantic-aware noise generation technique to generate different ratios of noise. Our initial results show that label weakening can improve the performance of the retrieval tasks in comparison to 10 different state-of-the-art loss functions.",
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.IR"
      ],
      "published": "2025-12-15T11:52:13+00:00",
      "updated": "2025-12-15T11:52:13+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.13237v1",
      "file": "papers/2512.13237v1.pdf"
    },
    {
      "arxiv_id": "2512.13074v1",
      "title": "A Simple and Effective Framework for Symmetric Consistent Indexing in Large-Scale Dense Retrieval",
      "authors": [
        {
          "name": "Huimu Wang"
        },
        {
          "name": "Yiming Qiu"
        },
        {
          "name": "Xingzhi Yao"
        },
        {
          "name": "Zhiguo Chen"
        },
        {
          "name": "Guoyu Tang"
        },
        {
          "name": "Songlin Wang"
        },
        {
          "name": "Sulong Xu"
        },
        {
          "name": "Mingming Li"
        }
      ],
      "abstract": "Dense retrieval has become the industry standard in large-scale information retrieval systems due to its high efficiency and competitive accuracy. Its core relies on a coarse-to-fine hierarchical architecture that enables rapid candidate selection and precise semantic matching, achieving millisecond-level response over billion-scale corpora. This capability makes it essential not only in traditional search and recommendation scenarios but also in the emerging paradigm of generative recommendation driven by large language models, where semantic IDs-themselves a form of coarse-to-fine representation-play a foundational role. However, the widely adopted dual-tower encoding architecture introduces inherent challenges, primarily representational space misalignment and retrieval index inconsistency, which degrade matching accuracy, retrieval stability, and performance on long-tail queries. These issues are further magnified in semantic ID generation, ultimately limiting the performance ceiling of downstream generative models.\n  To address these challenges, this paper proposes a simple and effective framework named SCI comprising two synergistic modules: a symmetric representation alignment module that employs an innovative input-swapping mechanism to unify the dual-tower representation space without adding parameters, and an consistent indexing with dual-tower synergy module that redesigns retrieval paths using a dual-view indexing strategy to maintain consistency from training to inference. The framework is systematic, lightweight, and engineering-friendly, requiring minimal overhead while fully supporting billion-scale deployment. We provide theoretical guarantees for our approach, with its effectiveness validated by results across public datasets and real-world e-commerce datasets.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "published": "2025-12-15T08:11:24+00:00",
      "updated": "2025-12-15T08:11:24+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.13074v1",
      "file": "papers/2512.13074v1.pdf"
    },
    {
      "arxiv_id": "2512.13037v1",
      "title": "Progressive Refinement of E-commerce Search Ranking Based on Short-Term Activities of the Buyer",
      "authors": [
        {
          "name": "Taoran Sheng"
        },
        {
          "name": "Sathappan Muthiah"
        },
        {
          "name": "Atiq Islam"
        },
        {
          "name": "Jinming Feng"
        }
      ],
      "abstract": "In e-commerce shopping, aligning search results with a buyer's immediate needs and preferences presents a significant challenge, particularly in adapting search results throughout the buyer's shopping journey as they move from the initial stages of browsing to making a purchase decision or shift from one intent to another. This study presents a systematic approach to adapting e-commerce search results based on the current context. We start with basic methods and incrementally incorporate more contextual information and state-of-the-art techniques to improve the search outcomes. By applying this evolving contextual framework to items displayed on the search engine results page (SERP), we progressively align search outcomes more closely with the buyer's interests and current search intentions. Our findings demonstrate that this incremental enhancement, from simple heuristic autoregressive features to advanced sequence models, significantly improves ranker performance. The integration of contextual techniques enhances the performance of our production ranker, leading to improved search results in both offline and online A/B testing in terms of Mean Reciprocal Rank (MRR). Overall, the paper details iterative methodologies and their substantial contributions to search result contextualization on e-commerce platforms.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.LG"
      ],
      "published": "2025-12-15T07:07:32+00:00",
      "updated": "2025-12-15T07:07:32+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.13037v1",
      "file": "papers/2512.13037v1.pdf"
    },
    {
      "arxiv_id": "2512.12980v1",
      "title": "Reveal Hidden Pitfalls and Navigate Next Generation of Vector Similarity Search from Task-Centric Views",
      "authors": [
        {
          "name": "Tingyang Chen"
        },
        {
          "name": "Cong Fu"
        },
        {
          "name": "Jiahua Wu"
        },
        {
          "name": "Haotian Wu"
        },
        {
          "name": "Hua Fan"
        },
        {
          "name": "Xiangyu Ke"
        },
        {
          "name": "Yunjun Gao"
        },
        {
          "name": "Yabo Ni"
        },
        {
          "name": "Anxiang Zeng"
        }
      ],
      "abstract": "Vector Similarity Search (VSS) in high-dimensional spaces is rapidly emerging as core functionality in next-generation database systems for numerous data-intensive services -- from embedding lookups in large language models (LLMs), to semantic information retrieval and recommendation engines. Current benchmarks, however, evaluate VSS primarily on the recall-latency trade-off against a ground truth defined solely by distance metrics, neglecting how retrieval quality ultimately impacts downstream tasks. This disconnect can mislead both academic research and industrial practice.\n  We present Iceberg, a holistic benchmark suite for end-to-end evaluation of VSS methods in realistic application contexts. From a task-centric view, Iceberg uncovers the Information Loss Funnel, which identifies three principal sources of end-to-end performance degradation: (1) Embedding Loss during feature extraction; (2) Metric Misuse, where distances poorly reflect task relevance; (3) Data Distribution Sensitivity, highlighting index robustness across skews and modalities. For a more comprehensive assessment, Iceberg spans eight diverse datasets across key domains such as image classification, face recognition, text retrieval, and recommendation systems. Each dataset, ranging from 1M to 100M vectors, includes rich, task-specific labels and evaluation metrics, enabling assessment of retrieval algorithms within the full application pipeline rather than in isolation. Iceberg benchmarks 13 state-of-the-art VSS methods and re-ranks them based on application-level metrics, revealing substantial deviations from traditional rankings derived purely from recall-latency evaluations. Building on these insights, we define a set of task-centric meta-features and derive an interpretable decision tree to guide practitioners in selecting and tuning VSS methods for their specific workloads.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.DB"
      ],
      "published": "2025-12-15T04:49:33+00:00",
      "updated": "2025-12-15T04:49:33+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.12980v1",
      "file": "papers/2512.12980v1.pdf"
    },
    {
      "arxiv_id": "2512.12938v1",
      "title": "SPAR: Session-based Pipeline for Adaptive Retrieval on Legacy File Systems",
      "authors": [
        {
          "name": "Duy A. Nguyen"
        },
        {
          "name": "Hai H. Do"
        },
        {
          "name": "Minh Doan"
        },
        {
          "name": "Minh N. Do"
        }
      ],
      "abstract": "The ability to extract value from historical data is essential for enterprise decision-making. However, much of this information remains inaccessible within large legacy file systems that lack structured organization and semantic indexing, making retrieval and analysis inefficient and error-prone. We introduce SPAR (Session-based Pipeline for Adaptive Retrieval), a conceptual framework that integrates Large Language Models (LLMs) into a Retrieval-Augmented Generation (RAG) architecture specifically designed for legacy enterprise environments. Unlike conventional RAG pipelines, which require costly construction and maintenance of full-scale vector databases that mirror the entire file system, SPAR employs a lightweight two-stage process: a semantic Metadata Index is first created, after which session-specific vector databases are dynamically generated on demand. This design reduces computational overhead while improving transparency, controllability, and relevance in retrieval. We provide a theoretical complexity analysis comparing SPAR with standard LLM-based RAG pipelines, demonstrating its computational advantages. To validate the framework, we apply SPAR to a synthesized enterprise-scale file system containing a large corpus of biomedical literature, showing improvements in both retrieval effectiveness and downstream model accuracy. Finally, we discuss design trade-offs and outline open challenges for deploying SPAR across diverse enterprise settings.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2025-12-15T02:54:10+00:00",
      "updated": "2025-12-15T02:54:10+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.12938v1",
      "file": "papers/2512.12938v1.pdf"
    },
    {
      "arxiv_id": "2512.12935v1",
      "title": "Unified Interactive Multimodal Moment Retrieval via Cascaded Embedding-Reranking and Temporal-Aware Score Fusion",
      "authors": [
        {
          "name": "Toan Le Ngo Thanh"
        },
        {
          "name": "Phat Ha Huu"
        },
        {
          "name": "Tan Nguyen Dang Duy"
        },
        {
          "name": "Thong Nguyen Le Minh"
        },
        {
          "name": "Anh Nguyen Nhu Tinh"
        }
      ],
      "abstract": "The exponential growth of video content has created an urgent need for efficient multimodal moment retrieval systems. However, existing approaches face three critical challenges: (1) fixed-weight fusion strategies fail across cross modal noise and ambiguous queries, (2) temporal modeling struggles to capture coherent event sequences while penalizing unrealistic gaps, and (3) systems require manual modality selection, reducing usability. We propose a unified multimodal moment retrieval system with three key innovations. First, a cascaded dual-embedding pipeline combines BEIT-3 and SigLIP for broad retrieval, refined by BLIP-2 based reranking to balance recall and precision. Second, a temporal-aware scoring mechanism applies exponential decay penalties to large temporal gaps via beam search, constructing coherent event sequences rather than isolated frames. Third, Agent-guided query decomposition (GPT-4o) automatically interprets ambiguous queries, decomposes them into modality specific sub-queries (visual/OCR/ASR), and performs adaptive score fusion eliminating manual modality selection. Qualitative analysis demonstrates that our system effectively handles ambiguous queries, retrieves temporally coherent sequences, and dynamically adapts fusion strategies, advancing interactive moment search capabilities.",
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.IR"
      ],
      "published": "2025-12-15T02:50:43+00:00",
      "updated": "2025-12-15T02:50:43+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.12935v1",
      "file": "papers/2512.12935v1.pdf"
    },
    {
      "arxiv_id": "2512.12760v1",
      "title": "Intelligent Scientific Literature Explorer using Machine Learning (ISLE)",
      "authors": [
        {
          "name": "Sina Jani"
        },
        {
          "name": "Arman Heidari"
        },
        {
          "name": "Amirmohammad Anvari"
        },
        {
          "name": "Zahra Rahimi"
        }
      ],
      "abstract": "The rapid acceleration of scientific publishing has created substantial challenges for researchers attempting to discover, contextualize, and interpret relevant literature. Traditional keyword-based search systems provide limited semantic understanding, while existing AI-driven tools typically focus on isolated tasks such as retrieval, clustering, or bibliometric visualization. This paper presents an integrated system for scientific literature exploration that combines large-scale data acquisition, hybrid retrieval, semantic topic modeling, and heterogeneous knowledge graph construction. The system builds a comprehensive corpus by merging full-text data from arXiv with structured metadata from OpenAlex. A hybrid retrieval architecture fuses BM25 lexical search with embedding-based semantic search using Reciprocal Rank Fusion. Topic modeling is performed on retrieved results using BERTopic or non-negative matrix factorization depending on computational resources. A knowledge graph unifies papers, authors, institutions, countries, and extracted topics into an interpretable structure. The system provides a multi-layered exploration environment that reveals not only relevant publications but also the conceptual and relational landscape surrounding a query. Evaluation across multiple queries demonstrates improvements in retrieval relevance, topic coherence, and interpretability. The proposed framework contributes an extensible foundation for AI-assisted scientific discovery.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "published": "2025-12-14T16:54:24+00:00",
      "updated": "2025-12-14T16:54:24+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.12760v1",
      "file": "papers/2512.12760v1.pdf"
    },
    {
      "arxiv_id": "2512.12610v1",
      "title": "Patch-wise Retrieval: A Bag of Practical Techniques for Instance-level Matching",
      "authors": [
        {
          "name": "Wonseok Choi"
        },
        {
          "name": "Sohwi Lim"
        },
        {
          "name": "Nam Hyeon-Woo"
        },
        {
          "name": "Moon Ye-Bin"
        },
        {
          "name": "Dong-Ju Jeong"
        },
        {
          "name": "Jinyoung Hwang"
        },
        {
          "name": "Tae-Hyun Oh"
        }
      ],
      "abstract": "Instance-level image retrieval aims to find images containing the same object as a given query, despite variations in size, position, or appearance. To address this challenging task, we propose Patchify, a simple yet effective patch-wise retrieval framework that offers high performance, scalability, and interpretability without requiring fine-tuning. Patchify divides each database image into a small number of structured patches and performs retrieval by comparing these local features with a global query descriptor, enabling accurate and spatially grounded matching. To assess not just retrieval accuracy but also spatial correctness, we introduce LocScore, a localization-aware metric that quantifies whether the retrieved region aligns with the target object. This makes LocScore a valuable diagnostic tool for understanding and improving retrieval behavior. We conduct extensive experiments across multiple benchmarks, backbones, and region selection strategies, showing that Patchify outperforms global methods and complements state-of-the-art reranking pipelines. Furthermore, we apply Product Quantization for efficient large-scale retrieval and highlight the importance of using informative features during compression, which significantly boosts performance. Project website: https://wons20k.github.io/PatchwiseRetrieval/",
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.IR"
      ],
      "published": "2025-12-14T09:24:51+00:00",
      "updated": "2025-12-14T09:24:51+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.12610v1",
      "file": "papers/2512.12610v1.pdf"
    },
    {
      "arxiv_id": "2512.12458v1",
      "title": "Breaking the Curse of Dimensionality: On the Stability of Modern Vector Retrieval",
      "authors": [
        {
          "name": "Vihan Lakshman"
        },
        {
          "name": "Blaise Munyampirwa"
        },
        {
          "name": "Julian Shun"
        },
        {
          "name": "Benjamin Coleman"
        }
      ],
      "abstract": "Modern vector databases enable efficient retrieval over high-dimensional neural embeddings, powering applications from web search to retrieval-augmented generation. However, classical theory predicts such tasks should suffer from the curse of dimensionality, where distances between points become nearly indistinguishable, thereby crippling efficient nearest-neighbor search. We revisit this paradox through the lens of stability, the property that small perturbations to a query do not radically alter its nearest neighbors. Building on foundational results, we extend stability theory to three key retrieval settings widely used in practice: (i) multi-vector search, where we prove that the popular Chamfer distance metric preserves single-vector stability, while average pooling aggregation may destroy it; (ii) filtered vector search, where we show that sufficiently large penalties for mismatched filters can induce stability even when the underlying search is unstable; and (iii) sparse vector search, where we formalize and prove novel sufficient stability conditions. Across synthetic and real datasets, our experimental results match our theoretical predictions, offering concrete guidance for model and system design to avoid the curse of dimensionality.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.CG",
        "cs.DB",
        "cs.LG"
      ],
      "published": "2025-12-13T21:05:21+00:00",
      "updated": "2025-12-13T21:05:21+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.12458v1",
      "file": "papers/2512.12458v1.pdf"
    },
    {
      "arxiv_id": "2512.11490v1",
      "title": "VLM2GeoVec: Toward Universal Multimodal Embeddings for Remote Sensing",
      "authors": [
        {
          "name": "Emanuel Sánchez Aimar"
        },
        {
          "name": "Gulnaz Zhambulova"
        },
        {
          "name": "Fahad Shahbaz Khan"
        },
        {
          "name": "Yonghao Xu"
        },
        {
          "name": "Michael Felsberg"
        }
      ],
      "abstract": "Satellite imagery differs fundamentally from natural images: its aerial viewpoint, very high resolution, diverse scale variations, and abundance of small objects demand both region-level spatial reasoning and holistic scene understanding. Current remote-sensing approaches remain fragmented between dual-encoder retrieval models, which excel at large-scale cross-modal search but cannot interleave modalities, and generative assistants, which support region-level interpretation but lack scalable retrieval capabilities. We propose $\\textbf{VLM2GeoVec}$, an instruction-following, single-encoder vision-language model trained contrastively to embed interleaved inputs (images, text, bounding boxes, and geographic coordinates) in a unified vector space. Our single encoder interleaves all inputs into one joint embedding trained with a contrastive loss, eliminating multi-stage pipelines and task-specific modules. To evaluate its versatility, we introduce $\\textbf{RSMEB}$, a novel benchmark covering key remote-sensing embedding applications: scene classification; cross-modal search; compositional retrieval; visual-question answering; visual grounding and region-level reasoning; and semantic geospatial retrieval. On RSMEB, it achieves $\\textbf{26.6%}$ P@1 on region-caption retrieval (+25 pp vs. dual-encoder baselines), $\\textbf{32.5%}$ P@1 on referring-expression retrieval (+19 pp), and $\\textbf{17.8%}$ P@1 on semantic geo-localization retrieval (over $3\\times$ prior best), while matching or exceeding specialized baselines on conventional tasks such as scene classification and cross-modal retrieval. VLM2GeoVec unifies scalable retrieval with region-level spatial reasoning, enabling cohesive multimodal analysis in remote sensing. We will publicly release the code, checkpoints, and data upon acceptance.",
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.IR"
      ],
      "published": "2025-12-12T11:39:35+00:00",
      "updated": "2025-12-12T11:39:35+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.11490v1",
      "file": "papers/2512.11490v1.pdf"
    },
    {
      "arxiv_id": "2512.19703v1",
      "title": "ASK: Adaptive Self-improving Knowledge Framework for Audio Text Retrieval",
      "authors": [
        {
          "name": "Siyuan Fu"
        },
        {
          "name": "Xuchen Guo"
        },
        {
          "name": "Mingjun Liu"
        },
        {
          "name": "Hongxiang Li"
        },
        {
          "name": "Boyin Tan"
        },
        {
          "name": "Gongxi Zhu"
        },
        {
          "name": "Xianwei Zhuang"
        },
        {
          "name": "Jinghan Ru"
        },
        {
          "name": "Yuxin Xie"
        },
        {
          "name": "Yuguo Yin"
        }
      ],
      "abstract": "The dominant paradigm for Audio-Text Retrieval (ATR) relies on mini-batch-based contrastive learning. This process, however, is inherently limited by what we formalize as the Gradient Locality Bottleneck (GLB), which structurally prevents models from leveraging out-of-batch knowledge and thus impairs fine-grained and long-tail learning. While external knowledge-enhanced methods can alleviate the GLB, we identify a critical, unaddressed side effect: the Representation-Drift Mismatch (RDM), where a static knowledge base becomes progressively misaligned with the evolving model, turning guidance into noise. To address this dual challenge, we propose the Adaptive Self-improving Knowledge (ASK) framework, a model-agnostic, plug-and-play solution. ASK breaks the GLB via multi-grained knowledge injection, systematically mitigates RDM through dynamic knowledge refinement, and introduces a novel adaptive reliability weighting scheme to ensure consistent knowledge contributes to optimization. Experimental results on two benchmark datasets with superior, state-of-the-art performance justify the efficacy of our proposed ASK framework.",
      "primary_category": "eess.AS",
      "categories": [
        "eess.AS",
        "cs.IR",
        "cs.LG",
        "cs.MM",
        "cs.SD"
      ],
      "published": "2025-12-11T14:48:30+00:00",
      "updated": "2025-12-11T14:48:30+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.19703v1",
      "file": "papers/2512.19703v1.pdf"
    },
    {
      "arxiv_id": "2512.09487v1",
      "title": "RouteRAG: Efficient Retrieval-Augmented Generation from Text and Graph via Reinforcement Learning",
      "authors": [
        {
          "name": "Yucan Guo"
        },
        {
          "name": "Miao Su"
        },
        {
          "name": "Saiping Guan"
        },
        {
          "name": "Zihao Sun"
        },
        {
          "name": "Xiaolong Jin"
        },
        {
          "name": "Jiafeng Guo"
        },
        {
          "name": "Xueqi Cheng"
        }
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) integrates non-parametric knowledge into Large Language Models (LLMs), typically from unstructured texts and structured graphs. While recent progress has advanced text-based RAG to multi-turn reasoning through Reinforcement Learning (RL), extending these advances to hybrid retrieval introduces additional challenges. Existing graph-based or hybrid systems typically depend on fixed or handcrafted retrieval pipelines, lacking the ability to integrate supplementary evidence as reasoning unfolds. Besides, while graph evidence provides relational structures crucial for multi-hop reasoning, it is substantially more expensive to retrieve. To address these limitations, we introduce \\model{}, an RL-based framework that enables LLMs to perform multi-turn and adaptive graph-text hybrid RAG. \\model{} jointly optimizes the entire generation process via RL, allowing the model to learn when to reason, what to retrieve from either texts or graphs, and when to produce final answers, all within a unified generation policy. To guide this learning process, we design a two-stage training framework that accounts for both task outcome and retrieval efficiency, enabling the model to exploit hybrid evidence while avoiding unnecessary retrieval overhead. Experimental results across five question answering benchmarks demonstrate that \\model{} significantly outperforms existing RAG baselines, highlighting the benefits of end-to-end RL in supporting adaptive and efficient retrieval for complex reasoning.",
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "published": "2025-12-10T10:05:31+00:00",
      "updated": "2025-12-10T10:05:31+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.09487v1",
      "file": "papers/2512.09487v1.pdf"
    },
    {
      "arxiv_id": "2512.09331v1",
      "title": "Passing the Baton: High Throughput Distributed Disk-Based Vector Search with BatANN",
      "authors": [
        {
          "name": "Nam Anh Dang"
        },
        {
          "name": "Ben Landrum"
        },
        {
          "name": "Ken Birman"
        }
      ],
      "abstract": "Vector search underpins modern information-retrieval systems, including retrieval-augmented generation (RAG) pipelines and search engines over unstructured text and images. As datasets scale to billions of vectors, disk-based vector search has emerged as a practical solution. However, looking to the future, we need to anticipate datasets too large for any single server. We present BatANN, a distributed disk-based approximate nearest neighbor (ANN) system that retains the logarithmic search efficiency of a single global graph while achieving near-linear throughput scaling in the number of servers. Our core innovation is that when accessing a neighborhood which is stored on another machine, we send the full state of the query to the other machine to continue executing there for improved locality. On 100M- and 1B-point datasets at 0.95 recall using 10 servers, BatANN achieves 6.21-6.49x and 2.5-5.10x the throughput of the scatter-gather baseline, respectively, while maintaining mean latency below 6 ms. Moreover, we get these results on standard TCP. To our knowledge, BatANN is the first open-source distributed disk-based vector search system to operate over a single global graph.",
      "primary_category": "cs.DC",
      "categories": [
        "cs.DC",
        "cs.IR"
      ],
      "published": "2025-12-10T05:38:59+00:00",
      "updated": "2025-12-10T05:38:59+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.09331v1",
      "file": "papers/2512.09331v1.pdf"
    },
    {
      "arxiv_id": "2512.08193v1",
      "title": "ClinicalTrialsHub: Bridging Registries and Literature for Comprehensive Clinical Trial Access",
      "authors": [
        {
          "name": "Jiwoo Park"
        },
        {
          "name": "Ruoqi Liu"
        },
        {
          "name": "Avani Jagdale"
        },
        {
          "name": "Andrew Srisuwananukorn"
        },
        {
          "name": "Jing Zhao"
        },
        {
          "name": "Lang Li"
        },
        {
          "name": "Ping Zhang"
        },
        {
          "name": "Sachin Kumar"
        }
      ],
      "abstract": "We present ClinicalTrialsHub, an interactive search-focused platform that consolidates all data from ClinicalTrials.gov and augments it by automatically extracting and structuring trial-relevant information from PubMed research articles. Our system effectively increases access to structured clinical trial data by 83.8% compared to relying on ClinicalTrials.gov alone, with potential to make access easier for patients, clinicians, researchers, and policymakers, advancing evidence-based medicine. ClinicalTrialsHub uses large language models such as GPT-5.1 and Gemini-3-Pro to enhance accessibility. The platform automatically parses full-text research articles to extract structured trial information, translates user queries into structured database searches, and provides an attributed question-answering system that generates evidence-grounded answers linked to specific source sentences. We demonstrate its utility through a user study involving clinicians, clinical researchers, and PhD students of pharmaceutical sciences and nursing, and a systematic automatic evaluation of its information extraction and question answering capabilities.",
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "cs.IR"
      ],
      "published": "2025-12-09T02:52:06+00:00",
      "updated": "2025-12-09T02:52:06+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.08193v1",
      "file": "papers/2512.08193v1.pdf"
    },
    {
      "arxiv_id": "2512.08078v1",
      "title": "A Comparative Study of Retrieval Methods in Azure AI Search",
      "authors": [
        {
          "name": "Qiang Mao"
        },
        {
          "name": "Han Qin"
        },
        {
          "name": "Robert Neary"
        },
        {
          "name": "Charles Wang"
        },
        {
          "name": "Fusheng Wei"
        },
        {
          "name": "Jianping Zhang"
        },
        {
          "name": "Nathaniel Huber-Fliflet"
        }
      ],
      "abstract": "Increasingly, attorneys are interested in moving beyond keyword and semantic search to improve the efficiency of how they find key information during a document review task. Large language models (LLMs) are now seen as tools that attorneys can use to ask natural language questions of their data during document review to receive accurate and concise answers. This study evaluates retrieval strategies within Microsoft Azure's Retrieval-Augmented Generation (RAG) framework to identify effective approaches for Early Case Assessment (ECA) in eDiscovery. During ECA, legal teams analyze data at the outset of a matter to gain a general understanding of the data and attempt to determine key facts and risks before beginning full-scale review. In this paper, we compare the performance of Azure AI Search's keyword, semantic, vector, hybrid, and hybrid-semantic retrieval methods. We then present the accuracy, relevance, and consistency of each method's AI-generated responses. Legal practitioners can use the results of this study to enhance how they select RAG configurations in the future.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2025-12-08T22:20:02+00:00",
      "updated": "2025-12-08T22:20:02+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.08078v1",
      "file": "papers/2512.08078v1.pdf"
    },
    {
      "arxiv_id": "2512.07424v1",
      "title": "OnePiece: The Great Route to Generative Recommendation -- A Case Study from Tencent Algorithm Competition",
      "authors": [
        {
          "name": "Jiangxia Cao"
        },
        {
          "name": "Shuo Yang"
        },
        {
          "name": "Zijun Wang"
        },
        {
          "name": "Qinghai Tan"
        }
      ],
      "abstract": "In past years, the OpenAI's Scaling-Laws shows the amazing intelligence with the next-token prediction paradigm in neural language modeling, which pointing out a free-lunch way to enhance the model performance by scaling the model parameters. In RecSys, the retrieval stage is also follows a 'next-token prediction' paradigm, to recall the hunderds of items from the global item set, thus the generative recommendation usually refers specifically to the retrieval stage (without Tree-based methods). This raises a philosophical question: without a ground-truth next item, does the generative recommendation also holds a potential scaling law? In retrospect, the generative recommendation has two different technique paradigms: (1) ANN-based framework, utilizing the compressed user embedding to retrieve nearest other items in embedding space, e.g, Kuaiformer. (2) Auto-regressive-based framework, employing the beam search to decode the item from whole space, e.g, OneRec. In this paper, we devise a unified encoder-decoder framework to validate their scaling-laws at same time. Our empirical finding is that both of their losses strictly adhere to power-law Scaling Laws ($R^2$>0.9) within our unified architecture.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2025-12-08T10:56:56+00:00",
      "updated": "2025-12-08T10:56:56+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.07424v1",
      "file": "papers/2512.07424v1.pdf"
    },
    {
      "arxiv_id": "2512.07022v1",
      "title": "Reformulate, Retrieve, Localize: Agents for Repository-Level Bug Localization",
      "authors": [
        {
          "name": "Genevieve Caumartin"
        },
        {
          "name": "Glaucia Melo"
        }
      ],
      "abstract": "Bug localization remains a critical yet time-consuming challenge in large-scale software repositories. Traditional information retrieval-based bug localization (IRBL) methods rely on unchanged bug descriptions, which often contain noisy information, leading to poor retrieval accuracy. Recent advances in large language models (LLMs) have improved bug localization through query reformulation, yet the effect on agent performance remains unexplored. In this study, we investigate how an LLM-powered agent can improve file-level bug localization via lightweight query reformulation and summarization. We first employ an open-source, non-fine-tuned LLM to extract key information from bug reports, such as identifiers and code snippets, and reformulate queries pre-retrieval. Our agent then orchestrates BM25 retrieval using these preprocessed queries, automating localization workflow at scale. Using the best-performing query reformulation technique, our agent achieves 35% better ranking in first-file retrieval than our BM25 baseline and up to +22% file retrieval performance over SWE-agent.",
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.IR"
      ],
      "published": "2025-12-07T22:25:11+00:00",
      "updated": "2025-12-07T22:25:11+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.07022v1",
      "file": "papers/2512.07022v1.pdf"
    },
    {
      "arxiv_id": "2512.07015v1",
      "title": "FVA-RAG: Falsification-Verification Alignment for Mitigating Sycophantic Hallucinations",
      "authors": [
        {
          "name": "Mayank Ravishankara"
        }
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) systems have significantly reduced hallucinations in Large Language Models (LLMs) by grounding responses in external context. However, standard RAG architectures suffer from a critical vulnerability: Retrieval Sycophancy. When presented with a query based on a false premise or a common misconception, vector-based retrievers tend to fetch documents that align with the user's bias rather than objective truth, leading the model to \"hallucinate with citations.\"\n  In this work, we introduce Falsification-Verification Alignment RAG (FVA-RAG), a framework that shifts the retrieval paradigm from Inductive Verification (seeking support) to Deductive Falsification (seeking disproof). Unlike existing \"Self-Correction\" methods that rely on internal consistency, FVA-RAG deploys a distinct Adversarial Retrieval Policy that actively generates \"Kill Queries\"-targeted search terms designed to surface contradictory evidence. We introduce a dual-verification mechanism that explicitly weighs the draft answer against this \"Anti-Context.\" Preliminary experiments on a dataset of common misconceptions demonstrate that FVA-RAG significantly improves robustness against sycophantic hallucinations compared to standard RAG baselines, effectively acting as an inference-time \"Red Team\" for factual generation.",
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "published": "2025-12-07T21:28:42+00:00",
      "updated": "2025-12-07T21:28:42+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.07015v1",
      "file": "papers/2512.07015v1.pdf"
    },
    {
      "arxiv_id": "2512.06879v1",
      "title": "WisPaper: Your AI Scholar Search Engine",
      "authors": [
        {
          "name": "Li Ju"
        },
        {
          "name": "Jun Zhao"
        },
        {
          "name": "Mingxu Chai"
        },
        {
          "name": "Ziyu Shen"
        },
        {
          "name": "Xiangyang Wang"
        },
        {
          "name": "Yage Geng"
        },
        {
          "name": "Chunchun Ma"
        },
        {
          "name": "Hao Peng"
        },
        {
          "name": "Guangbin Li"
        },
        {
          "name": "Tao Li"
        },
        {
          "name": "Chengyong Liao"
        },
        {
          "name": "Fu Wang"
        },
        {
          "name": "Xiaolong Wang"
        },
        {
          "name": "Junshen Chen"
        },
        {
          "name": "Rui Gong"
        },
        {
          "name": "Shijia Liang"
        },
        {
          "name": "Feiyan Li"
        },
        {
          "name": "Ming Zhang"
        },
        {
          "name": "Kexin Tan"
        },
        {
          "name": "Jujie Ye"
        },
        {
          "name": "Zhiheng Xi"
        },
        {
          "name": "Shihan Dou"
        },
        {
          "name": "Tao Gui"
        },
        {
          "name": "Yuankai Ying"
        },
        {
          "name": "Yang Shi"
        },
        {
          "name": "Yue Zhang"
        },
        {
          "name": "Qi Zhang"
        }
      ],
      "abstract": "Researchers struggle to efficiently locate and manage relevant literature within the exponentially growing body of scientific publications. We present \\textsc{WisPaper}, an intelligent academic retrieval and literature management platform that addresses this challenge through three integrated capabilities: (1) \\textit{Scholar Search}, featuring both quick keyword-based and deep agentic search modes for efficient paper discovery; (2) \\textit{Library}, a customizable knowledge base for systematic literature organization; and (3) \\textit{AI Feeds}, an intelligent recommendation system that automatically delivers relevant new publications based on user interests. Unlike existing academic tools, \\textsc{WisPaper} provides a closed-loop workflow that seamlessly connects literature discovery, management, and continuous tracking of research frontiers. Our multilingual and multidisciplinary system significantly reduces the time researchers from diverse backgrounds spend on paper screening and management, enabling them to focus on their core research activities. The platform is publicly accessible and serves researchers across academia and industry.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "published": "2025-12-07T15:10:20+00:00",
      "updated": "2025-12-07T15:10:20+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.06879v1",
      "file": "papers/2512.06879v1.pdf"
    },
    {
      "arxiv_id": "2512.06449v1",
      "title": "Enhancing Medical Cross-Modal Hashing Retrieval using Dropout-Voting Mixture-of-Experts Fusion",
      "authors": [
        {
          "name": "Jaewon Ahn"
        },
        {
          "name": "Woosung Jang"
        },
        {
          "name": "Beakcheol Jang"
        }
      ],
      "abstract": "In recent years, cross-modal retrieval using images and text has become an active area of research, especially in the medical domain. The abundance of data in various modalities in this field has led to a growing importance of cross-modal retrieval for efficient image interpretation, data-driven diagnostic support, and medical education. In the context of the increasing integration of distributed medical data across healthcare facilities with the objective of enhancing interoperability, it is imperative to optimize the performance of retrieval systems in terms of the speed, memory efficiency, and accuracy of the retrieved data. This necessity arises in response to the substantial surge in data volume that characterizes contemporary medical practices. In this study, we propose a novel framework that incorporates dropout voting and mixture-of-experts (MoE) based contrastive fusion modules into a CLIP-based cross-modal hashing retrieval structure. We also propose the application of hybrid loss. So we now call our model MCMFH which is a medical cross-modal fusion hashing retrieval. Our method enables the simultaneous achievement of high accuracy and fast retrieval speed in low-memory environments. The model is demonstrated through experiments on radiological and non-radiological medical datasets.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2025-12-06T14:23:44+00:00",
      "updated": "2025-12-06T14:23:44+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.06449v1",
      "file": "papers/2512.06449v1.pdf"
    },
    {
      "arxiv_id": "2512.06395v1",
      "title": "Enhancing Information Retrieval in Digital Libraries through Unit Harmonisation in Scholarly Knowledge Graphs",
      "authors": [
        {
          "name": "Golsa Heidari"
        },
        {
          "name": "Markus Stocker"
        },
        {
          "name": "Sören Auer"
        }
      ],
      "abstract": "Scientists have always used the studies and research of other researchers to achieve new objectives and perspectives. In particular, employing and operating the measured data in previous studies is so practical. Searching the content of other scientists' articles is a challenge that researchers have always struggled with. Nowadays, the use of knowledge graphs as a semantic database has helped a lot in saving and retrieving scholarly knowledge. Such technologies are crucial to upgrading traditional search systems to smart knowledge retrieval, which is crucial to getting the most relevant answers for a user query, especially in information and knowledge management. However, in most cases, only the metadata of a paper is searchable, and it is still cumbersome for scientists to have access to the content of the papers. In this paper, we present a novel method of faceted search \\emph{structured content} for comparing and filtering measured data in scholarly knowledge graphs while different units of measurement are used in different studies. This search system proposes applicable units as facets to the user and would dynamically integrate content from further remote knowledge graphs to materialize the scholarly knowledge graph and achieve a higher order of exploration usability on scholarly content, which can be filtered to better satisfy the user's information needs. The state of the art is that, by using our faceted search system, users can not only search the contents of scientific articles, but also compare and filter heterogeneous data.",
      "primary_category": "cs.DL",
      "categories": [
        "cs.DL",
        "cs.IR"
      ],
      "published": "2025-12-06T10:58:17+00:00",
      "updated": "2025-12-06T10:58:17+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.06395v1",
      "file": "papers/2512.06395v1.pdf"
    },
    {
      "arxiv_id": "2512.06381v1",
      "title": "Beyond Existing Retrievals: Cross-Scenario Incremental Sample Learning Framework",
      "authors": [
        {
          "name": "Tao Wang"
        },
        {
          "name": "Xun Luo"
        },
        {
          "name": "Jinlong Guo"
        },
        {
          "name": "Yuliang Yan"
        },
        {
          "name": "Jian Wu"
        },
        {
          "name": "Yuning Jiang"
        },
        {
          "name": "Bo Zheng"
        }
      ],
      "abstract": "The parallelized multi-retrieval architecture has been widely adopted in large-scale recommender systems for its computational efficiency and comprehensive coverage of user interests. Many retrieval methods typically integrate additional cross-scenario samples to enhance the overall performance ceiling. However, those model designs neglect the fact that a part of the cross-scenario samples have already been retrieved by existing models within a system, leading to diminishing marginal utility in delivering incremental performance gains. In this paper, we propose a novel retrieval framework IncRec, specifically for cross-scenario incremental sample learning. The innovations of IncRec can be highlighted as two aspects. Firstly, we construct extreme cross-scenario incremental samples that are not retrieved by any existing model. And we design an incremental sample learning framework which focuses on capturing incremental representation to improve the overall retrieval performance. Secondly, we introduce a consistency-aware alignment module to further make the model prefer incremental samples with high exposure probability. Extensive offline and online A/B tests validate the superiority of our framework over state-of-the-art retrieval methods. In particular, we deploy IncRec in the Taobao homepage recommendation, achieving a 1% increase in online transaction count, demonstrating its practical applicability.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2025-12-06T10:26:18+00:00",
      "updated": "2025-12-06T10:26:18+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.06381v1",
      "file": "papers/2512.06381v1.pdf"
    },
    {
      "arxiv_id": "2512.06334v1",
      "title": "Enhanced Multimodal Video Retrieval System: Integrating Query Expansion and Cross-modal Temporal Event Retrieval",
      "authors": [
        {
          "name": "Van-Thinh Vo"
        },
        {
          "name": "Minh-Khoi Nguyen"
        },
        {
          "name": "Minh-Huy Tran"
        },
        {
          "name": "Anh-Quan Nguyen-Tran"
        },
        {
          "name": "Duy-Tan Nguyen"
        },
        {
          "name": "Khanh-Loi Nguyen"
        },
        {
          "name": "Anh-Minh Phan"
        }
      ],
      "abstract": "Multimedia information retrieval from videos remains a challenging problem. While recent systems have advanced multimodal search through semantic, object, and OCR queries - and can retrieve temporally consecutive scenes - they often rely on a single query modality for an entire sequence, limiting robustness in complex temporal contexts. To overcome this, we propose a cross-modal temporal event retrieval framework that enables different query modalities to describe distinct scenes within a sequence. To determine decision thresholds for scene transition and slide change adaptively, we build Kernel Density Gaussian Mixture Thresholding (KDE-GMM) algorithm, ensuring optimal keyframe selection. These extracted keyframes act as compact, high-quality visual exemplars that retain each segment's semantic essence, improving retrieval precision and efficiency. Additionally, the system incorporates a large language model (LLM) to refine and expand user queries, enhancing overall retrieval performance. The proposed system's effectiveness and robustness were demonstrated through its strong results in the Ho Chi Minh AI Challenge 2025.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2025-12-06T07:46:51+00:00",
      "updated": "2025-12-06T07:46:51+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.06334v1",
      "file": "papers/2512.06334v1.pdf"
    },
    {
      "arxiv_id": "2512.06155v1",
      "title": "Sift or Get Off the PoC: Applying Information Retrieval to Vulnerability Research with SiftRank",
      "authors": [
        {
          "name": "Caleb Gross"
        }
      ],
      "abstract": "Security research is fundamentally a problem of resource constraint and consequent prioritization. There is simply too much attack surface and too little time and energy to spend analyzing it all. The most effective security researchers are often those who are most skilled at intuitively deciding which part of an expansive attack surface to investigate. We demonstrate that this problem of selecting the most promising option from among many possibilities can be reframed as an information retrieval problem, and solved using document ranking techniques with LLMs performing the heavy lifting as general-purpose rankers. We present SiftRank, a ranking algorithm achieving O(n) complexity through three key mechanisms: listwise ranking using an LLM to order documents in small batches of approximately 10 items at a time; inflection-based convergence detection that adaptively terminates ranking when score distributions have stabilized; and iterative refinement that progressively focuses ranking effort on the most relevant documents. Unlike existing reranking approaches that require a separate first-stage retrieval step to narrow datasets to approximately 100 candidates, SiftRank operates directly on thousands of items, with each document evaluated across multiple randomized batches to mitigate inconsistent judgments by an LLM. We demonstrate practical effectiveness on N-day vulnerability analysis, successfully identifying a vulnerability-fixing function among 2,197 changed functions in a stripped binary firmware patch within 99 seconds at an inference cost of $0.82. Our approach enables scalable security prioritization for problems that are generally constrained by manual analysis, requiring only standard LLM API access without specialized infrastructure, embedding, or domain-specific fine-tuning. An open-source implementation of SiftRank may be found at https://github.com/noperator/siftrank.",
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR",
        "cs.IR"
      ],
      "published": "2025-12-05T21:09:32+00:00",
      "updated": "2025-12-05T21:09:32+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.06155v1",
      "file": "papers/2512.06155v1.pdf"
    },
    {
      "arxiv_id": "2512.05967v1",
      "title": "Enhancing Retrieval-Augmented Generation with Entity Linking for Educational Platforms",
      "authors": [
        {
          "name": "Francesco Granata"
        },
        {
          "name": "Francesco Poggi"
        },
        {
          "name": "Misael Mongiovì"
        }
      ],
      "abstract": "In the era of Large Language Models (LLMs), Retrieval-Augmented Generation (RAG) architectures are gaining significant attention for their ability to ground language generation in reliable knowledge sources. Despite their impressive effectiveness in many areas, RAG systems based solely on semantic similarity often fail to ensure factual accuracy in specialized domains, where terminological ambiguity can affect retrieval relevance. This study proposes an enhanced RAG architecture that integrates a factual signal derived from Entity Linking to improve the accuracy of educational question-answering systems in Italian. The system includes a Wikidata-based Entity Linking module and implements three re-ranking strategies to combine semantic and entity-based information: a hybrid score weighting model, reciprocal rank fusion, and a cross-encoder re-ranker. Experiments were conducted on two benchmarks: a custom academic dataset and the standard SQuAD-it dataset. Results show that, in domain-specific contexts, the hybrid schema based on reciprocal rank fusion significantly outperforms both the baseline and the cross-encoder approach, while the cross-encoder achieves the best results on the general-domain dataset. These findings confirm the presence of an effect of domain mismatch and highlight the importance of domain adaptation and hybrid ranking strategies to enhance factual precision and reliability in retrieval-augmented generation. They also demonstrate the potential of entity-aware RAG systems in educational environments, fostering adaptive and reliable AI-based tutoring tools.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "published": "2025-12-05T18:59:18+00:00",
      "updated": "2025-12-05T18:59:18+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.05967v1",
      "file": "papers/2512.05967v1.pdf"
    },
    {
      "arxiv_id": "2512.05908v1",
      "title": "Natural Language Summarization Enables Multi-Repository Bug Localization by LLMs in Microservice Architectures",
      "authors": [
        {
          "name": "Amirkia Rafiei Oskooei"
        },
        {
          "name": "S. Selcan Yukcu"
        },
        {
          "name": "Mehmet Cevheri Bozoglan"
        },
        {
          "name": "Mehmet S. Aktas"
        }
      ],
      "abstract": "Bug localization in multi-repository microservice architectures is challenging due to the semantic gap between natural language bug reports and code, LLM context limitations, and the need to first identify the correct repository. We propose reframing this as a natural language reasoning task by transforming codebases into hierarchical NL summaries and performing NL-to-NL search instead of cross-modal retrieval. Our approach builds context-aware summaries at file, directory, and repository levels, then uses a two-phase search: first routing bug reports to relevant repositories, then performing top-down localization within those repositories. Evaluated on DNext, an industrial system with 46 repositories and 1.1M lines of code, our method achieves Pass@10 of 0.82 and MRR of 0.50, significantly outperforming retrieval baselines and agentic RAG systems like GitHub Copilot and Cursor. This work demonstrates that engineered natural language representations can be more effective than raw source code for scalable bug localization, providing an interpretable repository -> directory -> file search path, which is vital for building trust in enterprise AI tools by providing essential transparency.",
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ],
      "published": "2025-12-05T17:42:09+00:00",
      "updated": "2025-12-05T17:42:09+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.05908v1",
      "file": "papers/2512.05908v1.pdf"
    },
    {
      "arxiv_id": "2512.05430v1",
      "title": "ArtistMus: A Globally Diverse, Artist-Centric Benchmark for Retrieval-Augmented Music Question Answering",
      "authors": [
        {
          "name": "Daeyong Kwon"
        },
        {
          "name": "SeungHeon Doh"
        },
        {
          "name": "Juhan Nam"
        }
      ],
      "abstract": "Recent advances in large language models (LLMs) have transformed open-domain question answering, yet their effectiveness in music-related reasoning remains limited due to sparse music knowledge in pretraining data. While music information retrieval and computational musicology have explored structured and multimodal understanding, few resources support factual and contextual music question answering (MQA) grounded in artist metadata or historical context. We introduce MusWikiDB, a vector database of 3.2M passages from 144K music-related Wikipedia pages, and ArtistMus, a benchmark of 1,000 questions on 500 diverse artists with metadata such as genre, debut year, and topic. These resources enable systematic evaluation of retrieval-augmented generation (RAG) for MQA. Experiments show that RAG markedly improves factual accuracy; open-source models gain up to +56.8 percentage points (for example, Qwen3 8B improves from 35.0 to 91.8), approaching proprietary model performance. RAG-style fine-tuning further boosts both factual recall and contextual reasoning, improving results on both in-domain and out-of-domain benchmarks. MusWikiDB also yields approximately 6 percentage points higher accuracy and 40% faster retrieval than a general-purpose Wikipedia corpus. We release MusWikiDB and ArtistMus to advance research in music information retrieval and domain-specific question answering, establishing a foundation for retrieval-augmented reasoning in culturally rich domains such as music.",
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "published": "2025-12-05T05:09:30+00:00",
      "updated": "2025-12-05T05:09:30+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.05430v1",
      "file": "papers/2512.05430v1.pdf"
    },
    {
      "arxiv_id": "2512.05411v1",
      "title": "A Systematic Framework for Enterprise Knowledge Retrieval: Leveraging LLM-Generated Metadata to Enhance RAG Systems",
      "authors": [
        {
          "name": "Pranav Pushkar Mishra"
        },
        {
          "name": "Kranti Prakash Yeole"
        },
        {
          "name": "Ramyashree Keshavamurthy"
        },
        {
          "name": "Mokshit Bharat Surana"
        },
        {
          "name": "Fatemeh Sarayloo"
        }
      ],
      "abstract": "In enterprise settings, efficiently retrieving relevant information from large and complex knowledge bases is essential for operational productivity and informed decision-making. This research presents a systematic framework for metadata enrichment using large language models (LLMs) to enhance document retrieval in Retrieval-Augmented Generation (RAG) systems. Our approach employs a comprehensive, structured pipeline that dynamically generates meaningful metadata for document segments, substantially improving their semantic representations and retrieval accuracy. Through extensive experiments, we compare three chunking strategies-semantic, recursive, and naive-and evaluate their effectiveness when combined with advanced embedding techniques. The results demonstrate that metadata-enriched approaches consistently outperform content-only baselines, with recursive chunking paired with TF-IDF weighted embeddings yielding an 82.5% precision rate compared to 73.3% for semantic content-only approaches. The naive chunking strategy with prefix-fusion achieved the highest Hit Rate@10 of 0.925. Our evaluation employs cross-encoder reranking for ground truth generation, enabling rigorous assessment via Hit Rate and Metadata Consistency metrics. These findings confirm that metadata enrichment enhances vector clustering quality while reducing retrieval latency, making it a key optimization for RAG systems across knowledge domains. This work offers practical insights for deploying high-performance, scalable document retrieval solutions in enterprise settings, demonstrating that metadata enrichment is a powerful approach for enhancing RAG effectiveness.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "published": "2025-12-05T04:05:06+00:00",
      "updated": "2025-12-05T04:05:06+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.05411v1",
      "file": "papers/2512.05411v1.pdf"
    },
    {
      "arxiv_id": "2512.05334v1",
      "title": "The Effect of Document Summarization on LLM-Based Relevance Judgments",
      "authors": [
        {
          "name": "Samaneh Mohtadi"
        },
        {
          "name": "Kevin Roitero"
        },
        {
          "name": "Stefano Mizzaro"
        },
        {
          "name": "Gianluca Demartini"
        }
      ],
      "abstract": "Relevance judgments are central to the evaluation of Information Retrieval (IR) systems, but obtaining them from human annotators is costly and time-consuming. Large Language Models (LLMs) have recently been proposed as automated assessors, showing promising alignment with human annotations. Most prior studies have treated documents as fixed units, feeding their full content directly to LLM assessors. We investigate how text summarization affects the reliability of LLM-based judgments and their downstream impact on IR evaluation. Using state-of-the-art LLMs across multiple TREC collections, we compare judgments made from full documents with those based on LLM-generated summaries of different lengths. We examine their agreement with human labels, their effect on retrieval effectiveness evaluation, and their influence on IR systems' ranking stability. Our findings show that summary-based judgments achieve comparable stability in systems' ranking to full-document judgments, while introducing systematic shifts in label distributions and biases that vary by model and dataset. These results highlight summarization as both an opportunity for more efficient large-scale IR evaluation and a methodological choice with important implications for the reliability of automatic judgments.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "published": "2025-12-05T00:26:13+00:00",
      "updated": "2025-12-05T00:26:13+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.05334v1",
      "file": "papers/2512.05334v1.pdf"
    },
    {
      "arxiv_id": "2512.04009v1",
      "title": "Learning to Comparison-Shop",
      "authors": [
        {
          "name": "Jie Tang"
        },
        {
          "name": "Daochen Zha"
        },
        {
          "name": "Xin Liu"
        },
        {
          "name": "Huiji Gao"
        },
        {
          "name": "Liwei He"
        },
        {
          "name": "Stephanie Moyerman"
        },
        {
          "name": "Sanjeev Katariya"
        }
      ],
      "abstract": "In online marketplaces like Airbnb, users frequently engage in comparison shopping before making purchase decisions. Despite the prevalence of this behavior, a significant disconnect persists between mainstream e-commerce search engines and users' comparison needs. Traditional ranking models often evaluate items in isolation, disregarding the context in which users compare multiple items on a search results page. While recent advances in deep learning have sought to improve ranking accuracy, diversity, and fairness by encoding listwise context, the challenge of aligning search rankings with user comparison shopping behavior remains inadequately addressed. In this paper, we propose a novel ranking architecture - Learning-to-Comparison-Shop (LTCS) System - that explicitly models and learns users' comparison shopping behaviors. Through extensive offline and online experiments, we demonstrate that our approach yields statistically significant gains in key business metrics - improving NDCG by 1.7% and boosting booking conversion rate by 0.6% in A/B testing - while also enhancing user experience. We also compare our model against state-of-the-art approaches and demonstrate that LTCS significantly outperforms them.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2025-12-03T17:46:18+00:00",
      "updated": "2025-12-03T17:46:18+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.04009v1",
      "file": "papers/2512.04009v1.pdf"
    },
    {
      "arxiv_id": "2512.03737v1",
      "title": "AR-Med: Automated Relevance Enhancement in Medical Search via LLM-Driven Information Augmentation",
      "authors": [
        {
          "name": "Chuyue Wang"
        },
        {
          "name": "Jie Feng"
        },
        {
          "name": "Yuxi Wu"
        },
        {
          "name": "Hang Zhang"
        },
        {
          "name": "Zhiguo Fan"
        },
        {
          "name": "Bing Cheng"
        },
        {
          "name": "Wei Lin"
        }
      ],
      "abstract": "Accurate and reliable search on online healthcare platforms is critical for user safety and service efficacy. Traditional methods, however, often fail to comprehend complex and nuanced user queries, limiting their effectiveness. Large language models (LLMs) present a promising solution, offering powerful semantic understanding to bridge this gap. Despite their potential, deploying LLMs in this high-stakes domain is fraught with challenges, including factual hallucinations, specialized knowledge gaps, and high operational costs. To overcome these barriers, we introduce \\textbf{AR-Med}, a novel framework for \\textbf{A}utomated \\textbf{R}elevance assessment for \\textbf{Med}ical search that has been successfully deployed at scale on the Online Medical Delivery Platforms. AR-Med grounds LLM reasoning in verified medical knowledge through a retrieval-augmented approach, ensuring high accuracy and reliability. To enable efficient online service, we design a practical knowledge distillation scheme that compresses large teacher models into compact yet powerful student models. We also introduce LocalQSMed, a multi-expert annotated benchmark developed to guide model iteration and ensure strong alignment between offline and online performance. Extensive experiments show AR-Med achieves an offline accuracy of over 93\\%, a 24\\% absolute improvement over the original online system, and delivers significant gains in online relevance and user satisfaction. Our work presents a practical and scalable blueprint for developing trustworthy, LLM-powered systems in real-world healthcare applications.",
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.IR"
      ],
      "published": "2025-12-03T12:34:47+00:00",
      "updated": "2025-12-03T12:34:47+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.03737v1",
      "file": "papers/2512.03737v1.pdf"
    },
    {
      "arxiv_id": "2512.03514v1",
      "title": "M3DR: Towards Universal Multilingual Multimodal Document Retrieval",
      "authors": [
        {
          "name": "Adithya S Kolavi"
        },
        {
          "name": "Vyoman Jain"
        }
      ],
      "abstract": "Multimodal document retrieval systems have shown strong progress in aligning visual and textual content for semantic search. However, most existing approaches remain heavily English-centric, limiting their effectiveness in multilingual contexts. In this work, we present M3DR (Multilingual Multimodal Document Retrieval), a framework designed to bridge this gap across languages, enabling applicability across diverse linguistic and cultural contexts. M3DR leverages synthetic multilingual document data and generalizes across different vision-language architectures and model sizes, enabling robust cross-lingual and cross-modal alignment. Using contrastive training, our models learn unified representations for text and document images that transfer effectively across languages. We validate this capability on 22 typologically diverse languages, demonstrating consistent performance and adaptability across linguistic and script variations. We further introduce a comprehensive benchmark that captures real-world multilingual scenarios, evaluating models under monolingual, multilingual, and mixed-language settings. M3DR generalizes across both single dense vector and ColBERT-style token-level multi-vector retrieval paradigms. Our models, NetraEmbed and ColNetraEmbed achieve state-of-the-art performance with ~150% relative improvements on cross-lingual retrieval.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "published": "2025-12-03T07:17:59+00:00",
      "updated": "2025-12-03T07:17:59+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.03514v1",
      "file": "papers/2512.03514v1.pdf"
    },
    {
      "arxiv_id": "2512.03413v1",
      "title": "BookRAG: A Hierarchical Structure-aware Index-based Approach for Retrieval-Augmented Generation on Complex Documents",
      "authors": [
        {
          "name": "Shu Wang"
        },
        {
          "name": "Yingli Zhou"
        },
        {
          "name": "Yixiang Fang"
        }
      ],
      "abstract": "As an effective method to boost the performance of Large Language Models (LLMs) on the question answering (QA) task, Retrieval-Augmented Generation (RAG), which queries highly relevant information from external complex documents, has attracted tremendous attention from both industry and academia. Existing RAG approaches often focus on general documents, and they overlook the fact that many real-world documents (such as books, booklets, handbooks, etc.) have a hierarchical structure, which organizes their content from different granularity levels, leading to poor performance for the QA task. To address these limitations, we introduce BookRAG, a novel RAG approach targeted for documents with a hierarchical structure, which exploits logical hierarchies and traces entity relations to query the highly relevant information. Specifically, we build a novel index structure, called BookIndex, by extracting a hierarchical tree from the document, which serves as the role of its table of contents, using a graph to capture the intricate relationships between entities, and mapping entities to tree nodes. Leveraging the BookIndex, we then propose an agent-based query method inspired by the Information Foraging Theory, which dynamically classifies queries and employs a tailored retrieval workflow. Extensive experiments on three widely adopted benchmarks demonstrate that BookRAG achieves state-of-the-art performance, significantly outperforming baselines in both retrieval recall and QA accuracy while maintaining competitive efficiency.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "published": "2025-12-03T03:40:49+00:00",
      "updated": "2025-12-03T03:40:49+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.03413v1",
      "file": "papers/2512.03413v1.pdf"
    },
    {
      "arxiv_id": "2512.03025v2",
      "title": "LORE: A Large Generative Model for Search Relevance",
      "authors": [
        {
          "name": "Chenji Lu"
        },
        {
          "name": "Zhuo Chen"
        },
        {
          "name": "Hui Zhao"
        },
        {
          "name": "Zhiyuan Zeng"
        },
        {
          "name": "Gang Zhao"
        },
        {
          "name": "Junjie Ren"
        },
        {
          "name": "Ruicong Xu"
        },
        {
          "name": "Haoran Li"
        },
        {
          "name": "Songyan Liu"
        },
        {
          "name": "Pengjie Wang"
        },
        {
          "name": "Jian Xu"
        },
        {
          "name": "Bo Zheng"
        }
      ],
      "abstract": "Achievement. We introduce LORE, a systematic framework for Large Generative Model-based relevance in e-commerce search. Deployed and iterated over three years, LORE achieves a cumulative +27\\% improvement in online GoodRate metrics. This report shares the valuable experience gained throughout its development lifecycle, spanning data, features, training, evaluation, and deployment. Insight. While existing works apply Chain-of-Thought (CoT) to enhance relevance, they often hit a performance ceiling. We argue this stems from treating relevance as a monolithic task, lacking principled deconstruction. Our key insight is that relevance comprises distinct capabilities: knowledge and reasoning, multi-modal matching, and rule adherence. We contend that a qualitative-driven decomposition is essential for breaking through current performance bottlenecks. Contributions. LORE provides a complete blueprint for the LLM relevance lifecycle. Key contributions include: (1) A two-stage training paradigm combining progressive CoT synthesis via SFT with human preference alignment via RL. (2) A comprehensive benchmark, RAIR, designed to evaluate these core capabilities. (3) A query frequency-stratified deployment strategy that efficiently transfers offline LLM capabilities to the online system. LORE serves as both a practical solution and a methodological reference for other vertical domains.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "published": "2025-12-02T18:50:42+00:00",
      "updated": "2025-12-04T16:35:05+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.03025v2",
      "file": "papers/2512.03025v2.pdf"
    },
    {
      "arxiv_id": "2512.02660v2",
      "title": "Spatially-Grounded Document Retrieval via Patch-to-Region Relevance Propagation",
      "authors": [
        {
          "name": "Athos Georgiou"
        }
      ],
      "abstract": "Late-interaction multimodal retrieval models like ColPali achieve state-of-the-art document retrieval by embedding pages as images and computing fine-grained similarity between query tokens and visual patches. However, they return entire pages rather than specific regions, limiting utility for retrieval-augmented generation (RAG) where precise context is paramount. Conversely, OCR-based systems extract structured text with bounding box coordinates but lack semantic grounding for relevance assessment. We propose a hybrid architecture that unifies these paradigms: using ColPali's patch-level similarity scores as spatial relevance filters over OCR-extracted regions. We formalize the coordinate mapping between vision transformer patch grids and OCR bounding boxes, introduce intersection metrics for relevance propagation, and establish theoretical bounds on area efficiency. We evaluate on BBox-DocVQA with ground-truth bounding boxes. For within-page localization (given correct page retrieval), ColQwen3-4B with percentile-50 thresholding achieves 59.7% hit rate at IoU@0.5 (84.4% at IoU@0.25, 35.8% at IoU@0.7), with mean IoU of 0.569, compared to ~6.7% for random region selection. Our approach reduces context tokens by 28.8% compared to returning all OCR regions and by 52.3% compared to full-page image tokens. Our approach operates at inference time without additional training. We release Snappy, an open-source implementation at https://github.com/athrael-soju/Snappy.",
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.IR"
      ],
      "published": "2025-12-02T11:29:54+00:00",
      "updated": "2025-12-14T02:43:58+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.02660v2",
      "file": "papers/2512.02660v2.pdf"
    },
    {
      "arxiv_id": "2512.02555v1",
      "title": "ADORE: Autonomous Domain-Oriented Relevance Engine for E-commerce",
      "authors": [
        {
          "name": "Zheng Fang"
        },
        {
          "name": "Donghao Xie"
        },
        {
          "name": "Ming Pang"
        },
        {
          "name": "Chunyuan Yuan"
        },
        {
          "name": "Xue Jiang"
        },
        {
          "name": "Changping Peng"
        },
        {
          "name": "Zhangang Lin"
        },
        {
          "name": "Zheng Luo"
        }
      ],
      "abstract": "Relevance modeling in e-commerce search remains challenged by semantic gaps in term-matching methods (e.g., BM25) and neural models' reliance on the scarcity of domain-specific hard samples. We propose ADORE, a self-sustaining framework that synergizes three innovations: (1) A Rule-aware Relevance Discrimination module, where a Chain-of-Thought LLM generates intent-aligned training data, refined via Kahneman-Tversky Optimization (KTO) to align with user behavior; (2) An Error-type-aware Data Synthesis module that auto-generates adversarial examples to harden robustness; and (3) A Key-attribute-enhanced Knowledge Distillation module that injects domain-specific attribute hierarchies into a deployable student model. ADORE automates annotation, adversarial generation, and distillation, overcoming data scarcity while enhancing reasoning. Large-scale experiments and online A/B testing verify the effectiveness of ADORE. The framework establishes a new paradigm for resource-efficient, cognitively aligned relevance modeling in industrial applications.",
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "published": "2025-12-02T09:25:13+00:00",
      "updated": "2025-12-02T09:25:13+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.02555v1",
      "file": "papers/2512.02555v1.pdf"
    },
    {
      "arxiv_id": "2512.02502v1",
      "title": "AskNearby: An LLM-Based Application for Neighborhood Information Retrieval and Personalized Cognitive-Map Recommendations",
      "authors": [
        {
          "name": "Luyao Niu"
        },
        {
          "name": "Zhicheng Deng"
        },
        {
          "name": "Boyang Li"
        },
        {
          "name": "Nuoxian Huang"
        },
        {
          "name": "Ruiqi Liu"
        },
        {
          "name": "Wenjia Zhang"
        }
      ],
      "abstract": "The \"15-minute city\" envisions neighborhoods where residents can meet daily needs via a short walk or bike ride. Realizing this vision requires not only physical proximity but also efficient and reliable access to information about nearby places, services, and events. Existing location-based systems, however, focus mainly on city-level tasks and neglect the spatial, temporal, and cognitive factors that shape localized decision-making. We conceptualize this gap as the Local Life Information Accessibility (LLIA) problem and introduce AskNearby, an AI-driven community application that unifies retrieval and recommendation within the 15-minute life circle. AskNearby integrates (i) a three-layer Retrieval-Augmented Generation (RAG) pipeline that synergizes graph-based, semantic-vector, and geographic retrieval with (ii) a cognitive-map model that encodes each user's neighborhood familiarity and preferences. Experiments on real-world community datasets demonstrate that AskNearby significantly outperforms LLM-based and map-based baselines in retrieval accuracy and recommendation quality, achieving robust performance in spatiotemporal grounding and cognitive-aware ranking. Real-world deployments further validate its effectiveness. By addressing the LLIA challenge, AskNearby empowers residents to more effectively discover local resources, plan daily activities, and engage in community life.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "published": "2025-12-02T07:47:31+00:00",
      "updated": "2025-12-02T07:47:31+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.02502v1",
      "file": "papers/2512.02502v1.pdf"
    },
    {
      "arxiv_id": "2512.02425v1",
      "title": "WorldMM: Dynamic Multimodal Memory Agent for Long Video Reasoning",
      "authors": [
        {
          "name": "Woongyeong Yeo"
        },
        {
          "name": "Kangsan Kim"
        },
        {
          "name": "Jaehong Yoon"
        },
        {
          "name": "Sung Ju Hwang"
        }
      ],
      "abstract": "Recent advances in video large language models have demonstrated strong capabilities in understanding short clips. However, scaling them to hours- or days-long videos remains highly challenging due to limited context capacity and the loss of critical visual details during abstraction. Existing memory-augmented methods mitigate this by leveraging textual summaries of video segments, yet they heavily rely on text and fail to utilize visual evidence when reasoning over complex scenes. Moreover, retrieving from fixed temporal scales further limits their flexibility in capturing events that span variable durations. To address this, we introduce WorldMM, a novel multimodal memory agent that constructs and retrieves from multiple complementary memories, encompassing both textual and visual representations. WorldMM comprises three types of memory: episodic memory indexes factual events across multiple temporal scales, semantic memory continuously updates high-level conceptual knowledge, and visual memory preserves detailed information about scenes. During inference, an adaptive retrieval agent iteratively selects the most relevant memory source and leverages multiple temporal granularities based on the query, continuing until it determines that sufficient information has been gathered. WorldMM significantly outperforms existing baselines across five long video question-answering benchmarks, achieving an average 8.4% performance gain over previous state-of-the-art methods, showing its effectiveness on long video reasoning.",
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.IR",
        "cs.LG"
      ],
      "published": "2025-12-02T05:14:52+00:00",
      "updated": "2025-12-02T05:14:52+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.02425v1",
      "file": "papers/2512.02425v1.pdf"
    },
    {
      "arxiv_id": "2512.00968v1",
      "title": "Optimizing Generative Ranking Relevance via Reinforcement Learning in Xiaohongshu Search",
      "authors": [
        {
          "name": "Ziyang Zeng"
        },
        {
          "name": "Heming Jing"
        },
        {
          "name": "Jindong Chen"
        },
        {
          "name": "Xiangli Li"
        },
        {
          "name": "Hongyu Liu"
        },
        {
          "name": "Yixuan He"
        },
        {
          "name": "Zhengyu Li"
        },
        {
          "name": "Yige Sun"
        },
        {
          "name": "Zheyong Xie"
        },
        {
          "name": "Yuqing Yang"
        },
        {
          "name": "Shaosheng Cao"
        },
        {
          "name": "Jun Fan"
        },
        {
          "name": "Yi Wu"
        },
        {
          "name": "Yao Hu"
        }
      ],
      "abstract": "Ranking relevance is a fundamental task in search engines, aiming to identify the items most relevant to a given user query. Traditional relevance models typically produce scalar scores or directly predict relevance labels, limiting both interpretability and the modeling of complex relevance signals. Inspired by recent advances in Chain-of-Thought (CoT) reasoning for complex tasks, we investigate whether explicit reasoning can enhance both interpretability and performance in relevance modeling. However, existing reasoning-based Generative Relevance Models (GRMs) primarily rely on supervised fine-tuning on large amounts of human-annotated or synthetic CoT data, which often leads to limited generalization. Moreover, domain-agnostic, free-form reasoning tends to be overly generic and insufficiently grounded, limiting its potential to handle the diverse and ambiguous cases prevalent in open-domain search. In this work, we formulate relevance modeling in Xiaohongshu search as a reasoning task and introduce a Reinforcement Learning (RL)-based training framework to enhance the grounded reasoning capabilities of GRMs. Specifically, we incorporate practical business-specific relevance criteria into the multi-step reasoning prompt design and propose Stepwise Advantage Masking (SAM), a lightweight process-supervision strategy which facilitates effective learning of these criteria through improved credit assignment. To enable industrial deployment, we further distill the large-scale RL-tuned model to a lightweight version suitable for real-world search systems. Extensive experiments on industrial datasets, along with online A/B tests, demonstrate the effectiveness of our approach.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "published": "2025-11-30T16:31:16+00:00",
      "updated": "2025-11-30T16:31:16+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.00968v1",
      "file": "papers/2512.00968v1.pdf"
    },
    {
      "arxiv_id": "2512.00772v1",
      "title": "SHRAG: AFrameworkfor Combining Human-Inspired Search with RAG",
      "authors": [
        {
          "name": "Hyunseok Ryu"
        },
        {
          "name": "Wonjune Shin"
        },
        {
          "name": "Hyun Park"
        }
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) is gaining recognition as one of the key technological axes for next generation information retrieval, owing to its ability to mitigate the hallucination phenomenon in Large Language\n  Models (LLMs)and effectively incorporate up-to-date information. However, specialized expertise is necessary to\n  construct ahigh-quality retrieval system independently; moreover, RAGdemonstratesrelativelyslowerprocessing\n  speeds compared to conventional pure retrieval systems because it involves both retrieval and generation stages.\n  Accordingly, this study proposes SHRAG, a novel framework designed to facilitate the seamless integration of\n  Information Retrieval and RAG while simultaneously securing precise retrieval performance. SHRAG utilizes a\n  Large Language Model as a Query Strategist to automatically transform unstructured natural language queries\n  into logically structured search queries, subsequently performing Boolean retrieval to emulate the search process\n  of an expert human searcher. Furthermore, it incorporates multilingual query expansion and a multilingual\n  embedding model, enabling it to perform efficient cross-lingual question answering within the multilingual\n  dataset environment of the ScienceON Challenge. Experimental results demonstrate that the proposed method,\n  combining logical retrieval capabilities and generative reasoning, can significantly enhance the accuracy and\n  reliability of RAG systems. Furthermore, SHRAG movesbeyondconventionaldocument-centric retrieval methods,\n  presenting the potential for a new search paradigm capable of providing direct and reliable responses to queries.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.DL"
      ],
      "published": "2025-11-30T08:06:47+00:00",
      "updated": "2025-11-30T08:06:47+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.00772v1",
      "file": "papers/2512.00772v1.pdf"
    },
    {
      "arxiv_id": "2512.00390v1",
      "title": "Mitigating the Threshold Priming Effect in Large Language Model-Based Relevance Judgments via Personality Infusing",
      "authors": [
        {
          "name": "Nuo Chen"
        },
        {
          "name": "Hanpei Fang"
        },
        {
          "name": "Jiqun Liu"
        },
        {
          "name": "Wilson Wei"
        },
        {
          "name": "Tetsuya Sakai"
        },
        {
          "name": "Xiao-Ming Wu"
        }
      ],
      "abstract": "Recent research has explored LLMs as scalable tools for relevance labeling, but studies indicate they are susceptible to priming effects, where prior relevance judgments influence later ones. Although psychological theories link personality traits to such biases, it is unclear whether simulated personalities in LLMs exhibit similar effects. We investigate how Big Five personality profiles in LLMs influence priming in relevance labeling, using multiple LLMs on TREC 2021 and 2022 Deep Learning Track datasets. Our results show that certain profiles, such as High Openness and Low Neuroticism, consistently reduce priming susceptibility. Additionally, the most effective personality in mitigating priming may vary across models and task types. Based on these findings, we propose personality prompting as a method to mitigate threshold priming, connecting psychological evidence with LLM-based evaluation practices.",
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.IR"
      ],
      "published": "2025-11-29T08:37:51+00:00",
      "updated": "2025-11-29T08:37:51+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.00390v1",
      "file": "papers/2512.00390v1.pdf"
    },
    {
      "arxiv_id": "2512.00378v1",
      "title": "The Information Theory of Similarity",
      "authors": [
        {
          "name": "Nikit Phadke"
        }
      ],
      "abstract": "We establish a precise mathematical equivalence between witness-based similarity systems (REWA) and Shannon's information theory. We prove that witness overlap is mutual information, that REWA bit complexity bounds arise from channel capacity limitations, and that ranking-preserving encodings obey rate-distortion constraints. This unification reveals that fifty years of similarity search research -- from Bloom filters to locality-sensitive hashing to neural retrieval -- implicitly developed information theory for relational data. We derive fundamental lower bounds showing that REWA's $O(Δ^{-2} \\log N)$ complexity is optimal: no encoding scheme can preserve similarity rankings with fewer bits. The framework establishes that semantic similarity has physical units (bits of mutual information), search is communication (query transmission over a noisy channel), and retrieval systems face fundamental capacity limits analogous to Shannon's channel coding theorem.",
      "primary_category": "cs.IT",
      "categories": [
        "cs.IT",
        "cs.DS",
        "cs.IR",
        "cs.LG"
      ],
      "published": "2025-11-29T08:12:45+00:00",
      "updated": "2025-11-29T08:12:45+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.00378v1",
      "file": "papers/2512.00378v1.pdf"
    },
    {
      "arxiv_id": "2512.00367v1",
      "title": "Breaking It Down: Domain-Aware Semantic Segmentation for Retrieval Augmented Generation",
      "authors": [
        {
          "name": "Aparajitha Allamraju"
        },
        {
          "name": "Maitreya Prafulla Chitale"
        },
        {
          "name": "Hiranmai Sri Adibhatla"
        },
        {
          "name": "Rahul Mishra"
        },
        {
          "name": "Manish Shrivastava"
        }
      ],
      "abstract": "Document chunking is a crucial component of Retrieval-Augmented Generation (RAG), as it directly affects the retrieval of relevant and precise context. Conventional fixed-length and recursive splitters often produce arbitrary, incoherent segments that fail to preserve semantic structure. Although semantic chunking has gained traction, its influence on generation quality remains underexplored. This paper introduces two efficient semantic chunking methods, Projected Similarity Chunking (PSC) and Metric Fusion Chunking (MFC), trained on PubMed data using three different embedding models. We further present an evaluation framework that measures the effect of chunking on both retrieval and generation by augmenting PubMedQA with full-text PubMed Central articles. Our results show substantial retrieval improvements (24x with PSC) in MRR and higher Hits@k on PubMedQA. We provide a comprehensive analysis, including statistical significance and response-time comparisons with common chunking libraries. Despite being trained on a single domain, PSC and MFC also generalize well, achieving strong out-of-domain generation performance across multiple datasets. Overall, our findings confirm that our semantic chunkers, especially PSC, consistently deliver superior performance.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.CL"
      ],
      "published": "2025-11-29T07:30:37+00:00",
      "updated": "2025-11-29T07:30:37+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.00367v1",
      "file": "papers/2512.00367v1.pdf"
    },
    {
      "arxiv_id": "2511.22460v1",
      "title": "An Efficient Embedding Based Ad Retrieval with GPU-Powered Feature Interaction",
      "authors": [
        {
          "name": "Yifan Lei"
        },
        {
          "name": "Jiahua Luo"
        },
        {
          "name": "Tingyu Jiang"
        },
        {
          "name": "Bo Zhang"
        },
        {
          "name": "Lifeng Wang"
        },
        {
          "name": "Dapeng Liu"
        },
        {
          "name": "Zhaoren Wu"
        },
        {
          "name": "Haijie Gu"
        },
        {
          "name": "Huan Yu"
        },
        {
          "name": "Jie Jiang"
        }
      ],
      "abstract": "In large-scale advertising recommendation systems, retrieval serves as a critical component, aiming to efficiently select a subset of candidate ads relevant to user behaviors from a massive ad inventory for subsequent ranking and recommendation. The Embedding-Based Retrieval (EBR) methods modeled by the dual-tower network are widely used in the industry to maintain both retrieval efficiency and accuracy. However, the dual-tower model has significant limitations: the embeddings of users and ads interact only at the final inner product computation, resulting in insufficient feature interaction capabilities. Although DNN-based models with both user and ad as input features, allowing for early-stage interaction between these features, are introduced in the ranking stage to mitigate this issue, they are computationally infeasible for the retrieval stage. To bridge this gap, this paper proposes an efficient GPU-based feature interaction for the dual-tower network to significantly improve retrieval accuracy while substantially reducing computational costs. Specifically, we introduce a novel compressed inverted list designed for GPU acceleration, enabling efficient feature interaction computation at scale. To the best of our knowledge, this is the first framework in the industry to successfully implement Wide and Deep in a retrieval system. We apply this model to the real-world business scenarios in Tencent Advertising, and experimental results demonstrate that our method outperforms existing approaches in offline evaluation and has been successfully deployed to Tencent's advertising recommendation system, delivering significant online performance gains. This improvement not only validates the effectiveness of the proposed method, but also provides new practical guidance for optimizing large-scale ad retrieval systems.",
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.IR"
      ],
      "published": "2025-11-27T13:48:37+00:00",
      "updated": "2025-11-27T13:48:37+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.22460v1",
      "file": "papers/2511.22460v1.pdf"
    },
    {
      "arxiv_id": "2511.22263v1",
      "title": "Efficiency and Effectiveness of SPLADE Models on Billion-Scale Web Document Title",
      "authors": [
        {
          "name": "Taeryun Won"
        },
        {
          "name": "Tae Kwan Lee"
        },
        {
          "name": "Hiun Kim"
        },
        {
          "name": "Hyemin Lee"
        }
      ],
      "abstract": "This paper presents a comprehensive comparison of BM25, SPLADE, and Expanded-SPLADE models in the context of large-scale web document retrieval. We evaluate the effectiveness and efficiency of these models on datasets spanning from tens of millions to billions of web document titles. SPLADE and Expanded-SPLADE, which utilize sparse lexical representations, demonstrate superior retrieval performance compared to BM25, especially for complex queries. However, these models incur higher computational costs. We introduce pruning strategies, including document-centric pruning and top-k query term selection, boolean query with term threshold to mitigate these costs and improve the models' efficiency without significantly sacrificing retrieval performance. The results show that Expanded-SPLADE strikes the best balance between effectiveness and efficiency, particularly when handling large datasets. Our findings offer valuable insights for deploying sparse retrieval models in large-scale search engines.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "published": "2025-11-27T09:40:21+00:00",
      "updated": "2025-11-27T09:40:21+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.22263v1",
      "file": "papers/2511.22263v1.pdf"
    },
    {
      "arxiv_id": "2511.22253v1",
      "title": "UNION: A Lightweight Target Representation for Efficient Zero-Shot Image-Guided Retrieval with Optional Textual Queries",
      "authors": [
        {
          "name": "Hoang-Bao Le"
        },
        {
          "name": "Allie Tran"
        },
        {
          "name": "Binh T. Nguyen"
        },
        {
          "name": "Liting Zhou"
        },
        {
          "name": "Cathal Gurrin"
        }
      ],
      "abstract": "Image-Guided Retrieval with Optional Text (IGROT) is a general retrieval setting where a query consists of an anchor image, with or without accompanying text, aiming to retrieve semantically relevant target images. This formulation unifies two major tasks: Composed Image Retrieval (CIR) and Sketch-Based Image Retrieval (SBIR). In this work, we address IGROT under low-data supervision by introducing UNION, a lightweight and generalisable target representation that fuses the image embedding with a null-text prompt. Unlike traditional approaches that rely on fixed target features, UNION enhances semantic alignment with multimodal queries while requiring no architectural modifications to pretrained vision-language models. With only 5,000 training samples - from LlavaSCo for CIR and Training-Sketchy for SBIR - our method achieves competitive results across benchmarks, including CIRCO mAP@50 of 38.5 and Sketchy mAP@200 of 82.7, surpassing many heavily supervised baselines. This demonstrates the robustness and efficiency of UNION in bridging vision and language across diverse query types.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.CV"
      ],
      "published": "2025-11-27T09:28:28+00:00",
      "updated": "2025-11-27T09:28:28+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.22253v1",
      "file": "papers/2511.22253v1.pdf"
    },
    {
      "arxiv_id": "2511.22247v1",
      "title": "FIGROTD: A Friendly-to-Handle Dataset for Image Guided Retrieval with Optional Text",
      "authors": [
        {
          "name": "Hoang-Bao Le"
        },
        {
          "name": "Allie Tran"
        },
        {
          "name": "Binh T. Nguyen"
        },
        {
          "name": "Liting Zhou"
        },
        {
          "name": "Cathal Gurrin"
        }
      ],
      "abstract": "Image-Guided Retrieval with Optional Text (IGROT) unifies visual retrieval (without text) and composed retrieval (with text). Despite its relevance in applications like Google Image and Bing, progress has been limited by the lack of an accessible benchmark and methods that balance performance across subtasks. Large-scale datasets such as MagicLens are comprehensive but computationally prohibitive, while existing models often favor either visual or compositional queries. We introduce FIGROTD, a lightweight yet high-quality IGROT dataset with 16,474 training triplets and 1,262 test triplets across CIR, SBIR, and CSTBIR. To reduce redundancy, we propose the Variance Guided Feature Mask (VaGFeM), which selectively enhances discriminative dimensions based on variance statistics. We further adopt a dual-loss design (InfoNCE + Triplet) to improve compositional reasoning. Trained on FIGROTD, VaGFeM achieves competitive results on nine benchmarks, reaching 34.8 mAP@10 on CIRCO and 75.7 mAP@200 on Sketchy, outperforming stronger baselines despite fewer triplets.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.CV"
      ],
      "published": "2025-11-27T09:18:56+00:00",
      "updated": "2025-11-27T09:18:56+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.22247v1",
      "file": "papers/2511.22247v1.pdf"
    },
    {
      "arxiv_id": "2511.22240v1",
      "title": "Evaluating Embedding Models and Pipeline Optimization for AI Search Quality",
      "authors": [
        {
          "name": "Philip Zhong"
        },
        {
          "name": "Kent Chen"
        },
        {
          "name": "Don Wang"
        }
      ],
      "abstract": "We evaluate the performance of various text embedding models and pipeline configurations for AI-driven search systems. We compare sentence-transformer and generative embedding models (e.g., All-MPNet, BGE, GTE, and Qwen) at different dimensions, indexing methods (Milvus HNSW/IVF), and chunking strategies. A custom evaluation dataset of 11,975 query-chunk pairs was synthesized from US City Council meeting transcripts using a local large language model (LLM). The data pipeline includes preprocessing, automated question generation per chunk, manual validation, and continuous integration/continuous deployment (CI/CD) integration. We measure retrieval accuracy using reference-based metrics: Top-K Accuracy and Normalized Discounted Cumulative Gain (NDCG). Our results demonstrate that higher-dimensional embeddings significantly boost search quality (e.g., Qwen3-Embedding-8B/4096 achieves Top-3 accuracy about 0.571 versus 0.412 for GTE-large/1024), and that neural re-rankers (e.g., a BGE cross-encoder) further improve ranking accuracy (Top-3 up to 0.527). Finer-grained chunking (512 characters versus 2000 characters) also improves accuracy. We discuss the impact of these factors and outline future directions for pipeline automation and evaluation.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "published": "2025-11-27T09:09:39+00:00",
      "updated": "2025-11-27T09:09:39+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.22240v1",
      "file": "papers/2511.22240v1.pdf"
    },
    {
      "arxiv_id": "2511.21121v1",
      "title": "Beyond Patch Aggregation: 3-Pass Pyramid Indexing for Vision-Enhanced Document Retrieval",
      "authors": [
        {
          "name": "Anup Roy"
        },
        {
          "name": "Rishabh Gyanendra Upadhyay"
        },
        {
          "name": "Animesh Rameshbhai Panara"
        },
        {
          "name": "Robin Mills"
        }
      ],
      "abstract": "Document centric RAG pipelines usually begin with OCR, followed by brittle heuristics for chunking, table parsing, and layout reconstruction. These text first workflows are costly to maintain, sensitive to small layout shifts, and often lose the spatial cues that contain the answer. Vision first retrieval has emerged as a strong alternative. By operating directly on page images, systems like ColPali and ColQwen preserve structure and reduce pipeline complexity while achieving strong benchmark performance. However, these late interaction models tie retrieval to a specific vision backbone and require storing hundreds of patch embeddings per page, creating high memory overhead and complicating large scale deployment.\n  We introduce VisionRAG, a multimodal retrieval system that is OCR free and model agnostic. VisionRAG indexes documents directly as images, preserving layout, tables, and spatial cues, and builds semantic vectors without committing to a specific extraction. Our three pass pyramid indexing framework creates vectors using global page summaries, section headers, visual hotspots, and fact level cues. These summaries act as lightweight retrieval surrogates. At query time, VisionRAG retrieves the most relevant pages using the pyramid index, then forwards the raw page image encoded as base64 to a multimodal LLM for final question answering. During retrieval, reciprocal rank fusion integrates signals across the pyramid to produce robust ranking.\n  VisionRAG stores only 17 to 27 vectors per page, matching the efficiency of patch based methods while staying flexible across multimodal encoders. On financial document benchmarks, it achieves 0.8051 accuracy at 10 on FinanceBench and 0.9629 recall at 100 on TAT DQA. These results show that OCR free, summary guided multimodal retrieval is a practical and scalable alternative to traditional text extraction pipelines.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "published": "2025-11-26T07:18:06+00:00",
      "updated": "2025-11-26T07:18:06+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.21121v1",
      "file": "papers/2511.21121v1.pdf"
    },
    {
      "arxiv_id": "2512.20626v1",
      "title": "MegaRAG: Multimodal Knowledge Graph-Based Retrieval Augmented Generation",
      "authors": [
        {
          "name": "Chi-Hsiang Hsiao"
        },
        {
          "name": "Yi-Cheng Wang"
        },
        {
          "name": "Tzung-Sheng Lin"
        },
        {
          "name": "Yi-Ren Yeh"
        },
        {
          "name": "Chu-Song Chen"
        }
      ],
      "abstract": "Retrieval-augmented generation (RAG) enables large language models (LLMs) to dynamically access external information, which is powerful for answering questions over previously unseen documents. Nonetheless, they struggle with high-level conceptual understanding and holistic comprehension due to limited context windows, which constrain their ability to perform deep reasoning over long-form, domain-specific content such as full-length books. To solve this problem, knowledge graphs (KGs) have been leveraged to provide entity-centric structure and hierarchical summaries, offering more structured support for reasoning. However, existing KG-based RAG solutions remain restricted to text-only inputs and fail to leverage the complementary insights provided by other modalities such as vision. On the other hand, reasoning from visual documents requires textual, visual, and spatial cues into structured, hierarchical concepts. To address this issue, we introduce a multimodal knowledge graph-based RAG that enables cross-modal reasoning for better content understanding. Our method incorporates visual cues into the construction of knowledge graphs, the retrieval phase, and the answer generation process. Experimental results across both global and fine-grained question answering tasks show that our approach consistently outperforms existing RAG-based approaches on both textual and multimodal corpora.",
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.IR"
      ],
      "published": "2025-11-26T05:00:03+00:00",
      "updated": "2025-11-26T05:00:03+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.20626v1",
      "file": "papers/2512.20626v1.pdf"
    },
    {
      "arxiv_id": "2511.20867v1",
      "title": "E-GEO: A Testbed for Generative Engine Optimization in E-Commerce",
      "authors": [
        {
          "name": "Puneet S. Bagga"
        },
        {
          "name": "Vivek F. Farias"
        },
        {
          "name": "Tamar Korkotashvili"
        },
        {
          "name": "Tianyi Peng"
        },
        {
          "name": "Yuhang Wu"
        }
      ],
      "abstract": "With the rise of large language models (LLMs), generative engines are becoming powerful alternatives to traditional search, reshaping retrieval tasks. In e-commerce, for instance, conversational shopping agents now guide consumers to relevant products. This shift has created the need for generative engine optimization (GEO)--improving content visibility and relevance for generative engines. Yet despite its growing importance, current GEO practices are ad hoc, and their impacts remain poorly understood, especially in e-commerce. We address this gap by introducing E-GEO, the first benchmark built specifically for e-commerce GEO. E-GEO contains over 7,000 realistic, multi-sentence consumer product queries paired with relevant listings, capturing rich intent, constraints, preferences, and shopping contexts that existing datasets largely miss. Using this benchmark, we conduct the first large-scale empirical study of e-commerce GEO, evaluating 15 common rewriting heuristics and comparing their empirical performance. To move beyond heuristics, we further formulate GEO as a tractable optimization problem and develop a lightweight iterative prompt-optimization algorithm that can significantly outperform these baselines. Surprisingly, the optimized prompts reveal a stable, domain-agnostic pattern--suggesting the existence of a \"universally effective\" GEO strategy. Our data and code are publicly available at https://github.com/psbagga17/E-GEO.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2025-11-25T21:28:40+00:00",
      "updated": "2025-11-25T21:28:40+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.20867v1",
      "file": "papers/2511.20867v1.pdf"
    },
    {
      "arxiv_id": "2512.07846v1",
      "title": "MixLM: High-Throughput and Effective LLM Ranking via Text-Embedding Mix-Interaction",
      "authors": [
        {
          "name": "Guoyao Li"
        },
        {
          "name": "Ran He"
        },
        {
          "name": "Shusen Jing"
        },
        {
          "name": "Kayhan Behdin"
        },
        {
          "name": "Yubo Wang"
        },
        {
          "name": "Sundara Raman Ramachandran"
        },
        {
          "name": "Chanh Nguyen"
        },
        {
          "name": "Jian Sheng"
        },
        {
          "name": "Xiaojing Ma"
        },
        {
          "name": "Chuanrui Zhu"
        },
        {
          "name": "Sriram Vasudevan"
        },
        {
          "name": "Muchen Wu"
        },
        {
          "name": "Sayan Ghosh"
        },
        {
          "name": "Lin Su"
        },
        {
          "name": "Qingquan Song"
        },
        {
          "name": "Xiaoqing Wang"
        },
        {
          "name": "Zhipeng Wang"
        },
        {
          "name": "Qing Lan"
        },
        {
          "name": "Yanning Chen"
        },
        {
          "name": "Jingwei Wu"
        },
        {
          "name": "Luke Simon"
        },
        {
          "name": "Wenjing Zhang"
        },
        {
          "name": "Qi Guo"
        },
        {
          "name": "Fedor Borisyuk"
        }
      ],
      "abstract": "Large language models (LLMs) excel at capturing semantic nuances and therefore show impressive relevance ranking performance in modern recommendation and search systems. However, they suffer from high computational overhead under industrial latency and throughput requirements. In particular, cross-encoder ranking systems often create long context prefill-heavy workloads, as the model has to be presented with the user, query and item information. To this end, we propose MixLM, a novel LLM-based ranking framework, which significantly improves the system throughput via reducing the input context length, while preserving the semantic strength of cross-encoder rankers. In contrast to a standard ranking system where the context is presented to the model as pure text, we propose to use mix-interaction, a mixture of text and embedding tokens to represent the input. Specifically, MixLM encodes all items in the catalog into a few embedding tokens and stores in a nearline cache. The encoded item descriptions are used during online inference, effectively reducing the item length from a few thousand text tokens to a few embedding tokens. We share insights from deploying our MixLM framework to a real-world search application at LinkedIn, including a detailed discussion of our training pipelines, as well as a thorough analysis of our online serving infrastructure optimization. Comparing with strong baselines, MixLM increased throughput by 10.0x under the same latency budget, while maintaining relevance metrics. The efficiency gains delivered by MixLM enabled full-traffic deployment of LLM-powered search, which resulted in a significant 0.47% increase in Daily Active Users (DAU) in online A/B tests.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "published": "2025-11-25T21:23:04+00:00",
      "updated": "2025-11-25T21:23:04+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.07846v1",
      "file": "papers/2512.07846v1.pdf"
    },
    {
      "arxiv_id": "2511.20227v1",
      "title": "HKRAG: Holistic Knowledge Retrieval-Augmented Generation Over Visually-Rich Documents",
      "authors": [
        {
          "name": "Anyang Tong"
        },
        {
          "name": "Xiang Niu"
        },
        {
          "name": "ZhiPing Liu"
        },
        {
          "name": "Chang Tian"
        },
        {
          "name": "Yanyan Wei"
        },
        {
          "name": "Zenglin Shi"
        },
        {
          "name": "Meng Wang"
        }
      ],
      "abstract": "Existing multimodal Retrieval-Augmented Generation (RAG) methods for visually rich documents (VRD) are often biased towards retrieving salient knowledge(e.g., prominent text and visual elements), while largely neglecting the critical fine-print knowledge(e.g., small text, contextual details). This limitation leads to incomplete retrieval and compromises the generator's ability to produce accurate and comprehensive answers. To bridge this gap, we propose HKRAG, a new holistic RAG framework designed to explicitly capture and integrate both knowledge types. Our framework features two key components: (1) a Hybrid Masking-based Holistic Retriever that employs explicit masking strategies to separately model salient and fine-print knowledge, ensuring a query-relevant holistic information retrieval; and (2) an Uncertainty-guided Agentic Generator that dynamically assesses the uncertainty of initial answers and actively decides how to integrate the two distinct knowledge streams for optimal response generation. Extensive experiments on open-domain visual question answering benchmarks show that HKRAG consistently outperforms existing methods in both zero-shot and supervised settings, demonstrating the critical importance of holistic knowledge retrieval for VRD understanding.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2025-11-25T11:59:52+00:00",
      "updated": "2025-11-25T11:59:52+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.20227v1",
      "file": "papers/2511.20227v1.pdf"
    },
    {
      "arxiv_id": "2511.19998v2",
      "title": "REWA: A General Theory of Witness-Based Similarity",
      "authors": [
        {
          "name": "Nikit Phadke"
        }
      ],
      "abstract": "We present a universal framework for similarity-preserving encodings that subsumes all discrete, continuous, algebraic, and learned similarity methods under a single theoretical umbrella. By formulating similarity as functional witness projection over monoids, we prove that \\[ O\\!\\left(\\frac{1}{Δ^{2}}\\log N\\right) \\] encoding complexity with ranking preservation holds for arbitrary algebraic structures. This unification reveals that Bloom filters, Locality Sensitive Hashing (LSH), Count-Min sketches, Random Fourier Features, and Transformer attention kernels are instances of the same underlying mechanism. We provide complete proofs with explicit constants under 4-wise independent hashing, handle heavy-tailed witnesses via normalization and clipping, and prove \\[ O(\\log N) \\] complexity for all major similarity methods from 1970-2024. We give explicit constructions for Boolean, Natural, Real, Tropical, and Product monoids, prove tight concentration bounds, and demonstrate compositional properties enabling multi-primitive similarity systems.",
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.DS",
        "cs.IR"
      ],
      "published": "2025-11-25T07:04:44+00:00",
      "updated": "2025-11-28T07:09:03+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.19998v2",
      "file": "papers/2511.19998v2.pdf"
    },
    {
      "arxiv_id": "2511.19987v1",
      "title": "$\\text{R}^2\\text{R}$: A Route-to-Rerank Post-Training Framework for Multi-Domain Decoder-Only Rerankers",
      "authors": [
        {
          "name": "Xinyu Wang"
        },
        {
          "name": "Hanwei Wu"
        },
        {
          "name": "Qingchen Hu"
        },
        {
          "name": "Zhenghan Tai"
        },
        {
          "name": "Jingrui Tian"
        },
        {
          "name": "Lei Ding"
        },
        {
          "name": "Jijun Chi"
        },
        {
          "name": "Hailin He"
        },
        {
          "name": "Tung Sum Thomas Kwok"
        },
        {
          "name": "Yufei Cui"
        },
        {
          "name": "Sicheng Lyu"
        },
        {
          "name": "Muzhi Li"
        },
        {
          "name": "Mingze Li"
        },
        {
          "name": "Xinyue Yu"
        },
        {
          "name": "Ling Zhou"
        },
        {
          "name": "Peng Lu"
        }
      ],
      "abstract": "Decoder-only rerankers are central to Retrieval-Augmented Generation (RAG). However, generalist models miss domain-specific nuances in high-stakes fields like finance and law, and naive fine-tuning causes surface-form overfitting and catastrophic forgetting. To address this challenge, we introduce R2R, a domain-aware framework that combines dynamic expert routing with a two-stage training strategy, Entity Abstraction for Generalization (EAG). EAG introduces a counter-shortcut mechanism by masking the most predictive surface cues, forcing the reranker to learn domain-invariant relevance patterns rather than memorizing dataset-specific entities. To efficiently activate domain experts, R2R employs a lightweight Latent Semantic Router that probes internal representations from the frozen backbone decoder to select the optimal LoRA expert per query. Extensive experiments across different reranker backbones and diverse domains (legal, medical, and financial) demonstrate that R2R consistently surpasses generalist and single-domain fine-tuned baselines. Our results confirm that R2R is a model-agnostic and modular approach to domain specialization with strong cross-domain robustness.",
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.IR"
      ],
      "published": "2025-11-25T06:54:51+00:00",
      "updated": "2025-11-25T06:54:51+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.19987v1",
      "file": "papers/2511.19987v1.pdf"
    },
    {
      "arxiv_id": "2511.19349v1",
      "title": "Revisiting Feedback Models for HyDE",
      "authors": [
        {
          "name": "Nour Jedidi"
        },
        {
          "name": "Jimmy Lin"
        }
      ],
      "abstract": "Recent approaches that leverage large language models (LLMs) for pseudo-relevance feedback (PRF) have generally not utilized well-established feedback models like Rocchio and RM3 when expanding queries for sparse retrievers like BM25. Instead, they often opt for a simple string concatenation of the query and LLM-generated expansion content. But is this optimal? To answer this question, we revisit and systematically evaluate traditional feedback models in the context of HyDE, a popular method that enriches query representations with LLM-generated hypothetical answer documents. Our experiments show that HyDE's effectiveness can be substantially improved when leveraging feedback algorithms such as Rocchio to extract and weight expansion terms, providing a simple way to further enhance the accuracy of LLM-based PRF methods.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2025-11-24T17:50:18+00:00",
      "updated": "2025-11-24T17:50:18+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.19349v1",
      "file": "papers/2511.19349v1.pdf"
    },
    {
      "arxiv_id": "2511.19325v1",
      "title": "Generative Query Expansion with Multilingual LLMs for Cross-Lingual Information Retrieval",
      "authors": [
        {
          "name": "Olivia Macmillan-Scott"
        },
        {
          "name": "Roksana Goworek"
        },
        {
          "name": "Eda B. Özyiğit"
        }
      ],
      "abstract": "Query expansion is the reformulation of a user query by adding semantically related information, and is an essential component of monolingual and cross-lingual information retrieval used to ensure that relevant documents are not missed. Recently, multilingual large language models (mLLMs) have shifted query expansion from semantic augmentation with synonyms and related words to pseudo-document generation. Pseudo-documents both introduce additional relevant terms and bridge the gap between short queries and long documents, which is particularly beneficial in dense retrieval. This study evaluates recent mLLMs and fine-tuned variants across several generative expansion strategies to identify factors that drive cross-lingual retrieval performance. Results show that query length largely determines which prompting technique is effective, and that more elaborate prompts often do not yield further gains. Substantial linguistic disparities persist: cross-lingual query expansion can produce the largest improvements for languages with the weakest baselines, yet retrieval is especially poor between languages written in different scripts. Fine-tuning is found to lead to performance gains only when the training and test data are of similar format. These outcomes underline the need for more balanced multilingual and cross-lingual training and evaluation resources.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "published": "2025-11-24T17:18:25+00:00",
      "updated": "2025-11-24T17:18:25+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.19325v1",
      "file": "papers/2511.19325v1.pdf"
    },
    {
      "arxiv_id": "2511.19324v1",
      "title": "What Drives Cross-lingual Ranking? Retrieval Approaches with Multilingual Language Models",
      "authors": [
        {
          "name": "Roksana Goworek"
        },
        {
          "name": "Olivia Macmillan-Scott"
        },
        {
          "name": "Eda B. Özyiğit"
        }
      ],
      "abstract": "Cross-lingual information retrieval (CLIR) enables access to multilingual knowledge but remains challenging due to disparities in resources, scripts, and weak cross-lingual semantic alignment in embedding models. Existing pipelines often rely on translation and monolingual retrieval heuristics, which add computational overhead and noise, degrading performance. This work systematically evaluates four intervention types, namely document translation, multilingual dense retrieval with pretrained encoders, contrastive learning at word, phrase, and query-document levels, and cross-encoder re-ranking, across three benchmark datasets. We find that dense retrieval models trained specifically for CLIR consistently outperform lexical matching methods and derive little benefit from document translation. Contrastive learning mitigates language biases and yields substantial improvements for encoders with weak initial alignment, and re-ranking can be effective, but depends on the quality of the cross-encoder training data. Although high-resource languages still dominate overall performance, gains over lexical and document-translated baselines are most pronounced for low-resource and cross-script pairs. These findings indicate that cross-lingual search systems should prioritise semantic multilingual embeddings and targeted learning-based alignment over translation-based pipelines, particularly for cross-script and under-resourced languages.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "published": "2025-11-24T17:17:40+00:00",
      "updated": "2025-11-24T17:17:40+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.19324v1",
      "file": "papers/2511.19324v1.pdf"
    },
    {
      "arxiv_id": "2511.18354v1",
      "title": "Toward an AI-Native Internet: Rethinking the Web Architecture for Semantic Retrieval",
      "authors": [
        {
          "name": "Muhammad Bilal"
        },
        {
          "name": "Zafar Qazi"
        },
        {
          "name": "Marco Canini"
        }
      ],
      "abstract": "The rise of Generative AI Search is fundamentally transforming how users and intelligent systems interact with the Internet. LLMs increasingly act as intermediaries between humans and web information. Yet the web remains optimized for human browsing rather than AI-driven semantic retrieval, resulting in wasted network bandwidth, lower information quality, and unnecessary complexity for developers. We introduce the concept of an AI-Native Internet, a web architecture in which servers expose semantically relevant information chunks rather than full documents, supported by a Web-native semantic resolver that allows AI applications to discover relevant information sources before retrieving fine-grained chunks. Through motivational experiments, we quantify the inefficiencies of current HTML-based retrieval, and outline architectural directions and open challenges for evolving today's document-centric web into an AI-oriented substrate that better supports semantic access to web content.",
      "primary_category": "cs.NI",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.IR"
      ],
      "published": "2025-11-23T09:01:22+00:00",
      "updated": "2025-11-23T09:01:22+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.18354v1",
      "file": "papers/2511.18354v1.pdf"
    },
    {
      "arxiv_id": "2511.18313v1",
      "title": "Path-Constrained Retrieval: A Structural Approach to Reliable LLM Agent Reasoning Through Graph-Scoped Semantic Search",
      "authors": [
        {
          "name": "Joseph Oladokun"
        }
      ],
      "abstract": "Large Language Model agents often retrieve context from knowledge bases that lack structural consistency with the agent's current reasoning state, leading to incoherent reasoning chains. We introduce Path-Constrained Retrieval (PCR), a retrieval method that combines structural graph constraints with semantic search to ensure retrieved information maintains logical relationships within a knowledge graph. PCR restricts the search space to nodes reachable from an anchor node, preventing retrieval of structurally disconnected information that may lead to inconsistent reasoning. We evaluate PCR on PathRAG-6, a benchmark spanning six domains with 180 nodes and 360 edges. Our results show that PCR achieves full structural consistency compared to 24-32 percent in baseline methods, while maintaining strong relevance scores. On the technology domain, PCR obtains full relevance at rank 10 with full structural consistency, significantly outperforming vector search and hybrid retrieval. PCR reduces the average graph distance of retrieved context by 78 percent compared to baselines, demonstrating retrieval of more structurally consistent information. These findings suggest that path-constrained retrieval is an effective approach for improving the reliability and coherence of LLM agent reasoning systems.",
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.DB",
        "cs.IR",
        "cs.LG"
      ],
      "published": "2025-11-23T06:50:01+00:00",
      "updated": "2025-11-23T06:50:01+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.18313v1",
      "file": "papers/2511.18313v1.pdf"
    },
    {
      "arxiv_id": "2511.17908v1",
      "title": "Principled Context Engineering for RAG: Statistical Guarantees via Conformal Prediction",
      "authors": [
        {
          "name": "Debashish Chakraborty"
        },
        {
          "name": "Eugene Yang"
        },
        {
          "name": "Daniel Khashabi"
        },
        {
          "name": "Dawn Lawrie"
        },
        {
          "name": "Kevin Duh"
        }
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) enhances factual grounding in large language models (LLMs) by incorporating retrieved evidence, but LLM accuracy declines when long or noisy contexts exceed the model's effective attention span. Existing pre-generation filters rely on heuristics or uncalibrated LLM confidence scores, offering no statistical control over retained evidence. We evaluate and demonstrate context engineering through conformal prediction, a coverage-controlled filtering framework that removes irrelevant content while preserving recall of supporting evidence. Using both embedding- and LLM-based scoring functions, we test this approach on the NeuCLIR and RAGTIME collections. Conformal filtering consistently meets its target coverage, ensuring that a specified fraction of relevant snippets are retained, and reduces retained context by 2-3x relative to unfiltered retrieval. On NeuCLIR, downstream factual accuracy measured by ARGUE F1 improves under strict filtering and remains stable at moderate coverage, indicating that most discarded material is redundant or irrelevant. These results demonstrate that conformal prediction enables reliable, coverage-controlled context reduction in RAG, offering a model-agnostic and principled approach to context engineering.",
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "published": "2025-11-22T04:17:06+00:00",
      "updated": "2025-11-22T04:17:06+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.17908v1",
      "file": "papers/2511.17908v1.pdf"
    },
    {
      "arxiv_id": "2511.17255v1",
      "title": "A Little More Like This: Text-to-Image Retrieval with Vision-Language Models Using Relevance Feedback",
      "authors": [
        {
          "name": "Bulat Khaertdinov"
        },
        {
          "name": "Mirela Popa"
        },
        {
          "name": "Nava Tintarev"
        }
      ],
      "abstract": "Large vision-language models (VLMs) enable intuitive visual search using natural language queries. However, improving their performance often requires fine-tuning and scaling to larger model variants. In this work, we propose a mechanism inspired by traditional text-based search to improve retrieval performance at inference time: relevance feedback. While relevance feedback can serve as an alternative to fine-tuning, its model-agnostic design also enables use with fine-tuned VLMs. Specifically, we introduce and evaluate four feedback strategies for VLM-based retrieval. First, we revise classical pseudo-relevance feedback (PRF), which refines query embeddings based on top-ranked results. To address its limitations, we propose generative relevance feedback (GRF), which uses synthetic captions for query refinement. Furthermore, we introduce an attentive feedback summarizer (AFS), a custom transformer-based model that integrates multimodal fine-grained features from relevant items. Finally, we simulate explicit feedback using ground-truth captions as an upper-bound baseline. Experiments on Flickr30k and COCO with the VLM backbones show that GRF, AFS, and explicit feedback improve retrieval performance by 3-5% in MRR@5 for smaller VLMs, and 1-3% for larger ones, compared to retrieval with no feedback. Moreover, AFS, similarly to explicit feedback, mitigates query drift and is more robust than GRF in iterative, multi-turn retrieval settings. Our findings demonstrate that relevance feedback can consistently enhance retrieval across VLMs and open up opportunities for interactive and adaptive visual search.",
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.IR"
      ],
      "published": "2025-11-21T14:01:36+00:00",
      "updated": "2025-11-21T14:01:36+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.17255v1",
      "file": "papers/2511.17255v1.pdf"
    },
    {
      "arxiv_id": "2511.17044v1",
      "title": "Parametric Retrieval-Augmented Generation using Latent Routing of LoRA Adapters",
      "authors": [
        {
          "name": "Zhan Su"
        },
        {
          "name": "Fengran Mo"
        },
        {
          "name": "Jian-yun Nie"
        }
      ],
      "abstract": "Parametric Retrieval-Augmented Generation (PRAG) is a novel RAG paradigm that integrates external knowledge directly into a Large Language Model (LLM) by parameterizing documents using LoRA adapters, demonstrating reduced inference costs compared to traditional RAG approaches. However, current PRAG approaches adopt a \\textbf{one-to-one} document encoding scheme, using a dedicated LoRA adapter for each individual document. This scheme introduces two major limitations: First, it leads to data scarcity, as the training datasets for individual LoRA adapters are limited. Second, it incurs high overhead during inference, requiring the merging of LLM weights with a new LoRA adapter for every candidate passage, which is computationally inefficient. To overcome these challenges, we propose a novel paradigm for encoding passages in PRAG that utilizes a latent routing encoding process (Poly-PRAG). During offline encoding, we treat the encoding of a set of documents as a multi-task learning process, where each passage is assigned a unique task identifier. By employing a routing function, we use a small set of latent LoRA adapters to encode the entire passage space. During online inference, this routing function selectively activates a subset of latent experts based on the input query. We conduct comprehensive evaluations of Poly-PRAG across multiple knowledge-intensive NLP tasks. Our extensive experiments demonstrate the effectiveness of the proposed method, achieving state-of-the-art results on four distinct datasets.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2025-11-21T08:44:21+00:00",
      "updated": "2025-11-21T08:44:21+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.17044v1",
      "file": "papers/2511.17044v1.pdf"
    },
    {
      "arxiv_id": "2511.16921v1",
      "title": "δ-EMG: A Monotonic Graph Index for Approximate Nearest Neighbor Search",
      "authors": [
        {
          "name": "Liming Xiang"
        },
        {
          "name": "Jing Feng"
        },
        {
          "name": "Ziqi Yin"
        },
        {
          "name": "Zijian Li"
        },
        {
          "name": "Daihao Xue"
        },
        {
          "name": "Hongchao Qin"
        },
        {
          "name": "Ronghua Li"
        },
        {
          "name": "Guoren Wang"
        }
      ],
      "abstract": "Approximate nearest neighbor (ANN) search in high-dimensional spaces is a foundational component of many modern retrieval and recommendation systems. Currently, almost all algorithms follow an $ε$-Recall-Bounded principle when comparing performance: they require the ANN search results to achieve a recall of more than $1-ε$ and then compare query-per-second (QPS) performance. However, this approach only accounts for the recall of true positive results and does not provide guarantees on the deviation of incorrect results. To address this limitation, we focus on an Error-Bounded ANN method, which ensures that the returned results are a $(1/δ)$-approximation of the true values. Our approach adopts a graph-based framework. To enable Error-Bounded ANN search, we propose a $δ$-EMG (Error-bounded Monotonic Graph), which, for the first time, provides a provable approximation for arbitrary queries. By enforcing a $δ$-monotonic geometric constraint during graph construction, $δ$-EMG ensures that any greedy search converges to a $(1/δ)$-approximate neighbor without backtracking. Building on this foundation, we design an error-bounded top-$k$ ANN search algorithm that adaptively controls approximation accuracy during query time. To make the framework practical at scale, we introduce $δ$-EMQG (Error-bounded Monotonic Quantized Graph), a localized and degree-balanced variant with near-linear construction complexity. We further integrate vector quantization to accelerate distance computation while preserving theoretical guarantees. Extensive experiments on the ANN-Benchmarks dataset demonstrate the effectiveness of our approach. Under a recall requirement of 0.99, our algorithm achieves 19,000 QPS on the SIFT1M dataset, outperforming other methods by more than 40\\%.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2025-11-21T03:20:54+00:00",
      "updated": "2025-11-21T03:20:54+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.16921v1",
      "file": "papers/2511.16921v1.pdf"
    },
    {
      "arxiv_id": "2511.16576v1",
      "title": "PolyMinHash: Efficient Area-Based MinHashing of Polygons for Approximate Nearest Neighbor Search",
      "authors": [
        {
          "name": "Alima Subedi"
        },
        {
          "name": "Sankalpa Pokharel"
        },
        {
          "name": "Satish Puri"
        }
      ],
      "abstract": "Similarity searches are a critical task in data mining. As data sets grow larger, exact nearest neighbor searches quickly become unfeasible, leading to the adoption of approximate nearest neighbor (ANN) searches. ANN has been studied for text data, images, and trajectories. However, there has been little effort to develop ANN systems for polygons in spatial database systems and geographic information systems. We present PolyMinHash, a system for approximate polygon similarity search that adapts MinHashing into a novel 2D polygon-hashing scheme to generate short, similarity-preserving signatures of input polygons. Minhash is generated by counting the number of randomly sampled points needed before the sampled point lands within the polygon's interior area, yielding hash values that preserve area-based Jaccard similarity. We present the tradeoff between search accuracy and runtime of our PolyMinHash system. Our hashing mechanism reduces the number of candidates to be processed in the query refinement phase by up to 98% compared to the number of candidates processed by the brute-force algorithm.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2025-11-20T17:31:14+00:00",
      "updated": "2025-11-20T17:31:14+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.16576v1",
      "file": "papers/2511.16576v1.pdf"
    },
    {
      "arxiv_id": "2511.16528v1",
      "title": "TurkColBERT: A Benchmark of Dense and Late-Interaction Models for Turkish Information Retrieval",
      "authors": [
        {
          "name": "Özay Ezerceli"
        },
        {
          "name": "Mahmoud El Hussieni"
        },
        {
          "name": "Selva Taş"
        },
        {
          "name": "Reyhan Bayraktar"
        },
        {
          "name": "Fatma Betül Terzioğlu"
        },
        {
          "name": "Yusuf Çelebi"
        },
        {
          "name": "Yağız Asker"
        }
      ],
      "abstract": "Neural information retrieval systems excel in high-resource languages but remain underexplored for morphologically rich, lower-resource languages such as Turkish. Dense bi-encoders currently dominate Turkish IR, yet late-interaction models -- which retain token-level representations for fine-grained matching -- have not been systematically evaluated. We introduce TurkColBERT, the first comprehensive benchmark comparing dense encoders and late-interaction models for Turkish retrieval. Our two-stage adaptation pipeline fine-tunes English and multilingual encoders on Turkish NLI/STS tasks, then converts them into ColBERT-style retrievers using PyLate trained on MS MARCO-TR. We evaluate 10 models across five Turkish BEIR datasets covering scientific, financial, and argumentative domains. Results show strong parameter efficiency: the 1.0M-parameter colbert-hash-nano-tr is 600$\\times$ smaller than the 600M turkish-e5-large dense encoder while preserving over 71\\% of its average mAP. Late-interaction models that are 3--5$\\times$ smaller than dense encoders significantly outperform them; ColmmBERT-base-TR yields up to +13.8\\% mAP on domain-specific tasks. For production-readiness, we compare indexing algorithms: MUVERA+Rerank is 3.33$\\times$ faster than PLAID and offers +1.7\\% relative mAP gain. This enables low-latency retrieval, with ColmmBERT-base-TR achieving 0.54 ms query times under MUVERA. We release all checkpoints, configs, and evaluation scripts. Limitations include reliance on moderately sized datasets ($\\leq$50K documents) and translated benchmarks, which may not fully reflect real-world Turkish retrieval conditions; larger-scale MUVERA evaluations remain necessary.",
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "published": "2025-11-20T16:42:21+00:00",
      "updated": "2025-11-20T16:42:21+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.16528v1",
      "file": "papers/2511.16528v1.pdf"
    },
    {
      "arxiv_id": "2511.16326v1",
      "title": "ARK: Answer-Centric Retriever Tuning via KG-augmented Curriculum Learning",
      "authors": [
        {
          "name": "Jiawei Zhou"
        },
        {
          "name": "Hang Ding"
        },
        {
          "name": "Haiyun Jiang"
        }
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) has emerged as a powerful framework for knowledge-intensive tasks, yet its effectiveness in long-context scenarios is often bottlenecked by the retriever's inability to distinguish sparse yet crucial evidence. Standard retrievers, optimized for query-document similarity, frequently fail to align with the downstream goal of generating a precise answer. To bridge this gap, we propose a novel fine-tuning framework that optimizes the retriever for Answer Alignment. Specifically, we first identify high-quality positive chunks by evaluating their sufficiency to generate the correct answer. We then employ a curriculum-based contrastive learning scheme to fine-tune the retriever. This curriculum leverages LLM-constructed Knowledge Graphs (KGs) to generate augmented queries, which in turn mine progressively challenging hard negatives. This process trains the retriever to distinguish the answer-sufficient positive chunks from these nuanced distractors, enhancing its generalization. Extensive experiments on 10 datasets from the Ultradomain and LongBench benchmarks demonstrate that our fine-tuned retriever achieves state-of-the-art performance, improving 14.5% over the base model without substantial architectural modifications and maintaining strong efficiency for long-context RAG. Our work presents a robust and effective methodology for building truly answer-centric retrievers.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2025-11-20T13:05:09+00:00",
      "updated": "2025-11-20T13:05:09+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.16326v1",
      "file": "papers/2511.16326v1.pdf"
    },
    {
      "arxiv_id": "2511.16106v1",
      "title": "Incorporating Token Importance in Multi-Vector Retrieval",
      "authors": [
        {
          "name": "Archish S"
        },
        {
          "name": "Ankit Garg"
        },
        {
          "name": "Kirankumar Shiragur"
        },
        {
          "name": "Neeraj Kayal"
        }
      ],
      "abstract": "ColBERT introduced a late interaction mechanism that independently encodes queries and documents using BERT, and computes similarity via fine-grained interactions over token-level vector representations. This design enables expressive matching while allowing efficient computation of scores, as the multi-vector document representations could be pre-computed offline. ColBERT models distance using a Chamfer-style function: for each query token, it selects the closest document token and sums these distances across all query tokens.\n  In our work, we explore enhancements to the Chamfer distance function by computing a weighted sum over query token contributions, where weights reflect the token importance. Empirically, we show that this simple extension, requiring only token-weight training while keeping the multi-vector representations fixed, further enhances the expressiveness of late interaction multi-vector mechanism. In particular, on the BEIR benchmark, our method achieves an average improvement of 1.28\\% in Recall@10 in the zero-shot setting using IDF-based weights, and 3.66\\% through few-shot fine-tuning.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2025-11-20T06:58:31+00:00",
      "updated": "2025-11-20T06:58:31+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.16106v1",
      "file": "papers/2511.16106v1.pdf"
    },
    {
      "arxiv_id": "2511.15996v1",
      "title": "QueryGym: A Toolkit for Reproducible LLM-Based Query Reformulation",
      "authors": [
        {
          "name": "Amin Bigdeli"
        },
        {
          "name": "Radin Hamidi Rad"
        },
        {
          "name": "Mert Incesu"
        },
        {
          "name": "Negar Arabzadeh"
        },
        {
          "name": "Charles L. A. Clarke"
        },
        {
          "name": "Ebrahim Bagheri"
        }
      ],
      "abstract": "We present QueryGym, a lightweight, extensible Python toolkit that supports large language model (LLM)-based query reformulation. This is an important tool development since recent work on llm-based query reformulation has shown notable increase in retrieval effectiveness. However, while different authors have sporadically shared the implementation of their methods, there is no unified toolkit that provides a consistent implementation of such methods, which hinders fair comparison, rapid experimentation, consistent benchmarking and reliable deployment. QueryGym addresses this gap by providing a unified framework for implementing, executing, and comparing llm-based reformulation methods. The toolkit offers: (1) a Python API for applying diverse LLM-based methods, (2) a retrieval-agnostic interface supporting integration with backends such as Pyserini and PyTerrier, (3) a centralized prompt management system with versioning and metadata tracking, (4) built-in support for benchmarks like BEIR and MS MARCO, and (5) a completely open-source extensible implementation available to all researchers. QueryGym is publicly available at https://github.com/radinhamidi/QueryGym.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.CL"
      ],
      "published": "2025-11-20T02:45:50+00:00",
      "updated": "2025-11-20T02:45:50+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.15996v1",
      "file": "papers/2511.15996v1.pdf"
    },
    {
      "arxiv_id": "2511.15443v1",
      "title": "CroPS: Improving Dense Retrieval with Cross-Perspective Positive Samples in Short-Video Search",
      "authors": [
        {
          "name": "Ao Xie"
        },
        {
          "name": "Jiahui Chen"
        },
        {
          "name": "Quanzhi Zhu"
        },
        {
          "name": "Xiaoze Jiang"
        },
        {
          "name": "Zhiheng Qin"
        },
        {
          "name": "Enyun Yu"
        },
        {
          "name": "Han Li"
        }
      ],
      "abstract": "Dense retrieval has become a foundational paradigm in modern search systems, especially on short-video platforms. However, most industrial systems adopt a self-reinforcing training pipeline that relies on historically exposed user interactions for supervision. This paradigm inevitably leads to a filter bubble effect, where potentially relevant but previously unseen content is excluded from the training signal, biasing the model toward narrow and conservative retrieval. In this paper, we present CroPS (Cross-Perspective Positive Samples), a novel retrieval data engine designed to alleviate this problem by introducing diverse and semantically meaningful positive examples from multiple perspectives. CroPS enhances training with positive signals derived from user query reformulation behavior (query-level), engagement data in recommendation streams (system-level), and world knowledge synthesized by large language models (knowledge-level). To effectively utilize these heterogeneous signals, we introduce a Hierarchical Label Assignment (HLA) strategy and a corresponding H-InfoNCE loss that together enable fine-grained, relevance-aware optimization. Extensive experiments conducted on Kuaishou Search, a large-scale commercial short-video search platform, demonstrate that CroPS significantly outperforms strong baselines both offline and in live A/B tests, achieving superior retrieval performance and reducing query reformulation rates. CroPS is now fully deployed in Kuaishou Search, serving hundreds of millions of users daily.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.CL"
      ],
      "published": "2025-11-19T13:57:40+00:00",
      "updated": "2025-11-19T13:57:40+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.15443v1",
      "file": "papers/2511.15443v1.pdf"
    },
    {
      "arxiv_id": "2511.15435v1",
      "title": "HV-Attack: Hierarchical Visual Attack for Multimodal Retrieval Augmented Generation",
      "authors": [
        {
          "name": "Linyin Luo"
        },
        {
          "name": "Yujuan Ding"
        },
        {
          "name": "Yunshan Ma"
        },
        {
          "name": "Wenqi Fan"
        },
        {
          "name": "Hanjiang Lai"
        }
      ],
      "abstract": "Advanced multimodal Retrieval-Augmented Generation (MRAG) techniques have been widely applied to enhance the capabilities of Large Multimodal Models (LMMs), but they also bring along novel safety issues. Existing adversarial research has revealed the vulnerability of MRAG systems to knowledge poisoning attacks, which fool the retriever into recalling injected poisoned contents. However, our work considers a different setting: visual attack of MRAG by solely adding imperceptible perturbations at the image inputs of users, without manipulating any other components. This is challenging due to the robustness of fine-tuned retrievers and large-scale generators, and the effect of visual perturbation may be further weakened by propagation through the RAG chain. We propose a novel Hierarchical Visual Attack that misaligns and disrupts the two inputs (the multimodal query and the augmented knowledge) of MRAG's generator to confuse its generation. We further design a hierarchical two-stage strategy to obtain misaligned augmented knowledge. We disrupt the image input of the retriever to make it recall irrelevant knowledge from the original database, by optimizing the perturbation which first breaks the cross-modal alignment and then disrupts the multimodal semantic alignment. We conduct extensive experiments on two widely-used MRAG datasets: OK-VQA and InfoSeek. We use CLIP-based retrievers and two LMMs BLIP-2 and LLaVA as generators. Results demonstrate the effectiveness of our visual attack on MRAG through the significant decrease in both retrieval and generation performance.",
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.IR"
      ],
      "published": "2025-11-19T13:45:24+00:00",
      "updated": "2025-11-19T13:45:24+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.15435v1",
      "file": "papers/2511.15435v1.pdf"
    },
    {
      "arxiv_id": "2511.15383v1",
      "title": "A Compliance-Preserving Retrieval System for Aircraft MRO Task Search",
      "authors": [
        {
          "name": "Byungho Jo"
        }
      ],
      "abstract": "Aircraft Maintenance Technicians (AMTs) spend up to 30% of work time searching manuals, a documented efficiency bottleneck in MRO operations where every procedure must be traceable to certified sources. We present a compliance-preserving retrieval system that adapts LLM reranking and semantic search to aviation MRO environments by operating alongside, rather than replacing, certified legacy viewers. The system constructs revision-robust embeddings from ATA chapter hierarchies and uses vision-language parsing to structure certified content, allowing technicians to preview ranked tasks and access verified procedures in existing viewers. Evaluation on 49k synthetic queries achieves >90% retrieval accuracy, while bilingual controlled studies with 10 licensed AMTs demonstrate 90.9% top-10 success rate and 95% reduction in lookup time, from 6-15 minutes to 18 seconds per task. These gains provide concrete evidence that semantic retrieval can operate within strict regulatory constraints and meaningfully reduce operational workload in real-world multilingual MRO workflows.",
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.ET",
        "cs.IR"
      ],
      "published": "2025-11-19T12:25:40+00:00",
      "updated": "2025-11-19T12:25:40+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.15383v1",
      "file": "papers/2511.15383v1.pdf"
    },
    {
      "arxiv_id": "2511.15141v1",
      "title": "ItemRAG: Item-Based Retrieval-Augmented Generation for LLM-Based Recommendation",
      "authors": [
        {
          "name": "Sunwoo Kim"
        },
        {
          "name": "Geon Lee"
        },
        {
          "name": "Kyungho Kim"
        },
        {
          "name": "Jaemin Yoo"
        },
        {
          "name": "Kijung Shin"
        }
      ],
      "abstract": "Recently, large language models (LLMs) have been widely used as recommender systems, owing to their strong reasoning capability and their effectiveness in handling cold-start items. To better adapt LLMs for recommendation, retrieval-augmented generation (RAG) has been incorporated. Most existing RAG methods are user-based, retrieving purchase patterns of users similar to the target user and providing them to the LLM. In this work, we propose ItemRAG, an item-based RAG method for LLM-based recommendation that retrieves relevant items (rather than users) from item-item co-purchase histories. ItemRAG helps LLMs capture co-purchase patterns among items, which are beneficial for recommendations. Especially, our retrieval strategy incorporates semantically similar items to better handle cold-start items and uses co-purchase frequencies to improve the relevance of the retrieved items. Through extensive experiments, we demonstrate that ItemRAG consistently (1) improves the zero-shot LLM-based recommender by up to 43% in Hit-Ratio-1 and (2) outperforms user-based RAG baselines under both standard and cold-start item recommendation settings.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "published": "2025-11-19T05:39:14+00:00",
      "updated": "2025-11-19T05:39:14+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.15141v1",
      "file": "papers/2511.15141v1.pdf"
    },
    {
      "arxiv_id": "2511.15061v1",
      "title": "Beyond GeneGPT: A Multi-Agent Architecture with Open-Source LLMs for Enhanced Genomic Question Answering",
      "authors": [
        {
          "name": "Haodong Chen"
        },
        {
          "name": "Guido Zuccon"
        },
        {
          "name": "Teerapong Leelanupab"
        }
      ],
      "abstract": "Genomic question answering often requires complex reasoning and integration across diverse biomedical sources. GeneGPT addressed this challenge by combining domain-specific APIs with OpenAI's code-davinci-002 large language model to enable natural language interaction with genomic databases. However, its reliance on a proprietary model limits scalability, increases operational costs, and raises concerns about data privacy and generalization.\n  In this work, we revisit and reproduce GeneGPT in a pilot study using open source models, including Llama 3.1, Qwen2.5, and Qwen2.5 Coder, within a monolithic architecture; this allows us to identify the limitations of this approach. Building on this foundation, we then develop OpenBioLLM, a modular multi-agent framework that extends GeneGPT by introducing agent specialization for tool routing, query generation, and response validation. This enables coordinated reasoning and role-based task execution.\n  OpenBioLLM matches or outperforms GeneGPT on over 90% of the benchmark tasks, achieving average scores of 0.849 on Gene-Turing and 0.830 on GeneHop, while using smaller open-source models without additional fine-tuning or tool-specific pretraining. OpenBioLLM's modular multi-agent design reduces latency by 40-50% across benchmark tasks, significantly improving efficiency without compromising model capability. The results of our comprehensive evaluation highlight the potential of open-source multi-agent systems for genomic question answering. Code and resources are available at https://github.com/ielab/OpenBioLLM.",
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "published": "2025-11-19T03:08:20+00:00",
      "updated": "2025-11-19T03:08:20+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.15061v1",
      "file": "papers/2511.15061v1.pdf"
    },
    {
      "arxiv_id": "2511.14881v1",
      "title": "SilverTorch: A Unified Model-based System to Democratize Large-Scale Recommendation on GPUs",
      "authors": [
        {
          "name": "Bi Xue"
        },
        {
          "name": "Hong Wu"
        },
        {
          "name": "Lei Chen"
        },
        {
          "name": "Chao Yang"
        },
        {
          "name": "Yiming Ma"
        },
        {
          "name": "Fei Ding"
        },
        {
          "name": "Zhen Wang"
        },
        {
          "name": "Liang Wang"
        },
        {
          "name": "Xiaoheng Mao"
        },
        {
          "name": "Ke Huang"
        },
        {
          "name": "Xialu Li"
        },
        {
          "name": "Peng Xia"
        },
        {
          "name": "Rui Jian"
        },
        {
          "name": "Yanli Zhao"
        },
        {
          "name": "Yanzun Huang"
        },
        {
          "name": "Yijie Deng"
        },
        {
          "name": "Harry Tran"
        },
        {
          "name": "Ryan Chang"
        },
        {
          "name": "Min Yu"
        },
        {
          "name": "Eric Dong"
        },
        {
          "name": "Jiazhou Wang"
        },
        {
          "name": "Qianqian Zhang"
        },
        {
          "name": "Keke Zhai"
        },
        {
          "name": "Hongzhang Yin"
        },
        {
          "name": "Pawel Garbacki"
        },
        {
          "name": "Zheng Fang"
        },
        {
          "name": "Yiyi Pan"
        },
        {
          "name": "Min Ni"
        },
        {
          "name": "Yang Liu"
        }
      ],
      "abstract": "Serving deep learning based recommendation models (DLRM) at scale is challenging. Existing systems rely on CPU-based ANN indexing and filtering services, suffering from non-negligible costs and forgoing joint optimization opportunities. Such inefficiency makes them difficult to support more complex model architectures, such as learned similarities and multi-task retrieval.\n  In this paper, we propose SilverTorch, a model-based system for serving recommendation models on GPUs. SilverTorch unifies model serving by replacing standalone indexing and filtering services with layers of served models. We propose a Bloom index algorithm on GPUs for feature filtering and a tensor-native fused Int8 ANN kernel on GPUs for nearest neighbor search. We further co-design the ANN search index and filtering index to reduce GPU memory utilization and eliminate unnecessary computation. Benefit from SilverTorch's serving paradigm, we introduce a OverArch scoring layer and a Value Model to aggregate results across multi-tasks. These advancements improve the accuracy for retrieval and enable future studies for serving more complex models. For ranking, SilverTorch's design accelerates item embedding calculation by caching the pre-calculated embeddings inside the serving model.\n  Our evaluation on the industry-scale datasets show that SilverTorch achieves up to 5.6x lower latency and 23.7x higher throughput compared to the state-of-the-art approaches. We also demonstrate that SilverTorch's solution is 13.35x more cost-efficient than CPU-based solution while improving accuracy via serving more complex models. SilverTorch serves over hundreds of models online across major products and recommends contents for billions of daily active users.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2025-11-18T20:00:19+00:00",
      "updated": "2025-11-18T20:00:19+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.14881v1",
      "file": "papers/2511.14881v1.pdf"
    },
    {
      "arxiv_id": "2511.14758v1",
      "title": "NeuCLIRBench: A Modern Evaluation Collection for Monolingual, Cross-Language, and Multilingual Information Retrieval",
      "authors": [
        {
          "name": "Dawn Lawrie"
        },
        {
          "name": "James Mayfield"
        },
        {
          "name": "Eugene Yang"
        },
        {
          "name": "Andrew Yates"
        },
        {
          "name": "Sean MacAvaney"
        },
        {
          "name": "Ronak Pradeep"
        },
        {
          "name": "Scott Miller"
        },
        {
          "name": "Paul McNamee"
        },
        {
          "name": "Luca Soldani"
        }
      ],
      "abstract": "To measure advances in retrieval, test collections with relevance judgments that can faithfully distinguish systems are required. This paper presents NeuCLIRBench, an evaluation collection for cross-language and multilingual retrieval. The collection consists of documents written natively in Chinese, Persian, and Russian, as well as those same documents machine translated into English. The collection supports several retrieval scenarios including: monolingual retrieval in English, Chinese, Persian, or Russian; cross-language retrieval with English as the query language and one of the other three languages as the document language; and multilingual retrieval, again with English as the query language and relevant documents in all three languages. NeuCLIRBench combines the TREC NeuCLIR track topics of 2022, 2023, and 2024. The 250,128 judgments across approximately 150 queries for the monolingual and cross-language tasks and 100 queries for multilingual retrieval provide strong statistical discriminatory power to distinguish retrieval approaches. A fusion baseline of strong neural retrieval systems is included with the collection so that developers of reranking algorithms are no longer reliant on BM25 as their first-stage retriever. NeuCLIRBench is publicly available.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2025-11-18T18:58:19+00:00",
      "updated": "2025-11-18T18:58:19+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.14758v1",
      "file": "papers/2511.14758v1.pdf"
    },
    {
      "arxiv_id": "2511.14531v1",
      "title": "LiveRAG: A diverse Q&A dataset with varying difficulty level for RAG evaluation",
      "authors": [
        {
          "name": "David Carmel"
        },
        {
          "name": "Simone Filice"
        },
        {
          "name": "Guy Horowitz"
        },
        {
          "name": "Yoelle Maarek"
        },
        {
          "name": "Alex Shtoff"
        },
        {
          "name": "Oren Somekh"
        },
        {
          "name": "Ran Tavory"
        }
      ],
      "abstract": "With Retrieval Augmented Generation (RAG) becoming more and more prominent in generative AI solutions, there is an emerging need for systematically evaluating their effectiveness. We introduce the LiveRAG benchmark, a publicly available dataset of 895 synthetic questions and answers designed to support systematic evaluation of RAG-based Q&A systems. This synthetic benchmark is derived from the one used during the SIGIR'2025 LiveRAG Challenge, where competitors were evaluated under strict time constraints. It is augmented with information that was not made available to competitors during the Challenge, such as the ground-truth answers, together with their associated supporting claims which were used for evaluating competitors' answers. In addition, each question is associated with estimated difficulty and discriminability scores, derived from applying an Item Response Theory model to competitors' responses. Our analysis highlights the benchmark's questions diversity, the wide range of their difficulty levels, and their usefulness in differentiating between system capabilities. The LiveRAG benchmark will hopefully help the community advance RAG research, conduct systematic evaluation, and develop more robust Q&A systems.",
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.IR"
      ],
      "published": "2025-11-18T14:34:35+00:00",
      "updated": "2025-11-18T14:34:35+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.14531v1",
      "file": "papers/2511.14531v1.pdf"
    },
    {
      "arxiv_id": "2511.14405v2",
      "title": "Jasper-Token-Compression-600M Technical Report",
      "authors": [
        {
          "name": "Dun Zhang"
        },
        {
          "name": "Ziyang Zeng"
        },
        {
          "name": "Yudong Zhou"
        },
        {
          "name": "Shuyang Lu"
        }
      ],
      "abstract": "This technical report presents the training methodology and evaluation results of the open-source Jasper-Token-Compression-600M model, released in November 2025. Building on previous distillation-based recipes from the English Stella and Jasper models, we successfully extend this approach to a bilingual (English and Chinese) domain, further enhancing model performance through the incorporation of contrastive learning. A key innovation of our model is the introduction of a one-dimensional convolution-based token compression module. We dynamically adjust the compression rate during training, enabling the model to learn more robust and efficient compressed text representations. By combining knowledge distillation with token compression techniques, we achieve significant improvements in both embedding quality and inference efficiency. Our model performs with higher efficiency than a traditional 0.6B model while achieving performance comparable to that of an 8B model. For more information on the model release, visit: https://huggingface.co/infgrad/Jasper-Token-Compression-600M.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2025-11-18T12:13:47+00:00",
      "updated": "2025-11-19T06:03:10+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.14405v2",
      "file": "papers/2511.14405v2.pdf"
    },
    {
      "arxiv_id": "2511.14130v1",
      "title": "PRISM: Prompt-Refined In-Context System Modelling for Financial Retrieval",
      "authors": [
        {
          "name": "Chun Chet Ng"
        },
        {
          "name": "Jia Yu Lim"
        },
        {
          "name": "Wei Zeng Low"
        }
      ],
      "abstract": "With the rapid progress of large language models (LLMs), financial information retrieval has become a critical industrial application. Extracting task-relevant information from lengthy financial filings is essential for both operational and analytical decision-making. The FinAgentBench dataset formalizes this problem through two tasks: document ranking and chunk ranking. We present PRISM, a training-free framework that integrates refined system prompting, in-context learning (ICL), and a lightweight multi-agent system. Each component is examined extensively to reveal their synergies: prompt engineering provides precise task instructions, ICL supplies semantically relevant few-shot examples, and the multi-agent system models coordinated scoring behaviour. Our best configuration achieves an NDCG@5 of 0.71818 on the restricted validation split. We further demonstrate that PRISM is feasible and robust for production-scale financial retrieval. Its modular, inference-only design makes it practical for real-world use cases. The source code is released at https://bit.ly/prism-ailens.",
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CE",
        "cs.CL",
        "cs.IR"
      ],
      "published": "2025-11-18T04:30:52+00:00",
      "updated": "2025-11-18T04:30:52+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.14130v1",
      "file": "papers/2511.14130v1.pdf"
    },
    {
      "arxiv_id": "2511.14096v1",
      "title": "NeuroPath: Neurobiology-Inspired Path Tracking and Reflection for Semantically Coherent Retrieval",
      "authors": [
        {
          "name": "Junchen Li"
        },
        {
          "name": "Rongzheng Wang"
        },
        {
          "name": "Yihong Huang"
        },
        {
          "name": "Qizhi Chen"
        },
        {
          "name": "Jiasheng Zhang"
        },
        {
          "name": "Shuang Liang"
        }
      ],
      "abstract": "Retrieval-augmented generation (RAG) greatly enhances large language models (LLMs) performance in knowledge-intensive tasks. However, naive RAG methods struggle with multi-hop question answering due to their limited capacity to capture complex dependencies across documents. Recent studies employ graph-based RAG to capture document connections. However, these approaches often result in a loss of semantic coherence and introduce irrelevant noise during node matching and subgraph construction. To address these limitations, we propose NeuroPath, an LLM-driven semantic path tracking RAG framework inspired by the path navigational planning of place cells in neurobiology. It consists of two steps: Dynamic Path Tracking and Post-retrieval Completion. Dynamic Path Tracking performs goal-directed semantic path tracking and pruning over the constructed knowledge graph (KG), improving noise reduction and semantic coherence. Post-retrieval Completion further reinforces these benefits by conducting second-stage retrieval using intermediate reasoning and the original query to refine the query goal and complete missing information in the reasoning path. NeuroPath surpasses current state-of-the-art baselines on three multi-hop QA datasets, achieving average improvements of 16.3% on recall@2 and 13.5% on recall@5 over advanced graph-based RAG methods. Moreover, compared to existing iter-based RAG methods, NeuroPath achieves higher accuracy and reduces token consumption by 22.8%. Finally, we demonstrate the robustness of NeuroPath across four smaller LLMs (Llama3.1, GLM4, Mistral0.3, and Gemma3), and further validate its scalability across tasks of varying complexity. Code is available at https://github.com/KennyCaty/NeuroPath.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "published": "2025-11-18T03:28:23+00:00",
      "updated": "2025-11-18T03:28:23+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.14096v1",
      "file": "papers/2511.14096v1.pdf"
    },
    {
      "arxiv_id": "2511.13885v1",
      "title": "TaoSearchEmb: A Multi-Objective Reinforcement Learning Framework for Dense Retrieval in Taobao Search",
      "authors": [
        {
          "name": "Xingxian Liu"
        },
        {
          "name": "Dongshuai Li"
        },
        {
          "name": "Tao Wen"
        },
        {
          "name": "Jiahui Wan"
        },
        {
          "name": "Gui Ling"
        },
        {
          "name": "Fuyu Lv"
        },
        {
          "name": "Dan Ou"
        },
        {
          "name": "Haihong Tang"
        }
      ],
      "abstract": "Dense retrieval, as the core component of e-commerce search engines, maps user queries and items into a unified semantic space through pre-trained embedding models to enable large-scale real-time semantic retrieval. Despite the rapid advancement of LLMs gradually replacing traditional BERT architectures for embedding, their training paradigms still adhere to BERT-like supervised fine-tuning and hard negative mining strategies. This approach relies on complex offline hard negative sample construction pipelines, which constrain model iteration efficiency and hinder the evolutionary potential of semantic representation capabilities. Besides, existing multi-task learning frameworks face the seesaw effect when simultaneously optimizing semantic relevance and non-relevance objectives. In this paper, we propose Retrieval-GRPO, a multi-objective reinforcement learning-based dense retrieval framework designed to address these challenges. The method eliminates offline hard negative sample construction by dynamically retrieving Top-K candidate products for each query during training, while introducing a relevance LLM as a reward model to generate real-time feedback. Specifically, the retrieval model dynamically optimizes embedding representations through reinforcement learning, with reward signals combining LLM-generated relevance scores, product quality scores, and multi-way exclusivity metrics to achieve multi-objective user preference alignment and real-time error correction. This mechanism not only removes dependency on hard negatives but also mitigates the seesaw effect through collaborative multi-objective optimization, significantly enhancing the model's semantic generalization capability for complex long-tail queries. Extensive offline and online experiments validate the effectiveness of Retrieval-GRPO, which has been deployed on China's largest e-commerce platform.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2025-11-17T20:16:52+00:00",
      "updated": "2025-11-17T20:16:52+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.13885v1",
      "file": "papers/2511.13885v1.pdf"
    },
    {
      "arxiv_id": "2511.13489v1",
      "title": "PolicyBot - Reliable Question Answering over Policy Documents",
      "authors": [
        {
          "name": "Gautam Nagarajan"
        },
        {
          "name": "Omir Kumar"
        },
        {
          "name": "Sudarsun Santhiappan"
        }
      ],
      "abstract": "All citizens of a country are affected by the laws and policies introduced by their government. These laws and policies serve essential functions for citizens. Such as granting them certain rights or imposing specific obligations. However, these documents are often lengthy, complex, and difficult to navigate, making it challenging for citizens to locate and understand relevant information. This work presents PolicyBot, a retrieval-augmented generation (RAG) system designed to answer user queries over policy documents with a focus on transparency and reproducibility. The system combines domain-specific semantic chunking, multilingual dense embeddings, multi-stage retrieval with reranking, and source-aware generation to provide responses grounded in the original documents. We implemented citation tracing to reduce hallucinations and improve user trust, and evaluated alternative retrieval and generation configurations to identify effective design choices. The end-to-end pipeline is built entirely with open-source tools, enabling easy adaptation to other domains requiring document-grounded question answering. This work highlights design considerations, practical challenges, and lessons learned in deploying trustworthy RAG systems for governance-related contexts.",
      "primary_category": "cs.ET",
      "categories": [
        "cs.ET",
        "cs.IR"
      ],
      "published": "2025-11-17T15:26:10+00:00",
      "updated": "2025-11-17T15:26:10+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.13489v1",
      "file": "papers/2511.13489v1.pdf"
    },
    {
      "arxiv_id": "2511.13418v1",
      "title": "Exploring Multi-Table Retrieval Through Iterative Search",
      "authors": [
        {
          "name": "Allaa Boutaleb"
        },
        {
          "name": "Bernd Amann"
        },
        {
          "name": "Rafael Angarita"
        },
        {
          "name": "Hubert Naacke"
        }
      ],
      "abstract": "Open-domain question answering over datalakes requires retrieving and composing information from multiple tables, a challenging subtask that demands semantic relevance and structural coherence (e.g., joinability). While exact optimization methods like Mixed-Integer Programming (MIP) can ensure coherence, their computational complexity is often prohibitive. Conversely, simpler greedy heuristics that optimize for query coverage alone often fail to find these coherent, joinable sets. This paper frames multi-table retrieval as an iterative search process, arguing this approach offers advantages in scalability, interpretability, and flexibility. We propose a general framework and a concrete instantiation: a fast, effective Greedy Join-Aware Retrieval algorithm that holistically balances relevance, coverage, and joinability. Experiments across 5 NL2SQL benchmarks demonstrate that our iterative method achieves competitive retrieval performance compared to the MIP-based approach while being 4-400x faster depending on the benchmark and search space settings. This work highlights the potential of iterative heuristics for practical, scalable, and composition-aware retrieval.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.DB",
        "cs.LG"
      ],
      "published": "2025-11-17T14:31:33+00:00",
      "updated": "2025-11-17T14:31:33+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.13418v1",
      "file": "papers/2511.13418v1.pdf"
    },
    {
      "arxiv_id": "2511.13415v1",
      "title": "Attention Grounded Enhancement for Visual Document Retrieval",
      "authors": [
        {
          "name": "Wanqing Cui"
        },
        {
          "name": "Wei Huang"
        },
        {
          "name": "Yazhi Guo"
        },
        {
          "name": "Yibo Hu"
        },
        {
          "name": "Meiguang Jin"
        },
        {
          "name": "Junfeng Ma"
        },
        {
          "name": "Keping Bi"
        }
      ],
      "abstract": "Visual document retrieval requires understanding heterogeneous and multi-modal content to satisfy information needs. Recent advances use screenshot-based document encoding with fine-grained late interaction, significantly improving retrieval performance. However, retrievers are still trained with coarse global relevance labels, without revealing which regions support the match. As a result, retrievers tend to rely on surface-level cues and struggle to capture implicit semantic connections, hindering their ability to handle non-extractive queries. To alleviate this problem, we propose a \\textbf{A}ttention-\\textbf{G}rounded \\textbf{RE}triever \\textbf{E}nhancement (AGREE) framework. AGREE leverages cross-modal attention from multimodal large language models as proxy local supervision to guide the identification of relevant document regions. During training, AGREE combines local signals with the global signals to jointly optimize the retriever, enabling it to learn not only whether documents match, but also which content drives relevance. Experiments on the challenging ViDoRe V2 benchmark show that AGREE significantly outperforms the global-supervision-only baseline. Quantitative and qualitative analyses further demonstrate that AGREE promotes deeper alignment between query terms and document regions, moving beyond surface-level matching toward more accurate and interpretable retrieval. Our code is available at: https://anonymous.4open.science/r/AGREE-2025.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.CL",
        "cs.CV"
      ],
      "published": "2025-11-17T14:28:41+00:00",
      "updated": "2025-11-17T14:28:41+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.13415v1",
      "file": "papers/2511.13415v1.pdf"
    },
    {
      "arxiv_id": "2511.13201v2",
      "title": "Cog-RAG: Cognitive-Inspired Dual-Hypergraph with Theme Alignment Retrieval-Augmented Generation",
      "authors": [
        {
          "name": "Hao Hu"
        },
        {
          "name": "Yifan Feng"
        },
        {
          "name": "Ruoxue Li"
        },
        {
          "name": "Rundong Xue"
        },
        {
          "name": "Xingliang Hou"
        },
        {
          "name": "Zhiqiang Tian"
        },
        {
          "name": "Yue Gao"
        },
        {
          "name": "Shaoyi Du"
        }
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) enhances the response quality and domain-specific performance of large language models (LLMs) by incorporating external knowledge to combat hallucinations. In recent research, graph structures have been integrated into RAG to enhance the capture of semantic relations between entities. However, it primarily focuses on low-order pairwise entity relations, limiting the high-order associations among multiple entities. Hypergraph-enhanced approaches address this limitation by modeling multi-entity interactions via hyperedges, but they are typically constrained to inter-chunk entity-level representations, overlooking the global thematic organization and alignment across chunks. Drawing inspiration from the top-down cognitive process of human reasoning, we propose a theme-aligned dual-hypergraph RAG framework (Cog-RAG) that uses a theme hypergraph to capture inter-chunk thematic structure and an entity hypergraph to model high-order semantic relations. Furthermore, we design a cognitive-inspired two-stage retrieval strategy that first activates query-relevant thematic content from the theme hypergraph, and then guides fine-grained recall and diffusion in the entity hypergraph, achieving semantic alignment and consistent generation from global themes to local details. Our extensive experiments demonstrate that Cog-RAG significantly outperforms existing state-of-the-art baseline approaches.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2025-11-17T10:10:33+00:00",
      "updated": "2025-12-16T10:39:35+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.13201v2",
      "file": "papers/2511.13201v2.pdf"
    },
    {
      "arxiv_id": "2511.13057v2",
      "title": "Dimension vs. Precision: A Comparative Analysis of Autoencoders and Quantization for Efficient Vector Retrieval on BEIR SciFact",
      "authors": [
        {
          "name": "Satyanarayan Pati"
        }
      ],
      "abstract": "Dense retrieval models have become a standard for state-of-the-art information retrieval. However, their high-dimensional, high-precision (float32) vector embeddings create significant storage and memory challenges for real-world deployment. To address this, we conduct a rigorous empirical study on the BEIR SciFact benchmark, evaluating the trade-offs between two primary compression strategies: (1) Dimensionality Reduction via deep Autoencoders (AE), reducing original 384-dim vectors to latent spaces from 384 down to 12, and (2) Precision Reduction via Quantization (float16, int8, and binary). We systematically compare each method by measuring the \"performance loss\" (or gain) relative to a float32 baseline across a full suite of retrieval metrics (NDCG, MAP, MRR, Recall, Precision) at various k cutoffs. Our results show that int8 scalar quantization provides the most effective \"sweet spot,\" achieving a 4x compression with a negligible [~1-2%] drop in nDCG@10. In contrast, Autoencoders show a graceful degradation but suffer a more significant performance loss at equivalent 4x compression ratios (AE-96). binary quantization was found to be unsuitable for this task due to catastrophic performance drops. This work provides a practical guide for deploying efficient, high-performance retrieval systems.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "published": "2025-11-17T07:02:11+00:00",
      "updated": "2025-11-18T16:07:31+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.13057v2",
      "file": "papers/2511.13057v2.pdf"
    },
    {
      "arxiv_id": "2511.12518v1",
      "title": "DualGR: Generative Retrieval with Long and Short-Term Interests Modeling",
      "authors": [
        {
          "name": "Zhongchao Yi"
        },
        {
          "name": "Kai Feng"
        },
        {
          "name": "Xiaojian Ma"
        },
        {
          "name": "Yalong Wang"
        },
        {
          "name": "Yongqi Liu"
        },
        {
          "name": "Han Li"
        },
        {
          "name": "Zhengyang Zhou"
        },
        {
          "name": "Yang Wang"
        }
      ],
      "abstract": "In large-scale industrial recommendation systems, retrieval must produce high-quality candidates from massive corpora under strict latency. Recently, Generative Retrieval (GR) has emerged as a viable alternative to Embedding-Based Retrieval (EBR), which quantizes items into a finite token space and decodes candidates autoregressively, providing a scalable path that explicitly models target-history interactions via cross-attention. However, three challenges persist: 1) how to balance users' long-term and short-term interests , 2) noise interference when generating hierarchical semantic IDs (SIDs), 3) the absence of explicit modeling for negative feedback such as exposed items without clicks. To address these challenges, we propose DualGR, a generative retrieval framework that explicitly models dual horizons of user interests with selective activation. Specifically, DualGR utilizes Dual-Branch Long/Short-Term Router (DBR) to cover both stable preferences and transient intents by explicitly modeling users' long- and short-term behaviors. Meanwhile, Search-based SID Decoding (S2D) is presented to control context-induced noise and enhance computational efficiency by constraining candidate interactions to the current coarse (level-1) bucket during fine-grained (level-2/3) SID prediction. % also reinforcing intra-class consistency. Finally, we propose an Exposure-aware Next-Token Prediction Loss (ENTP-Loss) that treats \"exposed-but-unclicked\" items as hard negatives at level-1, enabling timely interest fade-out. On the large-scale Kuaishou short-video recommendation system, DualGR has achieved outstanding performance. Online A/B testing shows +0.527% video views and +0.432% watch time lifts, validating DualGR as a practical and effective paradigm for industrial generative retrieval.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2025-11-16T09:20:54+00:00",
      "updated": "2025-11-16T09:20:54+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.12518v1",
      "file": "papers/2511.12518v1.pdf"
    },
    {
      "arxiv_id": "2511.12004v2",
      "title": "ComLQ: Benchmarking Complex Logical Queries in Information Retrieval",
      "authors": [
        {
          "name": "Ganlin Xu"
        },
        {
          "name": "Zhitao Yin"
        },
        {
          "name": "Linghao Zhang"
        },
        {
          "name": "Jiaqing Liang"
        },
        {
          "name": "Weijia Lu"
        },
        {
          "name": "Xiaodong Zhang"
        },
        {
          "name": "Zhifei Yang"
        },
        {
          "name": "Sihang Jiang"
        },
        {
          "name": "Deqing Yang"
        }
      ],
      "abstract": "Information retrieval (IR) systems play a critical role in navigating information overload across various applications. Existing IR benchmarks primarily focus on simple queries that are semantically analogous to single- and multi-hop relations, overlooking \\emph{complex logical queries} involving first-order logic operations such as conjunction ($\\land$), disjunction ($\\lor$), and negation ($\\lnot$). Thus, these benchmarks can not be used to sufficiently evaluate the performance of IR models on complex queries in real-world scenarios. To address this problem, we propose a novel method leveraging large language models (LLMs) to construct a new IR dataset \\textbf{ComLQ} for \\textbf{Com}plex \\textbf{L}ogical \\textbf{Q}ueries, which comprises 2,909 queries and 11,251 candidate passages. A key challenge in constructing the dataset lies in capturing the underlying logical structures within unstructured text. Therefore, by designing the subgraph-guided prompt with the subgraph indicator, an LLM (such as GPT-4o) is guided to generate queries with specific logical structures based on selected passages. All query-passage pairs in ComLQ are ensured \\emph{structure conformity} and \\emph{evidence distribution} through expert annotation. To better evaluate whether retrievers can handle queries with negation, we further propose a new evaluation metric, \\textbf{Log-Scaled Negation Consistency} (\\textbf{LSNC@$K$}). As a supplement to standard relevance-based metrics (such as nDCG and mAP), LSNC@$K$ measures whether top-$K$ retrieved passages violate negation conditions in queries. Our experimental results under zero-shot settings demonstrate existing retrieval models' limited performance on complex logical queries, especially on queries with negation, exposing their inferior capabilities of modeling exclusion.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2025-11-15T02:58:21+00:00",
      "updated": "2025-11-23T06:31:37+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.12004v2",
      "file": "papers/2511.12004v2.pdf"
    },
    {
      "arxiv_id": "2511.11847v1",
      "title": "A Multimodal Manufacturing Safety Chatbot: Knowledge Base Design, Benchmark Development, and Evaluation of Multiple RAG Approaches",
      "authors": [
        {
          "name": "Ryan Singh"
        },
        {
          "name": "Austin Hamilton"
        },
        {
          "name": "Amanda White"
        },
        {
          "name": "Michael Wise"
        },
        {
          "name": "Ibrahim Yousif"
        },
        {
          "name": "Arthur Carvalho"
        },
        {
          "name": "Zhe Shan"
        },
        {
          "name": "Reza Abrisham Baf"
        },
        {
          "name": "Mohammad Mayyas"
        },
        {
          "name": "Lora A. Cavuoto"
        },
        {
          "name": "Fadel M. Megahed"
        }
      ],
      "abstract": "Ensuring worker safety remains a critical challenge in modern manufacturing environments. Industry 5.0 reorients the prevailing manufacturing paradigm toward more human-centric operations. Using a design science research methodology, we identify three essential requirements for next-generation safety training systems: high accuracy, low latency, and low cost. We introduce a multimodal chatbot powered by large language models that meets these design requirements. The chatbot uses retrieval-augmented generation to ground its responses in curated regulatory and technical documentation. To evaluate our solution, we developed a domain-specific benchmark of expert-validated question and answer pairs for three representative machines: a Bridgeport manual mill, a Haas TL-1 CNC lathe, and a Universal Robots UR5e collaborative robot. We tested 24 RAG configurations using a full-factorial design and assessed them with automated evaluations of correctness, latency, and cost. Our top 2 configurations were then evaluated by ten industry experts and academic researchers. Our results show that retrieval strategy and model configuration have a significant impact on performance. The top configuration (selected for chatbot deployment) achieved an accuracy of 86.66%, an average latency of 10.04 seconds, and an average cost of $0.005 per query. Overall, our work provides three contributions: an open-source, domain-grounded safety training chatbot; a validated benchmark for evaluating AI-assisted safety instruction; and a systematic methodology for designing and assessing AI-enabled instructional and immersive safety training systems for Industry 5.0 environments.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CY"
      ],
      "published": "2025-11-14T20:10:23+00:00",
      "updated": "2025-11-14T20:10:23+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.11847v1",
      "file": "papers/2511.11847v1.pdf"
    },
    {
      "arxiv_id": "2511.11010v1",
      "title": "GovScape: A Public Multimodal Search System for 70 Million Pages of Government PDFs",
      "authors": [
        {
          "name": "Kyle Deeds"
        },
        {
          "name": "Ying-Hsiang Huang"
        },
        {
          "name": "Claire Gong"
        },
        {
          "name": "Shreya Shaji"
        },
        {
          "name": "Alison Yan"
        },
        {
          "name": "Leslie Harka"
        },
        {
          "name": "Samuel J Klein"
        },
        {
          "name": "Shannon Zejiang Shen"
        },
        {
          "name": "Mark Phillips"
        },
        {
          "name": "Trevor Owens"
        },
        {
          "name": "Benjamin Charles Germain Lee"
        }
      ],
      "abstract": "Efforts over the past three decades have produced web archives containing billions of webpage snapshots and petabytes of data. The End of Term Web Archive alone contains, among other file types, millions of PDFs produced by the federal government. While preservation with web archives has been successful, significant challenges for access and discoverability remain. For example, current affordances for browsing the End of Term PDFs are limited to downloading and browsing individual PDFs, as well as performing basic keyword search across them. In this paper, we introduce GovScape, a public search system that supports multimodal searches across 10,015,993 federal government PDFs from the 2020 End of Term crawl (70,958,487 total PDF pages) - to our knowledge, all renderable PDFs in the 2020 crawl that are 50 pages or under. GovScape supports four primary forms of search over these 10 million PDFs: in addition to providing (1) filter conditions over metadata facets including domain and crawl date and (2) exact text search against the PDF text, we provide (3) semantic text search and (4) visual search against the PDFs across individual pages, enabling users to structure queries such as \"redacted documents\" or \"pie charts.\" We detail the constituent components of GovScape, including the search affordances, embedding pipeline, system architecture, and open source codebase. Significantly, the total estimated compute cost for GovScape's pre-processing pipeline for 10 million PDFs was approximately $1,500, equivalent to 47,000 PDF pages per dollar spent on compute, demonstrating the potential for immediate scalability. Accordingly, we outline steps that we have already begun pursuing toward multimodal search at the 100+ million PDF scale. GovScape can be found at https://www.govscape.net.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.DL"
      ],
      "published": "2025-11-14T06:54:48+00:00",
      "updated": "2025-11-14T06:54:48+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.11010v1",
      "file": "papers/2511.11010v1.pdf"
    },
    {
      "arxiv_id": "2511.09545v1",
      "title": "Practical RAG Evaluation: A Rarity-Aware Set-Based Metric and Cost-Latency-Quality Trade-offs",
      "authors": [
        {
          "name": "Etienne Dallaire"
        }
      ],
      "abstract": "This paper addresses the guessing game in building production RAG. Classical rank-centric IR metrics (nDCG/MAP/MRR) are a poor fit for RAG, where LLMs consume a set of passages rather than a browsed list; position discounts and prevalence-blind aggregation miss what matters: whether the prompt at cutoff K contains the decisive evidence. Second, there is no standardized, reproducible way to build and audit golden sets. Third, leaderboards exist but lack end-to-end, on-corpus benchmarking that reflects production trade-offs. Fourth, how state-of-the-art embedding models handle proper-name identity signals and conversational noise remains opaque. To address these, we contribute: (1) RA-nWG@K, a rarity-aware, per-query-normalized set score, and operational ceilings via the pool-restricted oracle ceiling (PROC) and the percentage of PROC (%PROC) to separate retrieval from ordering headroom within a Cost-Latency-Quality (CLQ) lens; (2) rag-gs (MIT), a lean golden-set pipeline with Plackett-Luce listwise refinement whose iterative updates outperform single-shot LLM ranking; (3) a comprehensive benchmark on a production RAG (scientific-papers corpus) spanning dense retrieval, hybrid dense+BM25, embedding models and dimensions, cross-encoder rerankers, ANN (HNSW), and quantization; and (4) targeted diagnostics that quantify proper-name identity signal and conversational-noise sensitivity via identity-destroying and formatting ablations. Together, these components provide practitioner Pareto guidance and auditable guardrails to support reproducible, budget/SLA-aware decisions.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2025-11-12T18:49:21+00:00",
      "updated": "2025-11-12T18:49:21+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.09545v1",
      "file": "papers/2511.09545v1.pdf"
    },
    {
      "arxiv_id": "2511.09329v1",
      "title": "Sim4IA-Bench: A User Simulation Benchmark Suite for Next Query and Utterance Prediction",
      "authors": [
        {
          "name": "Andreas Konstantin Kruff"
        },
        {
          "name": "Christin Katharina Kreutz"
        },
        {
          "name": "Timo Breuer"
        },
        {
          "name": "Philipp Schaer"
        },
        {
          "name": "Krisztian Balog"
        }
      ],
      "abstract": "Validating user simulation is a difficult task due to the lack of established measures and benchmarks, which makes it challenging to assess whether a simulator accurately reflects real user behavior. As part of the Sim4IA Micro-Shared Task at the Sim4IA Workshop, SIGIR 2025, we present Sim4IA-Bench, a simulation benchmark suit for the prediction of the next queries and utterances, the first of its kind in the IR community. Our dataset as part of the suite comprises 160 real-world search sessions from the CORE search engine. For 70 of these sessions, up to 62 simulator runs are available, divided into Task A and Task B, in which different approaches predicted users next search queries or utterances. Sim4IA-Bench provides a basis for evaluating and comparing user simulation approaches and for developing new measures of simulator validity. Although modest in size, the suite represents the first publicly available benchmark that links real search sessions with simulated next-query predictions. In addition to serving as a testbed for next query prediction, it also enables exploratory studies on query reformulation behavior, intent drift, and interaction-aware retrieval evaluation. We also introduce a new measure for evaluating next-query predictions in this task. By making the suite publicly available, we aim to promote reproducible research and stimulate further work on realistic and explainable user simulation for information access: https://github.com/irgroup/Sim4IA-Bench.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2025-11-12T13:44:12+00:00",
      "updated": "2025-11-12T13:44:12+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.09329v1",
      "file": "papers/2511.09329v1.pdf"
    },
    {
      "arxiv_id": "2511.09109v2",
      "title": "Thinking Forward and Backward: Multi-Objective Reinforcement Learning for Retrieval-Augmented Reasoning",
      "authors": [
        {
          "name": "Wenda Wei"
        },
        {
          "name": "Yu-An Liu"
        },
        {
          "name": "Ruqing Zhang"
        },
        {
          "name": "Jiafeng Guo"
        },
        {
          "name": "Lixin Su"
        },
        {
          "name": "Shuaiqiang Wang"
        },
        {
          "name": "Dawei Yin"
        },
        {
          "name": "Maarten de Rijke"
        },
        {
          "name": "Xueqi Cheng"
        }
      ],
      "abstract": "Retrieval-augmented generation (RAG) has proven to be effective in mitigating hallucinations in large language models, yet its effectiveness remains limited in complex, multi-step reasoning scenarios. Recent efforts have incorporated search-based interactions into RAG, enabling iterative reasoning with real-time retrieval. Most approaches rely on outcome-based supervision, offering no explicit guidance for intermediate steps. This often leads to reward hacking and degraded response quality. We propose Bi-RAR, a novel retrieval-augmented reasoning framework that evaluates each intermediate step jointly in both forward and backward directions. To assess the information completeness of each step, we introduce a bidirectional information distance grounded in Kolmogorov complexity, approximated via language model generation probabilities. This quantification measures both how far the current reasoning is from the answer and how well it addresses the question. To optimize reasoning under these bidirectional signals, we adopt a multi-objective reinforcement learning framework with a cascading reward structure that emphasizes early trajectory alignment. Empirical results on seven question answering benchmarks demonstrate that Bi-RAR surpasses previous methods and enables efficient interaction and reasoning with the search engine during training and inference.",
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "published": "2025-11-12T08:29:39+00:00",
      "updated": "2025-11-13T06:08:52+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.09109v2",
      "file": "papers/2511.09109v2.pdf"
    },
    {
      "arxiv_id": "2511.08480v1",
      "title": "Compression then Matching: An Efficient Pre-training Paradigm for Multimodal Embedding",
      "authors": [
        {
          "name": "Da Li"
        },
        {
          "name": "Yuxiao Luo"
        },
        {
          "name": "Keping Bi"
        },
        {
          "name": "Jiafeng Guo"
        },
        {
          "name": "Wei Yuan"
        },
        {
          "name": "Biao Yang"
        },
        {
          "name": "Yan Wang"
        },
        {
          "name": "Fan Yang"
        },
        {
          "name": "Tingting Gao"
        },
        {
          "name": "Guorui Zhou"
        }
      ],
      "abstract": "Vision-language models advance multimodal representation learning by acquiring transferable semantic embeddings, thereby substantially enhancing performance across a range of vision-language tasks, including cross-modal retrieval, clustering, and classification. An effective embedding is expected to comprehensively preserve the semantic content of the input while simultaneously emphasizing features that are discriminative for downstream tasks. Recent approaches demonstrate that VLMs can be adapted into competitive embedding models via large-scale contrastive learning, enabling the simultaneous optimization of two complementary objectives. We argue that the two aforementioned objectives can be decoupled: a comprehensive understanding of the input facilitates the embedding model in achieving superior performance in downstream tasks via contrastive learning. In this paper, we propose CoMa, a compressed pre-training phase, which serves as a warm-up stage for contrastive learning. Experiments demonstrate that with only a small amount of pre-training data, we can transform a VLM into a competitive embedding model. CoMa achieves new state-of-the-art results among VLMs of comparable size on the MMEB, realizing optimization in both efficiency and effectiveness.",
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.IR"
      ],
      "published": "2025-11-11T17:23:02+00:00",
      "updated": "2025-11-11T17:23:02+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.08480v1",
      "file": "papers/2511.08480v1.pdf"
    },
    {
      "arxiv_id": "2511.08476v1",
      "title": "Advancing Scientific Knowledge Retrieval and Reuse with a Novel Digital Library for Machine-Readable Knowledge",
      "authors": [
        {
          "name": "Hadi Ghaemi"
        },
        {
          "name": "Lauren Snyder"
        },
        {
          "name": "Markus Stocker"
        }
      ],
      "abstract": "Digital libraries for research, such as the ACM Digital Library or Semantic Scholar, do not enable the machine-supported, efficient reuse of scientific knowledge (e.g., in synthesis research). This is because these libraries are based on document-centric models with narrative text knowledge expressions that require manual or semi-automated knowledge extraction, structuring, and organization. We present ORKG reborn, an emerging digital library that supports finding, accessing, and reusing accurate, fine-grained, and reproducible machine-readable expressions of scientific knowledge that relate scientific statements and their supporting evidence in terms of data and code. The rich expressions of scientific knowledge are published as reborn (born-reusable) articles and provide novel possibilities for scientific knowledge retrieval, for instance by statistical methods, software packages, variables, or data matching specific constraints. We describe the proposed system and demonstrate its practical viability and potential for information retrieval in contrast to state-of-the-art digital libraries and document-centric scholarly communication using several published articles in research fields ranging from computer science to soil science. Our work underscores the enormous potential of scientific knowledge databases and a viable approach to their construction.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2025-11-11T17:20:02+00:00",
      "updated": "2025-11-11T17:20:02+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.08476v1",
      "file": "papers/2511.08476v1.pdf"
    },
    {
      "arxiv_id": "2511.08150v4",
      "title": "DiffuGR: Generative Document Retrieval with Diffusion Language Models",
      "authors": [
        {
          "name": "Xinpeng Zhao"
        },
        {
          "name": "Zhaochun Ren"
        },
        {
          "name": "Yukun Zhao"
        },
        {
          "name": "Zhenyang Li"
        },
        {
          "name": "Mengqi Zhang"
        },
        {
          "name": "Jun Feng"
        },
        {
          "name": "Ran Chen"
        },
        {
          "name": "Ying Zhou"
        },
        {
          "name": "Zhumin Chen"
        },
        {
          "name": "Shuaiqiang Wang"
        },
        {
          "name": "Dawei Yin"
        },
        {
          "name": "Xin Xin"
        }
      ],
      "abstract": "Generative retrieval (GR) re-frames document retrieval as a sequence-based document identifier (DocID) generation task, memorizing documents with model parameters and enabling end-to-end retrieval without explicit indexing. Existing GR methods are based on auto-regressive generative models, i.e., the token generation is performed from left to right. However, such auto-regressive methods suffer from: (1) mismatch between DocID generation and natural language generation, e.g., an incorrect DocID token generated in early left steps would lead to totally erroneous retrieval; and (2) failure to balance the trade-off between retrieval efficiency and accuracy dynamically, which is crucial for practical applications. To address these limitations, we propose generative document retrieval with diffusion language models, dubbed DiffuGR. It models DocID generation as a discrete diffusion process: during training, DocIDs are corrupted through a stochastic masking process, and a diffusion language model is learned to recover them under a retrieval-aware objective. For inference, DiffuGR attempts to generate DocID tokens in parallel and refines them through a controllable number of denoising steps. In contrast to conventional left-to-right auto-regressive decoding, DiffuGR provides a novel mechanism to first generate more confident DocID tokens and refine the generation through diffusion-based denoising. Moreover, DiffuGR also offers explicit runtime control over the qualitylatency tradeoff. Extensive experiments on benchmark retrieval datasets show that DiffuGR is competitive with strong auto-regressive generative retrievers, while offering flexible speed and accuracy tradeoffs through variable denoising budgets. Overall, our results indicate that non-autoregressive diffusion models are a practical and effective alternative for generative document retrieval.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2025-11-11T12:00:09+00:00",
      "updated": "2025-11-23T12:30:11+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.08150v4",
      "file": "papers/2511.08150v4.pdf"
    },
    {
      "arxiv_id": "2511.08029v2",
      "title": "BiCA: Effective Biomedical Dense Retrieval with Citation-Aware Hard Negatives",
      "authors": [
        {
          "name": "Aarush Sinha"
        },
        {
          "name": "Pavan Kumar S"
        },
        {
          "name": "Roshan Balaji"
        },
        {
          "name": "Nirav Pravinbhai Bhatt"
        }
      ],
      "abstract": "Hard negatives are essential for training effective retrieval models. Hard-negative mining typically relies on ranking documents using cross-encoders or static embedding models based on similarity metrics such as cosine distance. Hard negative mining becomes challenging for biomedical and scientific domains due to the difficulty in distinguishing between source and hard negative documents. However, referenced documents naturally share contextual relevance with the source document but are not duplicates, making them well-suited as hard negatives. In this work, we propose BiCA: Biomedical Dense Retrieval with Citation-Aware Hard Negatives, an approach for hard-negative mining by utilizing citation links in 20,000 PubMed articles for improving a domain-specific small dense retriever. We fine-tune the GTE_small and GTE_Base models using these citation-informed negatives and observe consistent improvements in zero-shot dense retrieval using nDCG@10 for both in-domain and out-of-domain tasks on BEIR and outperform baselines on long-tailed topics in LoTTE using Success@5. Our findings highlight the potential of leveraging document link structure to generate highly informative negatives, enabling state-of-the-art performance with minimal fine-tuning and demonstrating a path towards highly data-efficient domain adaptation.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.CL"
      ],
      "published": "2025-11-11T09:31:37+00:00",
      "updated": "2025-12-21T06:45:20+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.08029v2",
      "file": "papers/2511.08029v2.pdf"
    },
    {
      "arxiv_id": "2511.07595v1",
      "title": "TurkEmbed4Retrieval: Turkish Embedding Model for Retrieval Task",
      "authors": [
        {
          "name": "Özay Ezerceli"
        },
        {
          "name": "Gizem Gümüşçekiçci"
        },
        {
          "name": "Tuğba Erkoç"
        },
        {
          "name": "Berke Özenç"
        }
      ],
      "abstract": "In this work, we introduce TurkEmbed4Retrieval, a retrieval specialized variant of the TurkEmbed model originally designed for Natural Language Inference (NLI) and Semantic Textual Similarity (STS) tasks. By fine-tuning the base model on the MS MARCO TR dataset using advanced training techniques, including Matryoshka representation learning and a tailored multiple negatives ranking loss, we achieve SOTA performance for Turkish retrieval tasks. Extensive experiments demonstrate that our model outperforms Turkish colBERT by 19,26% on key retrieval metrics for the Scifact TR dataset, thereby establishing a new benchmark for Turkish information retrieval.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2025-11-10T20:08:09+00:00",
      "updated": "2025-11-10T20:08:09+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.07595v1",
      "file": "papers/2511.07595v1.pdf"
    },
    {
      "arxiv_id": "2511.07581v1",
      "title": "Think Before You Retrieve: Learning Test-Time Adaptive Search with Small Language Models",
      "authors": [
        {
          "name": "Supriti Vijay"
        },
        {
          "name": "Aman Priyanshu"
        },
        {
          "name": "Anu Vellore"
        },
        {
          "name": "Baturay Saglam"
        },
        {
          "name": "Amin Karbasi"
        }
      ],
      "abstract": "Effective information retrieval requires reasoning over partial evidence and refining strategies as information emerges. Yet current approaches fall short: neural retrievers lack reasoning capabilities, large language models (LLMs) provide semantic depth but at prohibitive cost, and query rewriting or decomposition limits improvement to static transformations. As a result, existing methods fail to capture the iterative dynamics of exploration, feedback, and revision that complex user queries demand. We introduce Orion, a training framework that enables compact models (350M-1.2B parameters) to perform iterative retrieval through learned search strategies. Orion combines: (1) synthetic trajectory generation and supervised fine-tuning to encourage diverse exploration patterns in models, (2) reinforcement learning (RL) that rewards effective query refinement and backtracking behaviors, and (3) inference-time beam search algorithms that exploit the self-reflection capabilities learned during RL. Despite using only 3% of the training data available, our 1.2B model achieves 77.6% success on SciFact (vs. 72.6% for prior retrievers), 25.2% on BRIGHT (vs. 22.1%), 63.2% on NFCorpus (vs. 57.8%), and remains competitive on FEVER, HotpotQA, and MSMarco. It outperforms retrievers up to 200-400x larger on five of six benchmarks. These findings suggest that retrieval performance can emerge from learned strategies, not just model scale, when models are trained to search, reflect, and revise.",
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ],
      "published": "2025-11-10T19:49:55+00:00",
      "updated": "2025-11-10T19:49:55+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.07581v1",
      "file": "papers/2511.07581v1.pdf"
    },
    {
      "arxiv_id": "2511.07577v1",
      "title": "A Decentralized Retrieval Augmented Generation System with Source Reliabilities Secured on Blockchain",
      "authors": [
        {
          "name": "Yining Lu"
        },
        {
          "name": "Wenyi Tang"
        },
        {
          "name": "Max Johnson"
        },
        {
          "name": "Taeho Jung"
        },
        {
          "name": "Meng Jiang"
        }
      ],
      "abstract": "Existing retrieval-augmented generation (RAG) systems typically use a centralized architecture, causing a high cost of data collection, integration, and management, as well as privacy concerns. There is a great need for a decentralized RAG system that enables foundation models to utilize information directly from data owners who maintain full control over their sources. However, decentralization brings a challenge: the numerous independent data sources vary significantly in reliability, which can diminish retrieval accuracy and response quality. To address this, our decentralized RAG system has a novel reliability scoring mechanism that dynamically evaluates each source based on the quality of responses it contributes to generate and prioritizes high-quality sources during retrieval. To ensure transparency and trust, the scoring process is securely managed through blockchain-based smart contracts, creating verifiable and tamper-proof reliability records without relying on a central authority. We evaluate our decentralized system with two Llama models (3B and 8B) in two simulated environments where six data sources have different levels of reliability. Our system achieves a +10.7\\% performance improvement over its centralized counterpart in the real world-like unreliable data environments. Notably, it approaches the upper-bound performance of centralized systems under ideally reliable data environments. The decentralized infrastructure enables secure and trustworthy scoring management, achieving approximately 56\\% marginal cost savings through batched update operations. Our code and system are open-sourced at github.com/yining610/Reliable-dRAG.",
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR",
        "cs.CL",
        "cs.IR"
      ],
      "published": "2025-11-10T19:40:30+00:00",
      "updated": "2025-11-10T19:40:30+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.07577v1",
      "file": "papers/2511.07577v1.pdf"
    },
    {
      "arxiv_id": "2511.07328v1",
      "title": "Q-RAG: Long Context Multi-step Retrieval via Value-based Embedder Training",
      "authors": [
        {
          "name": "Artyom Sorokin"
        },
        {
          "name": "Nazar Buzun"
        },
        {
          "name": "Alexander Anokhin"
        },
        {
          "name": "Oleg Inozemcev"
        },
        {
          "name": "Egor Vedernikov"
        },
        {
          "name": "Petr Anokhin"
        },
        {
          "name": "Mikhail Burtsev"
        },
        {
          "name": "Trushkov Alexey"
        },
        {
          "name": "Yin Wenshuai"
        },
        {
          "name": "Evgeny Burnaev"
        }
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) methods enhance LLM performance by efficiently filtering relevant context for LLMs, reducing hallucinations and inference cost. However, most existing RAG methods focus on single-step retrieval, which is often insufficient for answering complex questions that require multi-step search. Recently, multi-step retrieval approaches have emerged, typically involving the fine-tuning of small LLMs to perform multi-step retrieval. This type of fine-tuning is highly resource-intensive and does not enable the use of larger LLMs. In this work, we propose Q-RAG, a novel approach that fine-tunes the Embedder model for multi-step retrieval using reinforcement learning (RL). Q-RAG offers a competitive, resource-efficient alternative to existing multi-step retrieval methods for open-domain question answering and achieves state-of-the-art results on the popular long-context benchmarks Babilong and RULER for contexts up to 10M tokens.",
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.IR"
      ],
      "published": "2025-11-10T17:31:02+00:00",
      "updated": "2025-11-10T17:31:02+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.07328v1",
      "file": "papers/2511.07328v1.pdf"
    },
    {
      "arxiv_id": "2511.11653v1",
      "title": "GroupRank: A Groupwise Reranking Paradigm Driven by Reinforcement Learning",
      "authors": [
        {
          "name": "Duolin Sun"
        },
        {
          "name": "Meixiu Long"
        },
        {
          "name": "Dan Yang"
        },
        {
          "name": "Yihan Jiao"
        },
        {
          "name": "Zhehao Tan"
        },
        {
          "name": "Jie Feng"
        },
        {
          "name": "Junjie Wang"
        },
        {
          "name": "Yue Shen"
        },
        {
          "name": "Peng Wei"
        },
        {
          "name": "Jian Wang"
        },
        {
          "name": "Jinjie Gu"
        }
      ],
      "abstract": "Large Language Models have shown strong potential as rerankers to enhance the overall performance of RAG systems. However, existing reranking paradigms are constrained by a core theoretical and practical dilemma: Pointwise methods, while simple and highly flexible, evaluate documents independently, making them prone to the Ranking Myopia Trap, overlooking the relative importance between documents. In contrast, Listwise methods can perceive the global ranking context, but suffer from inherent List Rigidity, leading to severe scalability and flexibility issues when handling large candidate sets. To address these challenges, we propose Groupwise, a novel reranking paradigm. In this approach, the query and a group of candidate documents are jointly fed into the model, which performs within-group comparisons to assign individual relevance scores to each document. This design retains the flexibility of Pointwise methods while enabling the comparative capability of Listwise methods. We further adopt GRPO for model training, equipped with a heterogeneous reward function that integrates ranking metrics with a distributional reward aimed at aligning score distributions across groups. To overcome the bottleneck caused by the scarcity of high quality labeled data, we further propose an innovative pipeline for synthesizing high quality retrieval and ranking data. The resulting data can be leveraged not only for training the reranker but also for training the retriever. Extensive experiments validate the effectiveness of our approach. On two reasoning intensive retrieval benchmarks, BRIGHT and R2MED.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2025-11-10T15:25:31+00:00",
      "updated": "2025-11-10T15:25:31+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.11653v1",
      "file": "papers/2511.11653v1.pdf"
    },
    {
      "arxiv_id": "2511.07025v1",
      "title": "Llama-Embed-Nemotron-8B: A Universal Text Embedding Model for Multilingual and Cross-Lingual Tasks",
      "authors": [
        {
          "name": "Yauhen Babakhin"
        },
        {
          "name": "Radek Osmulski"
        },
        {
          "name": "Ronay Ak"
        },
        {
          "name": "Gabriel Moreira"
        },
        {
          "name": "Mengyao Xu"
        },
        {
          "name": "Benedikt Schifferer"
        },
        {
          "name": "Bo Liu"
        },
        {
          "name": "Even Oldridge"
        }
      ],
      "abstract": "We introduce llama-embed-nemotron-8b, an open-weights text embedding model that achieves state-of-the-art performance on the Multilingual Massive Text Embedding Benchmark (MMTEB) leaderboard as of October 21, 2025. While recent models show strong performance, their training data or methodologies are often not fully disclosed. We aim to address this by developing a fully open-source model, publicly releasing its weights and detailed ablation studies, and planning to share the curated training datasets. Our model demonstrates superior performance across all major embedding tasks -- including retrieval, classification and semantic textual similarity (STS) -- and excels in challenging multilingual scenarios, such as low-resource languages and cross-lingual setups. This state-of-the-art performance is driven by a novel data mix of 16.1 million query-document pairs, split between 7.7 million samples from public datasets and 8.4 million synthetically generated examples from various open-weight LLMs. One of our key contributions is a detailed ablation study analyzing core design choices, including a comparison of contrastive loss implementations, an evaluation of synthetic data generation (SDG) strategies, and the impact of model merging. The llama-embed-nemotron-8b is an instruction-aware model, supporting user-defined instructions to enhance performance for specific use-cases. This combination of top-tier performance, broad applicability, and user-driven flexibility enables it to serve as a universal text embedding solution.",
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.IR"
      ],
      "published": "2025-11-10T12:13:16+00:00",
      "updated": "2025-11-10T12:13:16+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.07025v1",
      "file": "papers/2511.07025v1.pdf"
    },
    {
      "arxiv_id": "2511.06668v1",
      "title": "When Evidence Contradicts: Toward Safer Retrieval-Augmented Generation in Healthcare",
      "authors": [
        {
          "name": "Saeedeh Javadi"
        },
        {
          "name": "Sara Mirabi"
        },
        {
          "name": "Manan Gangar"
        },
        {
          "name": "Bahadorreza Ofoghi"
        }
      ],
      "abstract": "In high-stakes information domains such as healthcare, where large language models (LLMs) can produce hallucinations or misinformation, retrieval-augmented generation (RAG) has been proposed as a mitigation strategy, grounding model outputs in external, domain-specific documents. Yet, this approach can introduce errors when source documents contain outdated or contradictory information. This work investigates the performance of five LLMs in generating RAG-based responses to medicine-related queries. Our contributions are three-fold: i) the creation of a benchmark dataset using consumer medicine information documents from the Australian Therapeutic Goods Administration (TGA), where headings are repurposed as natural language questions, ii) the retrieval of PubMed abstracts using TGA headings, stratified across multiple publication years, to enable controlled temporal evaluation of outdated evidence, and iii) a comparative analysis of the frequency and impact of outdated or contradictory content on model-generated responses, assessing how LLMs integrate and reconcile temporally inconsistent information. Our findings show that contradictions between highly similar abstracts do, in fact, degrade performance, leading to inconsistencies and reduced factual accuracy in model answers. These results highlight that retrieval similarity alone is insufficient for reliable medical RAG and underscore the need for contradiction-aware filtering strategies to ensure trustworthy responses in high-stakes domains.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.LG"
      ],
      "published": "2025-11-10T03:27:54+00:00",
      "updated": "2025-11-10T03:27:54+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.06668v1",
      "file": "papers/2511.06668v1.pdf"
    },
    {
      "arxiv_id": "2511.06635v1",
      "title": "Can LLM Annotations Replace User Clicks for Learning to Rank?",
      "authors": [
        {
          "name": "Lulu Yu"
        },
        {
          "name": "Keping Bi"
        },
        {
          "name": "Jiafeng Guo"
        },
        {
          "name": "Shihao Liu"
        },
        {
          "name": "Shuaiqiang Wang"
        },
        {
          "name": "Dawei Yin"
        },
        {
          "name": "Xueqi Cheng"
        }
      ],
      "abstract": "Large-scale supervised data is essential for training modern ranking models, but obtaining high-quality human annotations is costly. Click data has been widely used as a low-cost alternative, and with recent advances in large language models (LLMs), LLM-based relevance annotation has emerged as another promising annotation. This paper investigates whether LLM annotations can replace click data for learning to rank (LTR) by conducting a comprehensive comparison across multiple dimensions. Experiments on both a public dataset, TianGong-ST, and an industrial dataset, Baidu-Click, show that click-supervised models perform better on high-frequency queries, while LLM annotation-supervised models are more effective on medium- and low-frequency queries. Further analysis shows that click-supervised models are better at capturing document-level signals such as authority or quality, while LLM annotation-supervised models are more effective at modeling semantic matching between queries and documents and at distinguishing relevant from non-relevant documents. Motivated by these observations, we explore two training strategies -- data scheduling and frequency-aware multi-objective learning -- that integrate both supervision signals. Both approaches enhance ranking performance across queries at all frequency levels, with the latter being more effective. Our code is available at https://github.com/Trustworthy-Information-Access/LLMAnn_Click.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2025-11-10T02:26:14+00:00",
      "updated": "2025-11-10T02:26:14+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.06635v1",
      "file": "papers/2511.06635v1.pdf"
    },
    {
      "arxiv_id": "2511.06582v1",
      "title": "TabRAG: Tabular Document Retrieval via Structured Language Representations",
      "authors": [
        {
          "name": "Jacob Si"
        },
        {
          "name": "Mike Qu"
        },
        {
          "name": "Michelle Lee"
        },
        {
          "name": "Yingzhen Li"
        }
      ],
      "abstract": "Ingesting data for Retrieval-Augmented Generation (RAG) involves either fine-tuning the embedding model directly on the target corpus or parsing documents for embedding model encoding. The former, while accurate, incurs high computational hardware requirements, while the latter suffers from suboptimal performance when extracting tabular data. In this work, we address the latter by presenting TabRAG, a parsing-based RAG pipeline designed to tackle table-heavy documents via structured language representations. TabRAG outperforms existing popular parsing-based methods for generation and retrieval. Code is available at https://github.com/jacobyhsi/TabRAG.",
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.IR",
        "cs.LG"
      ],
      "published": "2025-11-10T00:05:58+00:00",
      "updated": "2025-11-10T00:05:58+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.06582v1",
      "file": "papers/2511.06582v1.pdf"
    },
    {
      "arxiv_id": "2511.06179v1",
      "title": "MemoriesDB: A Temporal-Semantic-Relational Database for Long-Term Agent Memory / Modeling Experience as a Graph of Temporal-Semantic Surfaces",
      "authors": [
        {
          "name": "Joel Ward"
        }
      ],
      "abstract": "We introduce MemoriesDB, a unified data architecture designed to avoid decoherence across time, meaning, and relation in long-term computational memory. Each memory is a time-semantic-relational entity-a structure that simultaneously encodes when an event occurred, what it means, and how it connects to other events. Built initially atop PostgreSQL with pgvector extensions, MemoriesDB combines the properties of a time-series datastore, a vector database, and a graph system within a single append-only schema. Each memory is represented as a vertex uniquely labeled by its microsecond timestamp and accompanied by low- and high-dimensional normalized embeddings that capture semantic context. Directed edges between memories form labeled relations with per-edge metadata, enabling multiple contextual links between the same vertices. Together these constructs form a time-indexed stack of temporal-semantic surfaces, where edges project as directional arrows in a 1+1-dimensional similarity field, tracing the evolution of meaning through time while maintaining cross-temporal coherence. This formulation supports efficient time-bounded retrieval, hybrid semantic search, and lightweight structural reasoning in a single query path. A working prototype demonstrates scalable recall and contextual reinforcement using standard relational infrastructure, and we discuss extensions toward a columnar backend, distributed clustering, and emergent topic modeling.",
      "primary_category": "cs.DB",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.IR"
      ],
      "published": "2025-11-09T01:41:55+00:00",
      "updated": "2025-11-09T01:41:55+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.06179v1",
      "file": "papers/2511.06179v1.pdf"
    },
    {
      "arxiv_id": "2511.06125v1",
      "title": "Evaluation of retrieval-based QA on QUEST-LOFT",
      "authors": [
        {
          "name": "Nathan Scales"
        },
        {
          "name": "Nathanael Schärli"
        },
        {
          "name": "Olivier Bousquet"
        }
      ],
      "abstract": "Despite the popularity of retrieval-augmented generation (RAG) as a solution for grounded QA in both academia and industry, current RAG methods struggle with questions where the necessary information is distributed across many documents or where retrieval needs to be combined with complex reasoning. Recently, the LOFT study has shown that this limitation also applies to approaches based on long-context language models, with the QUEST benchmark exhibiting particularly large headroom. In this paper, we provide an in-depth analysis of the factors contributing to the poor performance on QUEST-LOFT, publish updated numbers based on a thorough human evaluation, and demonstrate that RAG can be optimized to significantly outperform long-context approaches when combined with a structured output format containing reasoning and evidence, optionally followed by answer re-verification.",
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "published": "2025-11-08T20:30:45+00:00",
      "updated": "2025-11-08T20:30:45+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.06125v1",
      "file": "papers/2511.06125v1.pdf"
    },
    {
      "arxiv_id": "2511.05991v1",
      "title": "Ontology Learning and Knowledge Graph Construction: A Comparison of Approaches and Their Impact on RAG Performance",
      "authors": [
        {
          "name": "Tiago da Cruz"
        },
        {
          "name": "Bernardo Tavares"
        },
        {
          "name": "Francisco Belo"
        }
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) systems combine Large Language Models (LLMs) with external knowledge, and their performance depends heavily on how that knowledge is represented. This study investigates how different Knowledge Graph (KG) construction strategies influence RAG performance. We compare a variety of approaches: standard vector-based RAG, GraphRAG, and retrieval over KGs built from ontologies derived either from relational databases or textual corpora. Results show that ontology-guided KGs incorporating chunk information achieve competitive performance with state-of-the-art frameworks, substantially outperforming vector retrieval baselines. Moreover, the findings reveal that ontology-guided KGs built from relational databases perform competitively to ones built with ontologies extracted from text, with the benefit of offering a dual advantage: they require a one-time-only ontology learning process, substantially reducing LLM usage costs; and avoid the complexity of ontology merging inherent to text-based approaches.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "published": "2025-11-08T12:38:45+00:00",
      "updated": "2025-11-08T12:38:45+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.05991v1",
      "file": "papers/2511.05991v1.pdf"
    },
    {
      "arxiv_id": "2511.05850v1",
      "title": "Retrieval Quality at Context Limit",
      "authors": [
        {
          "name": "Max McKinnon"
        }
      ],
      "abstract": "The ability of large language models (LLMs) to recall and retrieve information from long contexts is critical for many real-world applications. Prior work (Liu et al., 2023) reported that LLMs suffer significant drops in retrieval accuracy for facts placed in the middle of large contexts, an effect known as \"Lost in the Middle\" (LITM). We find the model Gemini 2.5 Flash can answer needle-in-a-haystack questions with great accuracy regardless of document position including when the document is nearly at the input context limit. Our results suggest that the \"Lost in the Middle\" effect is not present for simple factoid Q\\&A in Gemini 2.5 Flash, indicating substantial improvements in long-context retrieval.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "published": "2025-11-08T04:54:29+00:00",
      "updated": "2025-11-08T04:54:29+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.05850v1",
      "file": "papers/2511.05850v1.pdf"
    },
    {
      "arxiv_id": "2511.05684v1",
      "title": "A Representation Sharpening Framework for Zero Shot Dense Retrieval",
      "authors": [
        {
          "name": "Dhananjay Ashok"
        },
        {
          "name": "Suraj Nair"
        },
        {
          "name": "Mutasem Al-Darabsah"
        },
        {
          "name": "Choon Hui Teo"
        },
        {
          "name": "Tarun Agarwal"
        },
        {
          "name": "Jonathan May"
        }
      ],
      "abstract": "Zero-shot dense retrieval is a challenging setting where a document corpus is provided without relevant queries, necessitating a reliance on pretrained dense retrievers (DRs). However, since these DRs are not trained on the target corpus, they struggle to represent semantic differences between similar documents. To address this failing, we introduce a training-free representation sharpening framework that augments a document's representation with information that helps differentiate it from similar documents in the corpus. On over twenty datasets spanning multiple languages, the representation sharpening framework proves consistently superior to traditional retrieval, setting a new state-of-the-art on the BRIGHT benchmark. We show that representation sharpening is compatible with prior approaches to zero-shot dense retrieval and consistently improves their performance. Finally, we address the performance-cost tradeoff presented by our framework and devise an indexing-time approximation that preserves the majority of our performance gains over traditional retrieval, yet suffers no additional inference-time cost.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.CL"
      ],
      "published": "2025-11-07T20:07:46+00:00",
      "updated": "2025-11-07T20:07:46+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.05684v1",
      "file": "papers/2511.05684v1.pdf"
    },
    {
      "arxiv_id": "2511.05667v1",
      "title": "SARCH: Multimodal Search for Archaeological Archives",
      "authors": [
        {
          "name": "Nivedita Sinha"
        },
        {
          "name": "Bharati Khanijo"
        },
        {
          "name": "Sanskar Singh"
        },
        {
          "name": "Priyansh Mahant"
        },
        {
          "name": "Ashutosh Roy"
        },
        {
          "name": "Saubhagya Singh Bhadouria"
        },
        {
          "name": "Arpan Jain"
        },
        {
          "name": "Maya Ramanath"
        }
      ],
      "abstract": "In this paper, we describe a multi-modal search system designed to search old archaeological books and reports. This corpus is digitally available as scanned PDFs, but varies widely in the quality of scans. Our pipeline, designed for multi-modal archaeological documents, extracts and indexes text, images (classified into maps, photos, layouts, and others), and tables. We evaluated different retrieval strategies, including keyword-based search, embedding-based models, and a hybrid approach that selects optimal results from both modalities. We report and analyze our preliminary results and discuss future work in this exciting vertical.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2025-11-07T19:09:57+00:00",
      "updated": "2025-11-07T19:09:57+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.05667v1",
      "file": "papers/2511.05667v1.pdf"
    },
    {
      "arxiv_id": "2511.05385v1",
      "title": "TeaRAG: A Token-Efficient Agentic Retrieval-Augmented Generation Framework",
      "authors": [
        {
          "name": "Chao Zhang"
        },
        {
          "name": "Yuhao Wang"
        },
        {
          "name": "Derong Xu"
        },
        {
          "name": "Haoxin Zhang"
        },
        {
          "name": "Yuanjie Lyu"
        },
        {
          "name": "Yuhao Chen"
        },
        {
          "name": "Shuochen Liu"
        },
        {
          "name": "Tong Xu"
        },
        {
          "name": "Xiangyu Zhao"
        },
        {
          "name": "Yan Gao"
        },
        {
          "name": "Yao Hu"
        },
        {
          "name": "Enhong Chen"
        }
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) utilizes external knowledge to augment Large Language Models' (LLMs) reliability. For flexibility, agentic RAG employs autonomous, multi-round retrieval and reasoning to resolve queries. Although recent agentic RAG has improved via reinforcement learning, they often incur substantial token overhead from search and reasoning processes. This trade-off prioritizes accuracy over efficiency. To address this issue, this work proposes TeaRAG, a token-efficient agentic RAG framework capable of compressing both retrieval content and reasoning steps. 1) First, the retrieved content is compressed by augmenting chunk-based semantic retrieval with a graph retrieval using concise triplets. A knowledge association graph is then built from semantic similarity and co-occurrence. Finally, Personalized PageRank is leveraged to highlight key knowledge within this graph, reducing the number of tokens per retrieval. 2) Besides, to reduce reasoning steps, Iterative Process-aware Direct Preference Optimization (IP-DPO) is proposed. Specifically, our reward function evaluates the knowledge sufficiency by a knowledge matching mechanism, while penalizing excessive reasoning steps. This design can produce high-quality preference-pair datasets, supporting iterative DPO to improve reasoning conciseness. Across six datasets, TeaRAG improves the average Exact Match by 4% and 2% while reducing output tokens by 61% and 59% on Llama3-8B-Instruct and Qwen2.5-14B-Instruct, respectively. Code is available at https://github.com/Applied-Machine-Learning-Lab/TeaRAG.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "published": "2025-11-07T16:08:34+00:00",
      "updated": "2025-11-07T16:08:34+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.05385v1",
      "file": "papers/2511.05385v1.pdf"
    },
    {
      "arxiv_id": "2511.05301v1",
      "title": "QUESTER: Query Specification for Generative Retrieval",
      "authors": [
        {
          "name": "Arthur Satouf"
        },
        {
          "name": "Yuxuan Zong"
        },
        {
          "name": "Habiboulaye Amadou-Boubacar"
        },
        {
          "name": "Pablo Piantanida"
        },
        {
          "name": "Benjamin Piwowarski"
        }
      ],
      "abstract": "Generative Retrieval (GR) differs from the traditional index-then-retrieve pipeline by storing relevance in model parameters and directly generating document identifiers. However, GR often struggles to generalize and is costly to scale. We introduce QUESTER (QUEry SpecificaTion gEnerative Retrieval), which reframes GR as query specification generation - in this work, a simple keyword query handled by BM25 - using a (small) LLM. The policy is trained using reinforcement learning techniques (GRPO). Across in- and out-of-domain evaluations, we show that our model is more effective than BM25, and competitive with neural IR models, while maintaining a good efficiency",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.CL",
        "cs.LG"
      ],
      "published": "2025-11-07T15:01:38+00:00",
      "updated": "2025-11-07T15:01:38+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.05301v1",
      "file": "papers/2511.05301v1.pdf"
    },
    {
      "arxiv_id": "2511.05079v1",
      "title": "Wikipedia-based Datasets in Russian Information Retrieval Benchmark RusBEIR",
      "authors": [
        {
          "name": "Grigory Kovalev"
        },
        {
          "name": "Natalia Loukachevitch"
        },
        {
          "name": "Mikhail Tikhomirov"
        },
        {
          "name": "Olga Babina"
        },
        {
          "name": "Pavel Mamaev"
        }
      ],
      "abstract": "In this paper, we present a novel series of Russian information retrieval datasets constructed from the \"Did you know...\" section of Russian Wikipedia. Our datasets support a range of retrieval tasks, including fact-checking, retrieval-augmented generation, and full-document retrieval, by leveraging interesting facts and their referenced Wikipedia articles annotated at the sentence level with graded relevance. We describe the methodology for dataset creation that enables the expansion of existing Russian Information Retrieval (IR) resources. Through extensive experiments, we extend the RusBEIR research by comparing lexical retrieval models, such as BM25, with state-of-the-art neural architectures fine-tuned for Russian, as well as multilingual models. Results of our experiments show that lexical methods tend to outperform neural models on full-document retrieval, while neural approaches better capture lexical semantics in shorter texts, such as in fact-checking or fine-grained retrieval. Using our newly created datasets, we also analyze the impact of document length on retrieval performance and demonstrate that combining retrieval with neural reranking consistently improves results. Our contribution expands the resources available for Russian information retrieval research and highlights the importance of accurate evaluation of retrieval models to achieve optimal performance. All datasets are publicly available at HuggingFace. To facilitate reproducibility and future research, we also release the full implementation on GitHub.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.CL"
      ],
      "published": "2025-11-07T08:53:34+00:00",
      "updated": "2025-11-07T08:53:34+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.05079v1",
      "file": "papers/2511.05079v1.pdf"
    },
    {
      "arxiv_id": "2511.05000v1",
      "title": "Query Generation Pipeline with Enhanced Answerability Assessment for Financial Information Retrieval",
      "authors": [
        {
          "name": "Hyunkyu Kim"
        },
        {
          "name": "Yeeun Yoo"
        },
        {
          "name": "Youngjun Kwak"
        }
      ],
      "abstract": "As financial applications of large language models (LLMs) gain attention, accurate Information Retrieval (IR) remains crucial for reliable AI services. However, existing benchmarks fail to capture the complex and domain-specific information needs of real-world banking scenarios. Building domain-specific IR benchmarks is costly and constrained by legal restrictions on using real customer data. To address these challenges, we propose a systematic methodology for constructing domain-specific IR benchmarks through LLM-based query generation. As a concrete implementation of this methodology, our pipeline combines single and multi-document query generation with an enhanced and reasoning-augmented answerability assessment method, achieving stronger alignment with human judgments than prior approaches. Using this methodology, we construct KoBankIR, comprising 815 queries derived from 204 official banking documents. Our experiments show that existing retrieval models struggle with the complex multi-document queries in KoBankIR, demonstrating the value of our systematic approach for domain-specific benchmark construction and underscoring the need for improved retrieval techniques in financial domains.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "published": "2025-11-07T06:06:09+00:00",
      "updated": "2025-11-07T06:06:09+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.05000v1",
      "file": "papers/2511.05000v1.pdf"
    },
    {
      "arxiv_id": "2511.04939v2",
      "title": "Search Is Not Retrieval: Decoupling Semantic Matching from Contextual Assembly in RAG",
      "authors": [
        {
          "name": "Harshit Nainwani"
        },
        {
          "name": "Hediyeh Baban"
        }
      ],
      "abstract": "Retrieval systems are essential to contemporary AI pipelines, although most confuse two separate processes: finding relevant information and giving enough context for reasoning. We introduce the Search-Is-Not-Retrieve (SINR) framework, a dual-layer architecture that distinguishes between fine-grained search representations and coarse-grained retrieval contexts. SINR enhances the composability, scalability, and context fidelity of retrieval systems by directly connecting small, semantically accurate search chunks to larger, contextually complete retrieve chunks, all without incurring extra processing costs. This design changes retrieval from a passive step to an active one, making the system architecture more like how people process information. We discuss the SINR framework's conceptual foundation, formal structure, implementation issues, and qualitative outcomes. This provides a practical foundation for the next generation of AI systems that use retrieval.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "published": "2025-11-07T02:51:20+00:00",
      "updated": "2025-11-12T19:30:34+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.04939v2",
      "file": "papers/2511.04939v2.pdf"
    },
    {
      "arxiv_id": "2511.04901v1",
      "title": "Association via Entropy Reduction",
      "authors": [
        {
          "name": "Anthony Gamst"
        },
        {
          "name": "Lawrence Wilson"
        }
      ],
      "abstract": "Prior to recent successes using neural networks, term frequency-inverse document frequency (tf-idf) was clearly regarded as the best choice for identifying documents related to a query. We provide a different score, aver, and observe, on a dataset with ground truth marking for association, that aver does do better at finding assciated pairs than tf-idf. This example involves finding associated vertices in a large graph and that may be an area where neural networks are not currently an obvious best choice. Beyond this one anecdote, we observe that (1) aver has a natural threshold for declaring pairs as unassociated while tf-idf does not, (2) aver can distinguish between pairs of documents for which tf-idf gives a score of 1.0, (3) aver can be applied to larger collections of documents than pairs while tf-idf cannot, and (4) that aver is derived from entropy under a simple statistical model while tf-idf is a construction designed to achieve a certain goal and hence aver may be more \"natural.\" To be fair, we also observe that (1) writing down and computing the aver score for a pair is more complex than for tf-idf and (2) that the fact that the aver score is naturally scale-free makes it more complicated to interpret aver scores.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.CL"
      ],
      "published": "2025-11-07T01:03:48+00:00",
      "updated": "2025-11-07T01:03:48+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.04901v1",
      "file": "papers/2511.04901v1.pdf"
    },
    {
      "arxiv_id": "2511.04473v2",
      "title": "Ground-Truth Subgraphs for Better Training and Evaluation of Knowledge Graph Augmented LLMs",
      "authors": [
        {
          "name": "Alberto Cattaneo"
        },
        {
          "name": "Carlo Luschi"
        },
        {
          "name": "Daniel Justus"
        }
      ],
      "abstract": "Retrieval of information from graph-structured knowledge bases represents a promising direction for improving the factuality of LLMs. While various solutions have been proposed, a comparison of methods is difficult due to the lack of challenging QA datasets with ground-truth targets for graph retrieval. We present SynthKGQA, an LLM-powered framework for generating high-quality Knowledge Graph Question Answering datasets from any Knowledge Graph, providing the full set of ground-truth facts in the KG to reason over questions. We show how, in addition to enabling more informative benchmarking of KG retrievers, the data produced with SynthKGQA also allows us to train better models.We apply SynthKGQA to Wikidata to generate GTSQA, a new dataset designed to test zero-shot generalization abilities of KG retrievers with respect to unseen graph structures and relation types, and benchmark popular solutions for KG-augmented LLMs on it.",
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ],
      "published": "2025-11-06T15:45:18+00:00",
      "updated": "2025-12-04T08:34:50+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.04473v2",
      "file": "papers/2511.04473v2.pdf"
    },
    {
      "arxiv_id": "2511.04247v2",
      "title": "On the Brittleness of CLIP Text Encoders",
      "authors": [
        {
          "name": "Allie Tran"
        },
        {
          "name": "Luca Rossetto"
        }
      ],
      "abstract": "Multimodal co-embedding models, especially CLIP, have advanced the state of the art in zero-shot classification and multimedia information retrieval in recent years by aligning images and text in a shared representation space. However, such modals trained on a contrastive alignment can lack stability towards small input perturbations. Especially when dealing with manually expressed queries, minor variations in the query can cause large differences in the ranking of the best-matching results. In this paper, we present a systematic analysis of the effect of multiple classes of non-semantic query perturbations in an multimedia information retrieval scenario. We evaluate a diverse set of lexical, syntactic, and semantic perturbations across multiple CLIP variants using the TRECVID Ad-Hoc Video Search queries and the V3C1 video collection. Across models, we find that syntactic and semantic perturbations drive the largest instabilities, while brittleness is concentrated in trivial surface edits such as punctuation and case. Our results highlight robustness as a critical dimension for evaluating vision-language models beyond benchmark accuracy.",
      "primary_category": "cs.MM",
      "categories": [
        "cs.MM",
        "cs.AI",
        "cs.IR"
      ],
      "published": "2025-11-06T10:33:55+00:00",
      "updated": "2025-11-07T18:05:14+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.04247v2",
      "file": "papers/2511.04247v2.pdf"
    },
    {
      "arxiv_id": "2511.04221v1",
      "title": "Coordination-Free Lane Partitioning for Convergent ANN Search",
      "authors": [
        {
          "name": "Carl Kugblenu"
        },
        {
          "name": "Petri Vuorimaa"
        }
      ],
      "abstract": "Production vector search systems often fan out each query across parallel lanes (threads, replicas, or shards) to meet latency service-level objectives (SLOs). In practice, these lanes rediscover the same candidates, so extra compute does not increase coverage. We present a coordination-free lane partitioner that turns duplication into complementary work at the same cost and deadline. For each query we (1) build a deterministic candidate pool sized to the total top-k budget, (2) apply a per-query pseudorandom permutation, and (3) assign each lane a disjoint slice of positions. Lanes then return different results by construction, with no runtime coordination.\n  At equal cost with four lanes (total candidate budget 64), on SIFT1M (1M SIFT feature vectors) with Hierarchical Navigable Small World graphs (HNSW) recall@10 rises from 0.249 to 0.999 while lane overlap falls from nearly 100% to 0%. On MS MARCO (8.8M passages) with HNSW, hit@10 improves from 0.200 to 0.601 and Mean Reciprocal Rank at 10 (MRR@10) from 0.133 to 0.330. For inverted file (IVF) indexes we see smaller but consistent gains (for example, +11% on MS MARCO) by de-duplicating list routing. A microbenchmark shows planner overhead of ~37 microseconds per query (mean at the main setting) with linear growth in the number of merged candidates.\n  These results yield a simple operational guideline: size the per-query pool to the total budget, deterministically partition positions across lanes, and turn redundant fan-out into complementary coverage without changing budget or deadline.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.DB"
      ],
      "published": "2025-11-06T09:36:18+00:00",
      "updated": "2025-11-06T09:36:18+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.04221v1",
      "file": "papers/2511.04221v1.pdf"
    },
    {
      "arxiv_id": "2511.04087v1",
      "title": "E-CARE: An Efficient LLM-based Commonsense-Augmented Framework for E-Commerce",
      "authors": [
        {
          "name": "Ge Zhang"
        },
        {
          "name": "Rohan Deepak Ajwani"
        },
        {
          "name": "Tony Zheng"
        },
        {
          "name": "Hongjian Gu"
        },
        {
          "name": "Yaochen Hu"
        },
        {
          "name": "Wei Guo"
        },
        {
          "name": "Mark Coates"
        },
        {
          "name": "Yingxue Zhang"
        }
      ],
      "abstract": "Finding relevant products given a user query plays a pivotal role in an e-commerce platform, as it can spark shopping behaviors and result in revenue gains. The challenge lies in accurately predicting the correlation between queries and products. Recently, mining the cross-features between queries and products based on the commonsense reasoning capacity of Large Language Models (LLMs) has shown promising performance. However, such methods suffer from high costs due to intensive real-time LLM inference during serving, as well as human annotations and potential Supervised Fine Tuning (SFT). To boost efficiency while leveraging the commonsense reasoning capacity of LLMs for various e-commerce tasks, we propose the Efficient Commonsense-Augmented Recommendation Enhancer (E-CARE). During inference, models augmented with E-CARE can access commonsense reasoning with only a single LLM forward pass per query by utilizing a commonsense reasoning factor graph that encodes most of the reasoning schema from powerful LLMs. The experiments on 2 downstream tasks show an improvement of up to 12.1% on precision@5.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2025-11-06T05:57:48+00:00",
      "updated": "2025-11-06T05:57:48+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.04087v1",
      "file": "papers/2511.04087v1.pdf"
    },
    {
      "arxiv_id": "2511.04073v1",
      "title": "Learning Filter-Aware Distance Metrics for Nearest Neighbor Search with Multiple Filters",
      "authors": [
        {
          "name": "Ananya Sutradhar"
        },
        {
          "name": "Suryansh Gupta"
        },
        {
          "name": "Ravishankar Krishnaswamy"
        },
        {
          "name": "Haiyang Xu"
        },
        {
          "name": "Aseem Rastogi"
        },
        {
          "name": "Gopal Srinivasa"
        }
      ],
      "abstract": "Filtered Approximate Nearest Neighbor (ANN) search retrieves the closest vectors for a query vector from a dataset. It enforces that a specified set of discrete labels $S$ for the query must be included in the labels of each retrieved vector. Existing graph-based methods typically incorporate filter awareness by assigning fixed penalties or prioritizing nodes based on filter satisfaction. However, since these methods use fixed, data in- dependent penalties, they often fail to generalize across datasets with diverse label and vector distributions. In this work, we propose a principled alternative that learns the optimal trade-off between vector distance and filter match directly from the data, rather than relying on fixed penalties. We formulate this as a constrained linear optimization problem, deriving weights that better reflect the underlying filter distribution and more effectively address the filtered ANN search problem. These learned weights guide both the search process and index construction, leading to graph structures that more effectively capture the underlying filter distribution and filter semantics. Our experiments demonstrate that adapting the distance function to the data significantly im- proves accuracy by 5-10% over fixed-penalty methods, providing a more flexible and generalizable framework for the filtered ANN search problem.",
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.DB",
        "cs.IR"
      ],
      "published": "2025-11-06T05:24:41+00:00",
      "updated": "2025-11-06T05:24:41+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.04073v1",
      "file": "papers/2511.04073v1.pdf"
    },
    {
      "arxiv_id": "2511.03620v1",
      "title": "CLAX: Fast and Flexible Neural Click Models in JAX",
      "authors": [
        {
          "name": "Philipp Hager"
        },
        {
          "name": "Onno Zoeter"
        },
        {
          "name": "Maarten de Rijke"
        }
      ],
      "abstract": "CLAX is a JAX-based library that implements classic click models using modern gradient-based optimization. While neural click models have emerged over the past decade, complex click models based on probabilistic graphical models (PGMs) have not systematically adopted gradient-based optimization, preventing practitioners from leveraging modern deep learning frameworks while preserving the interpretability of classic models. CLAX addresses this gap by replacing EM-based optimization with direct gradient-based optimization in a numerically stable manner. The framework's modular design enables the integration of any component, from embeddings and deep networks to custom modules, into classic click models for end-to-end optimization. We demonstrate CLAX's efficiency by running experiments on the full Baidu-ULTR dataset comprising over a billion user sessions in $\\approx$ 2 hours on a single GPU, orders of magnitude faster than traditional EM approaches. CLAX implements ten classic click models, serving both industry practitioners seeking to understand user behavior and improve ranking performance at scale and researchers developing new click models. CLAX is available at: https://github.com/philipphager/clax",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.LG",
        "cs.SE"
      ],
      "published": "2025-11-05T16:39:10+00:00",
      "updated": "2025-11-05T16:39:10+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.03620v1",
      "file": "papers/2511.03620v1.pdf"
    },
    {
      "arxiv_id": "2511.03330v1",
      "title": "Discourse-Aware Scientific Paper Recommendation via QA-Style Summarization and Multi-Level Contrastive Learning",
      "authors": [
        {
          "name": "Shenghua Wang"
        },
        {
          "name": "Zhen Yin"
        }
      ],
      "abstract": "The rapid growth of open-access (OA) publications has intensified the challenge of identifying relevant scientific papers. Due to privacy constraints and limited access to user interaction data, recent efforts have shifted toward content-based recommendation, which relies solely on textual information. However, existing models typically treat papers as unstructured text, neglecting their discourse organization and thereby limiting semantic completeness and interpretability. To address these limitations, we propose OMRC-MR, a hierarchical framework that integrates QA-style OMRC (Objective, Method, Result, Conclusion) summarization, multi-level contrastive learning, and structure-aware re-ranking for scholarly recommendation. The QA-style summarization module converts raw papers into structured and discourse-consistent representations, while multi-level contrastive objectives align semantic representations across metadata, section, and document levels. The final re-ranking stage further refines retrieval precision through contextual similarity calibration. Experiments on DBLP, S2ORC, and the newly constructed Sci-OMRC dataset demonstrate that OMRC-MR consistently surpasses state-of-the-art baselines, achieving up to 7.2% and 3.8% improvements in Precision@10 and Recall@10, respectively. Additional evaluations confirm that QA-style summarization produces more coherent and factually complete representations. Overall, OMRC-MR provides a unified and interpretable content-based paradigm for scientific paper recommendation, advancing trustworthy and privacy-aware scholarly information retrieval.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "published": "2025-11-05T09:55:12+00:00",
      "updated": "2025-11-05T09:55:12+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.03330v1",
      "file": "papers/2511.03330v1.pdf"
    },
    {
      "arxiv_id": "2511.03298v1",
      "title": "KScaNN: Scalable Approximate Nearest Neighbor Search on Kunpeng",
      "authors": [
        {
          "name": "Oleg Senkevich"
        },
        {
          "name": "Siyang Xu"
        },
        {
          "name": "Tianyi Jiang"
        },
        {
          "name": "Alexander Radionov"
        },
        {
          "name": "Jan Tabaszewski"
        },
        {
          "name": "Dmitriy Malyshev"
        },
        {
          "name": "Zijian Li"
        },
        {
          "name": "Daihao Xue"
        },
        {
          "name": "Licheng Yu"
        },
        {
          "name": "Weidi Zeng"
        },
        {
          "name": "Meiling Wang"
        },
        {
          "name": "Xin Yao"
        },
        {
          "name": "Siyu Huang"
        },
        {
          "name": "Gleb Neshchetkin"
        },
        {
          "name": "Qiuling Pan"
        },
        {
          "name": "Yaoyao Fu"
        }
      ],
      "abstract": "Approximate Nearest Neighbor Search (ANNS) is a cornerstone algorithm for information retrieval, recommendation systems, and machine learning applications. While x86-based architectures have historically dominated this domain, the increasing adoption of ARM-based servers in industry presents a critical need for ANNS solutions optimized on ARM architectures. A naive port of existing x86 ANNS algorithms to ARM platforms results in a substantial performance deficit, failing to leverage the unique capabilities of the underlying hardware. To address this challenge, we introduce KScaNN, a novel ANNS algorithm co-designed for the Kunpeng 920 ARM architecture. KScaNN embodies a holistic approach that synergizes sophisticated, data aware algorithmic refinements with carefully-designed hardware specific optimizations. Its core contributions include: 1) novel algorithmic techniques, including a hybrid intra-cluster search strategy and an improved PQ residual calculation method, which optimize the search process at a higher level; 2) an ML-driven adaptive search module that provides adaptive, per-query tuning of search parameters, eliminating the inefficiencies of static configurations; and 3) highly-optimized SIMD kernels for ARM that maximize hardware utilization for the critical distance computation workloads. The experimental results demonstrate that KScaNN not only closes the performance gap but establishes a new standard, achieving up to a 1.63x speedup over the fastest x86-based solution. This work provides a definitive blueprint for achieving leadership-class performance for vector search on modern ARM architectures and underscores",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2025-11-05T09:01:32+00:00",
      "updated": "2025-11-05T09:01:32+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.03298v1",
      "file": "papers/2511.03298v1.pdf"
    },
    {
      "arxiv_id": "2511.03228v1",
      "title": "Beyond Ranked Lists: The SARAL Framework for Cross-Lingual Document Set Retrieval",
      "authors": [
        {
          "name": "Shantanu Agarwal"
        },
        {
          "name": "Joel Barry"
        },
        {
          "name": "Elizabeth Boschee"
        },
        {
          "name": "Scott Miller"
        }
      ],
      "abstract": "Machine Translation for English Retrieval of Information in Any Language (MATERIAL) is an IARPA initiative targeted to advance the state of cross-lingual information retrieval (CLIR). This report provides a detailed description of Information Sciences Institute's (ISI's) Summarization and domain-Adaptive Retrieval Across Language's (SARAL's) effort for MATERIAL. Specifically, we outline our team's novel approach to handle CLIR with emphasis in developing an approach amenable to retrieve a query-relevant document \\textit{set}, and not just a ranked document-list. In MATERIAL's Phase-3 evaluations, SARAL exceeded the performance of other teams in five out of six evaluation conditions spanning three different languages (Farsi, Kazakh, and Georgian).",
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.IR"
      ],
      "published": "2025-11-05T06:35:33+00:00",
      "updated": "2025-11-05T06:35:33+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.03228v1",
      "file": "papers/2511.03228v1.pdf"
    },
    {
      "arxiv_id": "2511.02770v1",
      "title": "Beyond Single Embeddings: Capturing Diverse Targets with Multi-Query Retrieval",
      "authors": [
        {
          "name": "Hung-Ting Chen"
        },
        {
          "name": "Xiang Liu"
        },
        {
          "name": "Shauli Ravfogel"
        },
        {
          "name": "Eunsol Choi"
        }
      ],
      "abstract": "Most text retrievers generate \\emph{one} query vector to retrieve relevant documents. Yet, the conditional distribution of relevant documents for the query may be multimodal, e.g., representing different interpretations of the query. We first quantify the limitations of existing retrievers. All retrievers we evaluate struggle more as the distance between target document embeddings grows. To address this limitation, we develop a new retriever architecture, \\emph{A}utoregressive \\emph{M}ulti-\\emph{E}mbedding \\emph{R}etriever (AMER). Our model autoregressively generates multiple query vectors, and all the predicted query vectors are used to retrieve documents from the corpus. We show that on the synthetic vectorized data, the proposed method could capture multiple target distributions perfectly, showing 4x better performance than single embedding model. We also fine-tune our model on real-world multi-answer retrieval datasets and evaluate in-domain. AMER presents 4 and 21\\% relative gains over single-embedding baselines on two datasets we evaluate on. Furthermore, we consistently observe larger gains on the subset of dataset where the embeddings of the target documents are less similar to each other. We demonstrate the potential of using a multi-query vector retriever and open up a new direction for future work.",
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.IR"
      ],
      "published": "2025-11-04T17:57:20+00:00",
      "updated": "2025-11-04T17:57:20+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.02770v1",
      "file": "papers/2511.02770v1.pdf"
    },
    {
      "arxiv_id": "2511.02571v1",
      "title": "Average Precision at Cutoff k under Random Rankings: Expectation and Variance",
      "authors": [
        {
          "name": "Tetiana Manzhos"
        },
        {
          "name": "Tetiana Ianevych"
        },
        {
          "name": "Olga Melnyk"
        }
      ],
      "abstract": "Recommender systems and information retrieval platforms rely on ranking algorithms to present the most relevant items to users, thereby improving engagement and satisfaction. Assessing the quality of these rankings requires reliable evaluation metrics. Among them, Mean Average Precision at cutoff k (MAP@k) is widely used, as it accounts for both the relevance of items and their positions in the list.\n  In this paper, the expectation and variance of Average Precision at k (AP@k) are derived since they can be used as biselines for MAP@k. Here, we covered two widely used evaluation models: offline and online. The expectation establishes the baseline, indicating the level of MAP@k that can be achieved by pure chance. The variance complements this baseline by quantifying the extent of random fluctuations, enabling a more reliable interpretation of observed scores.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "math.PR"
      ],
      "published": "2025-11-04T13:45:16+00:00",
      "updated": "2025-11-04T13:45:16+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.02571v1",
      "file": "papers/2511.02571v1.pdf"
    },
    {
      "arxiv_id": "2511.02358v1",
      "title": "Let Multimodal Embedders Learn When to Augment Query via Adaptive Query Augmentation",
      "authors": [
        {
          "name": "Wongyu Kim"
        },
        {
          "name": "Hochang Lee"
        },
        {
          "name": "Sanghak Lee"
        },
        {
          "name": "Yoonsung Kim"
        },
        {
          "name": "Jaehyun Park"
        }
      ],
      "abstract": "Query augmentation makes queries more meaningful by appending further information to the queries to find relevant documents. Current studies have proposed Large Language Model (LLM)-based embedders, which learn representation for embedding and generation for query augmentation in a multi-task manner by leveraging the generative capabilities of LLM. During inference, these jointly trained embedders have conducted query augmentation followed by embedding, showing effective results. However, augmenting every query leads to substantial embedding latency and query augmentation can be detrimental to performance for some queries. Also, previous methods have not been explored in multimodal environments. To tackle these problems, we propose M-Solomon, a universal multimodal embedder that can adaptively determine when to augment queries. Our approach first divides the queries of the training datasets into two groups at the dataset level. One includes queries that require augmentation and the other includes queries that do not. Then, we introduces a synthesis process that generates appropriate augmentations for queries that require them by leveraging a powerful Multimodal LLM (MLLM). Next, we present adaptive query augmentation. Through this step, M-Solomon can conduct query augmentation only when necessary by learning to generate synthetic augmentations with the prefix /augment for queries that demand them and to generate the simple string /embed for others. Experimental results showed that M-Solomon not only surpassed the baseline without augmentation by a large margin but also outperformed the baseline that always used augmentation, providing much faster embedding latency.",
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG",
        "cs.MM"
      ],
      "published": "2025-11-04T08:24:41+00:00",
      "updated": "2025-11-04T08:24:41+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.02358v1",
      "file": "papers/2511.02358v1.pdf"
    },
    {
      "arxiv_id": "2512.16925v1",
      "title": "V-Agent: An Interactive Video Search System Using Vision-Language Models",
      "authors": [
        {
          "name": "SunYoung Park"
        },
        {
          "name": "Jong-Hyeon Lee"
        },
        {
          "name": "Youngjune Kim"
        },
        {
          "name": "Daegyu Sung"
        },
        {
          "name": "Younghyun Yu"
        },
        {
          "name": "Young-rok Cha"
        },
        {
          "name": "Jeongho Ju"
        }
      ],
      "abstract": "We introduce V-Agent, a novel multi-agent platform designed for advanced video search and interactive user-system conversations. By fine-tuning a vision-language model (VLM) with a small video preference dataset and enhancing it with a retrieval vector from an image-text retrieval model, we overcome the limitations of traditional text-based retrieval systems in multimodal scenarios. The VLM-based retrieval model independently embeds video frames and audio transcriptions from an automatic speech recognition (ASR) module into a shared multimodal representation space, enabling V-Agent to interpret both visual and spoken content for context-aware video search. This system consists of three agents-a routing agent, a search agent, and a chat agent-that work collaboratively to address user intents by refining search outputs and communicating with users. The search agent utilizes the VLM-based retrieval model together with an additional re-ranking module to further enhance video retrieval quality. Our proposed framework demonstrates state-of-the-art zero-shot performance on the MultiVENT 2.0 benchmark, highlighting its potential for both academic research and real-world applications.",
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.IR",
        "cs.MA"
      ],
      "published": "2025-11-04T07:24:45+00:00",
      "updated": "2025-11-04T07:24:45+00:00",
      "pdf_url": "https://arxiv.org/pdf/2512.16925v1",
      "file": "papers/2512.16925v1.pdf"
    },
    {
      "arxiv_id": "2511.01857v1",
      "title": "Trove: A Flexible Toolkit for Dense Retrieval",
      "authors": [
        {
          "name": "Reza Esfandiarpoor"
        },
        {
          "name": "Max Zuo"
        },
        {
          "name": "Stephen H. Bach"
        }
      ],
      "abstract": "We introduce Trove, an easy-to-use open-source retrieval toolkit that simplifies research experiments without sacrificing flexibility or speed. For the first time, we introduce efficient data management features that load and process (filter, select, transform, and combine) retrieval datasets on the fly, with just a few lines of code. This gives users the flexibility to easily experiment with different dataset configurations without the need to compute and store multiple copies of large datasets. Trove is highly customizable: in addition to many built-in options, it allows users to freely modify existing components or replace them entirely with user-defined objects. It also provides a low-code and unified pipeline for evaluation and hard negative mining, which supports multi-node execution without any code changes. Trove's data management features reduce memory consumption by a factor of 2.6. Moreover, Trove's easy-to-use inference pipeline incurs no overhead, and inference times decrease linearly with the number of available nodes. Most importantly, we demonstrate how Trove simplifies retrieval experiments and allows for arbitrary customizations, thus facilitating exploratory research.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "published": "2025-11-03T18:59:57+00:00",
      "updated": "2025-11-03T18:59:57+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.01857v1",
      "file": "papers/2511.01857v1.pdf"
    },
    {
      "arxiv_id": "2511.01643v1",
      "title": "A Graph-based RAG for Energy Efficiency Question Answering",
      "authors": [
        {
          "name": "Riccardo Campi"
        },
        {
          "name": "Nicolò Oreste Pinciroli Vago"
        },
        {
          "name": "Mathyas Giudici"
        },
        {
          "name": "Pablo Barrachina Rodriguez-Guisado"
        },
        {
          "name": "Marco Brambilla"
        },
        {
          "name": "Piero Fraternali"
        }
      ],
      "abstract": "In this work, we investigate the use of Large Language Models (LLMs) within a graph-based Retrieval Augmented Generation (RAG) architecture for Energy Efficiency (EE) Question Answering. First, the system automatically extracts a Knowledge Graph (KG) from guidance and regulatory documents in the energy field. Then, the generated graph is navigated and reasoned upon to provide users with accurate answers in multiple languages. We implement a human-based validation using the RAGAs framework properties, a validation dataset comprising 101 question-answer pairs, and domain experts. Results confirm the potential of this architecture and identify its strengths and weaknesses. Validation results show how the system correctly answers in about three out of four of the cases (75.2 +- 2.7%), with higher results on questions related to more general EE answers (up to 81.0 +- 4.1%), and featuring promising multilingual abilities (4.4% accuracy loss due to translation).",
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "published": "2025-11-03T14:55:34+00:00",
      "updated": "2025-11-03T14:55:34+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.01643v1",
      "file": "papers/2511.01643v1.pdf"
    },
    {
      "arxiv_id": "2511.01617v1",
      "title": "Vote-in-Context: Turning VLMs into Zero-Shot Rank Fusers",
      "authors": [
        {
          "name": "Mohamed Eltahir"
        },
        {
          "name": "Ali Habibullah"
        },
        {
          "name": "Lama Ayash"
        },
        {
          "name": "Tanveer Hussain"
        },
        {
          "name": "Naeemullah Khan"
        }
      ],
      "abstract": "In the retrieval domain, candidates' fusion from heterogeneous retrievers is a long-standing challenge, particularly for complex, multi-modal data such as videos. While typical fusion techniques are training-free, they rely solely on rank or score signals, disregarding candidates' representations. This work introduces Vote-in-Context (ViC), a generalized, training-free framework that re-thinks list-wise reranking and fusion as a zero-shot reasoning task for a Vision-Language Model (VLM). The core insight is to serialize both content evidence and retriever metadata directly within the VLM's prompt, allowing the model to adaptively weigh retriever consensus against visual-linguistic content. We demonstrate the generality of this framework by applying it to the challenging domain of cross-modal video retrieval. To this end, we introduce the S-Grid, a compact serialization map that represents each video as an image grid, optionally paired with subtitles to enable list-wise reasoning over video candidates. ViC is evaluated both as a single-list reranker, where it dramatically improves the precision of individual retrievers, and as an ensemble fuser, where it consistently outperforms strong baselines like CombSUM. Across video retrieval benchmarks including ActivityNet and VATEX, the framework establishes new state-of-the-art zero-shot retrieval performance, demonstrating its effectiveness in handling complex visual and temporal signals alongside text. In zero-shot settings, ViC achieves Recall@1 scores of 87.1% (t2v) / 89.0% (v2t) on MSR-VTT and 99.6% (v2t) on VATEX, representing massive gains of up to +40 Recall@1 over previous state-of-the-art baselines. We present ViC as a simple, reproducible, and highly effective recipe for turning modern VLMs into powerful zero-shot rerankers and fusers. Code and resources are publicly available at: https://github.com/mohammad2012191/ViC",
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.IR"
      ],
      "published": "2025-11-03T14:25:12+00:00",
      "updated": "2025-11-03T14:25:12+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.01617v1",
      "file": "papers/2511.01617v1.pdf"
    },
    {
      "arxiv_id": "2511.01461v2",
      "title": "CAT-ID$^2$: Category-Tree Integrated Document Identifier Learning for Generative Retrieval In E-commerce",
      "authors": [
        {
          "name": "Xiaoyu Liu"
        },
        {
          "name": "Fuwei Zhang"
        },
        {
          "name": "Yiqing Wu"
        },
        {
          "name": "Xinyu Jia"
        },
        {
          "name": "Zenghua Xia"
        },
        {
          "name": "Fuzhen Zhuang"
        },
        {
          "name": "Zhao Zhang"
        },
        {
          "name": "Fei Jiang"
        },
        {
          "name": "Wei Lin"
        }
      ],
      "abstract": "Generative retrieval (GR) has gained significant attention as an effective paradigm that integrates the capabilities of large language models (LLMs). It generally consists of two stages: constructing discrete semantic identifiers (IDs) for documents and retrieving documents by autoregressively generating ID tokens. The core challenge in GR is how to construct document IDs (DocIDS) with strong representational power. Good IDs should exhibit two key properties: similar documents should have more similar IDs, and each document should maintain a distinct and unique ID. However, most existing methods ignore native category information, which is common and critical in E-commerce. Therefore, we propose a novel ID learning method, CAtegory-Tree Integrated Document IDentifier (CAT-ID$^2$), incorporating prior category information into the semantic IDs. CAT-ID$^2$ includes three key modules: a Hierarchical Class Constraint Loss to integrate category information layer by layer during quantization, a Cluster Scale Constraint Loss for uniform ID token distribution, and a Dispersion Loss to improve the distinction of reconstructed documents. These components enable CAT-ID$^2$ to generate IDs that make similar documents more alike while preserving the uniqueness of different documents' representations. Extensive offline and online experiments confirm the effectiveness of our method, with online A/B tests showing a 0.33% increase in average orders per thousand users for ambiguous intent queries and 0.24% for long-tail queries.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2025-11-03T11:21:35+00:00",
      "updated": "2025-11-04T03:29:25+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.01461v2",
      "file": "papers/2511.01461v2.pdf"
    },
    {
      "arxiv_id": "2511.01448v1",
      "title": "LiCoMemory: Lightweight and Cognitive Agentic Memory for Efficient Long-Term Reasoning",
      "authors": [
        {
          "name": "Zhengjun Huang"
        },
        {
          "name": "Zhoujin Tian"
        },
        {
          "name": "Qintian Guo"
        },
        {
          "name": "Fangyuan Zhang"
        },
        {
          "name": "Yingli Zhou"
        },
        {
          "name": "Di Jiang"
        },
        {
          "name": "Xiaofang Zhou"
        }
      ],
      "abstract": "Large Language Model (LLM) agents exhibit remarkable conversational and reasoning capabilities but remain constrained by limited context windows and the lack of persistent memory. Recent efforts address these limitations via external memory architectures, often employing graph-based representations, yet most adopt flat, entangled structures that intertwine semantics with topology, leading to redundant representations, unstructured retrieval, and degraded efficiency and accuracy. To resolve these issues, we propose LiCoMemory, an end-to-end agentic memory framework for real-time updating and retrieval, which introduces CogniGraph, a lightweight hierarchical graph that utilizes entities and relations as semantic indexing layers, and employs temporal and hierarchy-aware search with integrated reranking for adaptive and coherent knowledge retrieval. Experiments on long-term dialogue benchmarks, LoCoMo and LongMemEval, show that LiCoMemory not only outperforms established baselines in temporal reasoning, multi-session consistency, and retrieval efficiency, but also notably reduces update latency. Our official code and data are available at https://github.com/EverM0re/LiCoMemory.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2025-11-03T11:02:40+00:00",
      "updated": "2025-11-03T11:02:40+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.01448v1",
      "file": "papers/2511.01448v1.pdf"
    },
    {
      "arxiv_id": "2511.01386v1",
      "title": "RAGSmith: A Framework for Finding the Optimal Composition of Retrieval-Augmented Generation Methods Across Datasets",
      "authors": [
        {
          "name": "Muhammed Yusuf Kartal"
        },
        {
          "name": "Suha Kagan Kose"
        },
        {
          "name": "Korhan Sevinç"
        },
        {
          "name": "Burak Aktas"
        }
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) quality depends on many interacting choices across retrieval, ranking, augmentation, prompting, and generation, so optimizing modules in isolation is brittle. We introduce RAGSmith, a modular framework that treats RAG design as an end-to-end architecture search over nine technique families and 46{,}080 feasible pipeline configurations. A genetic search optimizes a scalar objective that jointly aggregates retrieval metrics (recall@k, mAP, nDCG, MRR) and generation metrics (LLM-Judge and semantic similarity). We evaluate on six Wikipedia-derived domains (Mathematics, Law, Finance, Medicine, Defense Industry, Computer Science), each with 100 questions spanning factual, interpretation, and long-answer types. RAGSmith finds configurations that consistently outperform naive RAG baseline by +3.8\\% on average (range +1.2\\% to +6.9\\% across domains), with gains up to +12.5\\% in retrieval and +7.5\\% in generation. The search typically explores $\\approx 0.2\\%$ of the space ($\\sim 100$ candidates) and discovers a robust backbone -- vector retrieval plus post-generation reflection/revision -- augmented by domain-dependent choices in expansion, reranking, augmentation, and prompt reordering; passage compression is never selected. Improvement magnitude correlates with question type, with larger gains on factual/long-answer mixes than interpretation-heavy sets. These results provide practical, domain-aware guidance for assembling effective RAG systems and demonstrate the utility of evolutionary search for full-pipeline optimization.",
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "published": "2025-11-03T09:36:27+00:00",
      "updated": "2025-11-03T09:36:27+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.01386v1",
      "file": "papers/2511.01386v1.pdf"
    },
    {
      "arxiv_id": "2511.01364v1",
      "title": "A semantic-based deep learning approach for mathematical expression retrieval",
      "authors": [
        {
          "name": "Pavan Kumar Perepu"
        }
      ],
      "abstract": "Mathematical expressions (MEs) have complex two-dimensional structures in which symbols can be present at any nested depth like superscripts, subscripts, above, below etc. As MEs are represented using LaTeX format, several text retrieval methods based on string matching, vector space models etc., have also been applied for ME retrieval problem in the literature. As these methods are based on syntactic similarity, recently deep learning approaches based on embedding have been used for semantic similarity. In our present work, we have focused on the retrieval of mathematical expressions using deep learning approaches. In our approach, semantic features are extracted from the MEs using a deep recurrent neural network (DRNN) and these features have been used for matching and retrieval. We have trained the network for a classification task which determines the complexity of an ME. ME complexity has been quantified in terms of its nested depth. Based on the nested depth, we have considered three complexity classes of MEs: Simple, Medium and Complex. After training the network, outputs just before the the final fully connected layer are extracted for all the MEs. These outputs form the semantic features of MEs and are stored in a database. For a given ME query, its semantic features are computed using the trained DRNN and matched against the semantic feature database. Matching is performed based on the standard euclidean distance and top 'k' nearest matches are retrieved, where 'k' is a user-defined parameter. Our approach has been illustrated on a database of 829 MEs.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.LG"
      ],
      "published": "2025-11-03T09:09:24+00:00",
      "updated": "2025-11-03T09:09:24+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.01364v1",
      "file": "papers/2511.01364v1.pdf"
    },
    {
      "arxiv_id": "2511.01268v1",
      "title": "Rescuing the Unpoisoned: Efficient Defense against Knowledge Corruption Attacks on RAG Systems",
      "authors": [
        {
          "name": "Minseok Kim"
        },
        {
          "name": "Hankook Lee"
        },
        {
          "name": "Hyungjoon Koo"
        }
      ],
      "abstract": "Large language models (LLMs) are reshaping numerous facets of our daily lives, leading widespread adoption as web-based services. Despite their versatility, LLMs face notable challenges, such as generating hallucinated content and lacking access to up-to-date information. Lately, to address such limitations, Retrieval-Augmented Generation (RAG) has emerged as a promising direction by generating responses grounded in external knowledge sources. A typical RAG system consists of i) a retriever that probes a group of relevant passages from a knowledge base and ii) a generator that formulates a response based on the retrieved content. However, as with other AI systems, recent studies demonstrate the vulnerability of RAG, such as knowledge corruption attacks by injecting misleading information. In response, several defense strategies have been proposed, including having LLMs inspect the retrieved passages individually or fine-tuning robust retrievers. While effective, such approaches often come with substantial computational costs.\n  In this work, we introduce RAGDefender, a resource-efficient defense mechanism against knowledge corruption (i.e., by data poisoning) attacks in practical RAG deployments. RAGDefender operates during the post-retrieval phase, leveraging lightweight machine learning techniques to detect and filter out adversarial content without requiring additional model training or inference. Our empirical evaluations show that RAGDefender consistently outperforms existing state-of-the-art defenses across multiple models and adversarial scenarios: e.g., RAGDefender reduces the attack success rate (ASR) against the Gemini model from 0.89 to as low as 0.02, compared to 0.69 for RobustRAG and 0.24 for Discern-and-Answer when adversarial passages outnumber legitimate ones by a factor of four (4x).",
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.IR"
      ],
      "published": "2025-11-03T06:39:58+00:00",
      "updated": "2025-11-03T06:39:58+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.01268v1",
      "file": "papers/2511.01268v1.pdf"
    },
    {
      "arxiv_id": "2511.01208v1",
      "title": "Contextual Relevance and Adaptive Sampling for LLM-Based Document Reranking",
      "authors": [
        {
          "name": "Jerry Huang"
        },
        {
          "name": "Siddarth Madala"
        },
        {
          "name": "Cheng Niu"
        },
        {
          "name": "Julia Hockenmaier"
        },
        {
          "name": "Tong Zhang"
        }
      ],
      "abstract": "Reranking algorithms have made progress in improving document retrieval quality by efficiently aggregating relevance judgments generated by large language models (LLMs). However, identifying relevant documents for queries that require in-depth reasoning remains a major challenge. Reasoning-intensive queries often exhibit multifaceted information needs and nuanced interpretations, rendering document relevance inherently context dependent. To address this, we propose contextual relevance, which we define as the probability that a document is relevant to a given query, marginalized over the distribution of different reranking contexts it may appear in (i.e., the set of candidate documents it is ranked alongside and the order in which the documents are presented to a reranking model). While prior works have studied methods to mitigate the positional bias LLMs exhibit by accounting for the ordering of documents, we empirically find that the compositions of these batches also plays an important role in reranking performance. To efficiently estimate contextual relevance, we propose TS-SetRank, a sampling-based, uncertainty-aware reranking algorithm. Empirically, TS-SetRank improves nDCG@10 over retrieval and reranking baselines by 15-25% on BRIGHT and 6-21% on BEIR, highlighting the importance of modeling relevance as context-dependent.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2025-11-03T04:03:32+00:00",
      "updated": "2025-11-03T04:03:32+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.01208v1",
      "file": "papers/2511.01208v1.pdf"
    },
    {
      "arxiv_id": "2511.00875v1",
      "title": "Controlling Gender Bias in Retrieval via a Backpack Architecture",
      "authors": [
        {
          "name": "Amirabbas Afzali"
        },
        {
          "name": "Amirreza Velae"
        },
        {
          "name": "Iman Ahmadi"
        },
        {
          "name": "Mohammad Aliannejadi"
        }
      ],
      "abstract": "The presence of social biases in large language models (LLMs) has become a significant concern in AI research. These biases, often embedded in training data, can perpetuate harmful stereotypes and distort decision-making processes. When LLMs are integrated into ranking systems, they can propagate these biases, leading to unfair outcomes in critical applications such as search engines and recommendation systems. Backpack Language Models, unlike traditional transformer-based models that treat text sequences as monolithic structures, generate outputs as weighted combinations of non-contextual, learned word aspects, also known as senses. Leveraging this architecture, we propose a framework for debiasing ranking tasks. Our experimental results show that this framework effectively mitigates gender bias in text retrieval and ranking with minimal degradation in performance.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.LG"
      ],
      "published": "2025-11-02T09:58:08+00:00",
      "updated": "2025-11-02T09:58:08+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.00875v1",
      "file": "papers/2511.00875v1.pdf"
    },
    {
      "arxiv_id": "2511.05549v1",
      "title": "AGRAG: Advanced Graph-based Retrieval-Augmented Generation for LLMs",
      "authors": [
        {
          "name": "Yubo Wang"
        },
        {
          "name": "Haoyang Li"
        },
        {
          "name": "Fei Teng"
        },
        {
          "name": "Lei Chen"
        }
      ],
      "abstract": "Graph-based retrieval-augmented generation (Graph-based RAG) has demonstrated significant potential in enhancing Large Language Models (LLMs) with structured knowledge. However, existing methods face three critical challenges: Inaccurate Graph Construction, caused by LLM hallucination; Poor Reasoning Ability, caused by failing to generate explicit reasons telling LLM why certain chunks were selected; and Inadequate Answering, which only partially answers the query due to the inadequate LLM reasoning, making their performance lag behind NaiveRAG on certain tasks. To address these issues, we propose AGRAG, an advanced graph-based retrieval-augmented generation framework. When constructing the graph, AGRAG substitutes the widely used LLM entity extraction method with a statistics-based method, avoiding hallucination and error propagation. When retrieval, AGRAG formulates the graph reasoning procedure as the Minimum Cost Maximum Influence (MCMI) subgraph generation problem, where we try to include more nodes with high influence score, but with less involving edge cost, to make the generated reasoning paths more comprehensive. We prove this problem to be NP-hard, and propose a greedy algorithm to solve it. The MCMI subgraph generated can serve as explicit reasoning paths to tell LLM why certain chunks were retrieved, thereby making the LLM better focus on the query-related part contents of the chunks, reducing the impact of noise, and improving AGRAG's reasoning ability. Furthermore, compared with the simple tree-structured reasoning paths, our MCMI subgraph can allow more complex graph structures, such as cycles, and improve the comprehensiveness of the generated reasoning paths.",
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR"
      ],
      "published": "2025-11-02T06:13:06+00:00",
      "updated": "2025-11-02T06:13:06+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.05549v1",
      "file": "papers/2511.05549v1.pdf"
    },
    {
      "arxiv_id": "2511.00805v1",
      "title": "REaR: Retrieve, Expand and Refine for Effective Multitable Retrieval",
      "authors": [
        {
          "name": "Rishita Agarwal"
        },
        {
          "name": "Himanshu Singhal"
        },
        {
          "name": "Peter Baile Chen"
        },
        {
          "name": "Manan Roy Choudhury"
        },
        {
          "name": "Dan Roth"
        },
        {
          "name": "Vivek Gupta"
        }
      ],
      "abstract": "Answering natural language queries over relational data often requires retrieving and reasoning over multiple tables, yet most retrievers optimize only for query-table relevance and ignore table table compatibility. We introduce REAR (Retrieve, Expand and Refine), a three-stage, LLM-free framework that separates semantic relevance from structural joinability for efficient, high-fidelity multi-table retrieval. REAR (i) retrieves query-aligned tables, (ii) expands these with structurally joinable tables via fast, precomputed column-embedding comparisons, and (iii) refines them by pruning noisy or weakly related candidates. Empirically, REAR is retriever-agnostic and consistently improves dense/sparse retrievers on complex table QA datasets (BIRD, MMQA, and Spider) by improving both multi-table retrieval quality and downstream SQL execution. Despite being LLM-free, it delivers performance competitive with state-of-the-art LLM-augmented retrieval systems (e.g.,ARM) while achieving much lower latency and cost. Ablations confirm complementary gains from expansion and refinement, underscoring REAR as a practical, scalable building block for table-based downstream tasks (e.g., Text-to-SQL).",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2025-11-02T05:01:04+00:00",
      "updated": "2025-11-02T05:01:04+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.00805v1",
      "file": "papers/2511.00805v1.pdf"
    },
    {
      "arxiv_id": "2511.00694v1",
      "title": "Taxonomy-based Negative Sampling In Personalized Semantic Search for E-commerce",
      "authors": [
        {
          "name": "Uthman Jinadu"
        },
        {
          "name": "Siawpeng Er"
        },
        {
          "name": "Le Yu"
        },
        {
          "name": "Chen Liang"
        },
        {
          "name": "Bingxin Li"
        },
        {
          "name": "Yi Ding"
        },
        {
          "name": "Aleksandar Velkoski"
        }
      ],
      "abstract": "Large retail outlets offer products that may be domain-specific, and this requires having a model that can understand subtle differences in similar items. Sampling techniques used to train these models are most of the time, computationally expensive or logistically challenging. These models also do not factor in users' previous purchase patterns or behavior, thereby retrieving irrelevant items for them. We present a semantic retrieval model for e-commerce search that embeds queries and products into a shared vector space and leverages a novel taxonomy-based hard-negative sampling(TB-HNS) strategy to mine contextually relevant yet challenging negatives. To further tailor retrievals, we incorporate user-level personalization by modeling each customer's past purchase history and behavior. In offline experiments, our approach outperforms BM25, ANCE and leading neural baselines on Recall@K, while live A/B testing shows substantial uplifts in conversion rate, add-to-cart rate, and average order value. We also demonstrate that our taxonomy-driven negatives reduce training overhead and accelerate convergence, and we share practical lessons from deploying this system at scale.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2025-11-01T20:25:00+00:00",
      "updated": "2025-11-01T20:25:00+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.00694v1",
      "file": "papers/2511.00694v1.pdf"
    },
    {
      "arxiv_id": "2511.00444v1",
      "title": "LIR: The First Workshop on Late Interaction and Multi Vector Retrieval @ ECIR 2026",
      "authors": [
        {
          "name": "Benjamin Clavié"
        },
        {
          "name": "Xianming Li"
        },
        {
          "name": "Antoine Chaffin"
        },
        {
          "name": "Omar Khattab"
        },
        {
          "name": "Tom Aarsen"
        },
        {
          "name": "Manuel Faysse"
        },
        {
          "name": "Jing Li"
        }
      ],
      "abstract": "Late interaction retrieval methods, pioneered by ColBERT, have emerged as a powerful alternative to single-vector neural IR. By leveraging fine-grained, token-level representations, they have been demonstrated to deliver strong generalisation and robustness, particularly in out-of-domain settings. They have recently been shown to be particularly well-suited for novel use cases, such as reasoning-based or cross-modality retrieval. At the same time, these models pose significant challenges of efficiency, usability, and integrations into fully fledged systems; as well as the natural difficulties encountered while researching novel application domains. Recent years have seen rapid advances across many of these areas, but research efforts remain fragmented across communities and frequently exclude practitioners. The purpose of this workshop is to create an environment where all aspects of late interaction can be discussed, with a focus on early research explorations, real-world outcomes, and negative or puzzling results to be freely shared and discussed. The aim of LIR is to provide a highly-interactive environment for researchers from various backgrounds and practitioners to freely discuss their experience, fostering further collaboration.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "published": "2025-11-01T08:21:33+00:00",
      "updated": "2025-11-01T08:21:33+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.00444v1",
      "file": "papers/2511.00444v1.pdf"
    },
    {
      "arxiv_id": "2511.00375v1",
      "title": "PolyRecommender: A Multimodal Recommendation System for Polymer Discovery",
      "authors": [
        {
          "name": "Xin Wang"
        },
        {
          "name": "Yunhao Xiao"
        },
        {
          "name": "Rui Qiao"
        }
      ],
      "abstract": "We introduce PolyRecommender, a multimodal discovery framework that integrates chemical language representations from PolyBERT with molecular graph-based representations from a graph encoder. The system first retrieves candidate polymers using language-based similarity and then ranks them using fused multimodal embeddings according to multiple target properties. By leveraging the complementary knowledge encoded in both modalities, PolyRecommender enables efficient retrieval and robust ranking across related polymer properties. Our work establishes a generalizable multimodal paradigm, advancing AI-guided design for the discovery of next-generation polymers.",
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.IR"
      ],
      "published": "2025-11-01T03:13:56+00:00",
      "updated": "2025-11-01T03:13:56+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.00375v1",
      "file": "papers/2511.00375v1.pdf"
    },
    {
      "arxiv_id": "2511.00268v1",
      "title": "IL-PCSR: Legal Corpus for Prior Case and Statute Retrieval",
      "authors": [
        {
          "name": "Shounak Paul"
        },
        {
          "name": "Dhananjay Ghumare"
        },
        {
          "name": "Pawan Goyal"
        },
        {
          "name": "Saptarshi Ghosh"
        },
        {
          "name": "Ashutosh Modi"
        }
      ],
      "abstract": "Identifying/retrieving relevant statutes and prior cases/precedents for a given legal situation are common tasks exercised by law practitioners. Researchers to date have addressed the two tasks independently, thus developing completely different datasets and models for each task; however, both retrieval tasks are inherently related, e.g., similar cases tend to cite similar statutes (due to similar factual situation). In this paper, we address this gap. We propose IL-PCR (Indian Legal corpus for Prior Case and Statute Retrieval), which is a unique corpus that provides a common testbed for developing models for both the tasks (Statute Retrieval and Precedent Retrieval) that can exploit the dependence between the two. We experiment extensively with several baseline models on the tasks, including lexical models, semantic models and ensemble based on GNNs. Further, to exploit the dependence between the two tasks, we develop an LLM-based re-ranking approach that gives the best performance.",
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "published": "2025-10-31T21:39:04+00:00",
      "updated": "2025-10-31T21:39:04+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.00268v1",
      "file": "papers/2511.00268v1.pdf"
    },
    {
      "arxiv_id": "2510.27584v2",
      "title": "Image Hashing via Cross-View Code Alignment in the Age of Foundation Models",
      "authors": [
        {
          "name": "Ilyass Moummad"
        },
        {
          "name": "Kawtar Zaher"
        },
        {
          "name": "Hervé Goëau"
        },
        {
          "name": "Alexis Joly"
        }
      ],
      "abstract": "Efficient large-scale retrieval requires representations that are both compact and discriminative. Foundation models provide powerful visual and multimodal embeddings, but nearest neighbor search in these high-dimensional spaces is computationally expensive. Hashing offers an efficient alternative by enabling fast Hamming distance search with binary codes, yet existing approaches often rely on complex pipelines, multi-term objectives, designs specialized for a single learning paradigm, and long training times. We introduce CroVCA (Cross-View Code Alignment), a simple and unified principle for learning binary codes that remain consistent across semantically aligned views. A single binary cross-entropy loss enforces alignment, while coding-rate maximization serves as an anti-collapse regularizer to promote balanced and diverse codes. To implement this, we design HashCoder, a lightweight MLP hashing network with a final batch normalization layer to enforce balanced codes. HashCoder can be used as a probing head on frozen embeddings or to adapt encoders efficiently via LoRA fine-tuning. Across benchmarks, CroVCA achieves state-of-the-art results in just 5 training epochs. At 16 bits, it particularly well-for instance, unsupervised hashing on COCO completes in under 2 minutes and supervised hashing on ImageNet100 in about 3 minutes on a single GPU. These results highlight CroVCA's efficiency, adaptability, and broad applicability.",
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.IR",
        "cs.LG"
      ],
      "published": "2025-10-31T16:08:46+00:00",
      "updated": "2025-11-03T10:21:43+00:00",
      "pdf_url": "https://arxiv.org/pdf/2510.27584v2",
      "file": "papers/2510.27584v2.pdf"
    },
    {
      "arxiv_id": "2510.27571v1",
      "title": "Towards Universal Video Retrieval: Generalizing Video Embedding via Synthesized Multimodal Pyramid Curriculum",
      "authors": [
        {
          "name": "Zhuoning Guo"
        },
        {
          "name": "Mingxin Li"
        },
        {
          "name": "Yanzhao Zhang"
        },
        {
          "name": "Dingkun Long"
        },
        {
          "name": "Pengjun Xie"
        },
        {
          "name": "Xiaowen Chu"
        }
      ],
      "abstract": "The prevailing video retrieval paradigm is structurally misaligned, as narrow benchmarks incentivize correspondingly limited data and single-task training. Therefore, universal capability is suppressed due to the absence of a diagnostic evaluation that defines and demands multi-dimensional generalization. To break this cycle, we introduce a framework built on the co-design of evaluation, data, and modeling. First, we establish the Universal Video Retrieval Benchmark (UVRB), a suite of 16 datasets designed not only to measure performance but also to diagnose critical capability gaps across tasks and domains. Second, guided by UVRB's diagnostics, we introduce a scalable synthesis workflow that generates 1.55 million high-quality pairs to populate the semantic space required for universality. Finally, we devise the Modality Pyramid, a curriculum that trains our General Video Embedder (GVE) by explicitly leveraging the latent interconnections within our diverse data. Extensive experiments show GVE achieves state-of-the-art zero-shot generalization on UVRB. In particular, our analysis reveals that popular benchmarks are poor predictors of general ability and that partially relevant retrieval is a dominant but overlooked scenario. Overall, our co-designed framework provides a practical path to escape the limited scope and advance toward truly universal video retrieval.",
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.IR",
        "cs.LG"
      ],
      "published": "2025-10-31T15:54:48+00:00",
      "updated": "2025-10-31T15:54:48+00:00",
      "pdf_url": "https://arxiv.org/pdf/2510.27571v1",
      "file": "papers/2510.27571v1.pdf"
    },
    {
      "arxiv_id": "2510.27566v1",
      "title": "Interact-RAG: Reason and Interact with the Corpus, Beyond Black-Box Retrieval",
      "authors": [
        {
          "name": "Yulong Hui"
        },
        {
          "name": "Chao Chen"
        },
        {
          "name": "Zhihang Fu"
        },
        {
          "name": "Yihao Liu"
        },
        {
          "name": "Jieping Ye"
        },
        {
          "name": "Huanchen Zhang"
        }
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) has significantly enhanced LLMs by incorporating external information. However, prevailing agentic RAG approaches are constrained by a critical limitation: they treat the retrieval process as a black-box querying operation. This confines agents' actions to query issuing, hindering its ability to tackle complex information-seeking tasks. To address this, we introduce Interact-RAG, a new paradigm that elevates the LLM agent from a passive query issuer into an active manipulator of the retrieval process. We dismantle the black-box with a Corpus Interaction Engine, equipping the agent with a set of action primitives for fine-grained control over information retrieval. To further empower the agent on the entire RAG pipeline, we first develop a reasoning-enhanced workflow, which enables both zero-shot execution and the synthesis of interaction trajectories. We then leverage this synthetic data to train a fully autonomous end-to-end agent via Supervised Fine-Tuning (SFT), followed by refinement with Reinforcement Learning (RL). Extensive experiments across six benchmarks demonstrate that Interact-RAG significantly outperforms other advanced methods, validating the efficacy of our reasoning-interaction strategy.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2025-10-31T15:48:43+00:00",
      "updated": "2025-10-31T15:48:43+00:00",
      "pdf_url": "https://arxiv.org/pdf/2510.27566v1",
      "file": "papers/2510.27566v1.pdf"
    },
    {
      "arxiv_id": "2511.04696v1",
      "title": "EncouRAGe: Evaluating RAG Local, Fast, and Reliable",
      "authors": [
        {
          "name": "Jan Strich"
        },
        {
          "name": "Adeline Scharfenberg"
        },
        {
          "name": "Chris Biemann"
        },
        {
          "name": "Martin Semmann"
        }
      ],
      "abstract": "We introduce EncouRAGe, a comprehensive Python framework designed to streamline the development and evaluation of Retrieval-Augmented Generation (RAG) systems using Large Language Models (LLMs) and Embedding Models. EncouRAGe comprises five modular and extensible components: Type Manifest, RAG Factory, Inference, Vector Store, and Metrics, facilitating flexible experimentation and extensible development. The framework emphasizes scientific reproducibility, diverse evaluation metrics, and local deployment, enabling researchers to efficiently assess datasets within RAG workflows. This paper presents implementation details and an extensive evaluation across multiple benchmark datasets, including 25k QA pairs and over 51k documents. Our results show that RAG still underperforms compared to the Oracle Context, while Hybrid BM25 consistently achieves the best results across all four datasets. We further examine the effects of reranking, observing only marginal performance improvements accompanied by higher response latency.",
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "published": "2025-10-31T15:19:29+00:00",
      "updated": "2025-10-31T15:19:29+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.04696v1",
      "file": "papers/2511.04696v1.pdf"
    },
    {
      "arxiv_id": "2510.27238v1",
      "title": "DRAMA: Unifying Data Retrieval and Analysis for Open-Domain Analytic Queries",
      "authors": [
        {
          "name": "Chuxuan Hu"
        },
        {
          "name": "Maxwell Yang"
        },
        {
          "name": "James Weiland"
        },
        {
          "name": "Yeji Lim"
        },
        {
          "name": "Suhas Palawala"
        },
        {
          "name": "Daniel Kang"
        }
      ],
      "abstract": "Manually conducting real-world data analyses is labor-intensive and inefficient. Despite numerous attempts to automate data science workflows, none of the existing paradigms or systems fully demonstrate all three key capabilities required to support them effectively: (1) open-domain data collection, (2) structured data transformation, and (3) analytic reasoning.\n  To overcome these limitations, we propose DRAMA, an end-to-end paradigm that answers users' analytic queries in natural language on large-scale open-domain data. DRAMA unifies data collection, transformation, and analysis as a single pipeline. To quantitatively evaluate system performance on tasks representative of DRAMA, we construct a benchmark, DRAMA-Bench, consisting of two categories of tasks: claim verification and question answering, each comprising 100 instances. These tasks are derived from real-world applications that have gained significant public attention and require the retrieval and analysis of open-domain data. We develop DRAMA-Bot, a multi-agent system designed following DRAMA. It comprises a data retriever that collects and transforms data by coordinating the execution of sub-agents, and a data analyzer that performs structured reasoning over the retrieved data. We evaluate DRAMA-Bot on DRAMA-Bench together with five state-of-the-art baseline agents. DRAMA-Bot achieves 86.5% task accuracy at a cost of $0.05, outperforming all baselines with up to 6.9 times the accuracy and less than 1/6 of the cost. DRAMA is publicly available at https://github.com/uiuc-kang-lab/drama.",
      "primary_category": "cs.DB",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ],
      "published": "2025-10-31T07:00:21+00:00",
      "updated": "2025-10-31T07:00:21+00:00",
      "pdf_url": "https://arxiv.org/pdf/2510.27238v1",
      "file": "papers/2510.27238v1.pdf"
    },
    {
      "arxiv_id": "2510.27232v1",
      "title": "A Survey on Deep Text Hashing: Efficient Semantic Text Retrieval with Binary Representation",
      "authors": [
        {
          "name": "Liyang He"
        },
        {
          "name": "Zhenya Huang"
        },
        {
          "name": "Cheng Yang"
        },
        {
          "name": "Rui Li"
        },
        {
          "name": "Zheng Zhang"
        },
        {
          "name": "Kai Zhang"
        },
        {
          "name": "Zhi Li"
        },
        {
          "name": "Qi Liu"
        },
        {
          "name": "Enhong Chen"
        }
      ],
      "abstract": "With the rapid growth of textual content on the Internet, efficient large-scale semantic text retrieval has garnered increasing attention from both academia and industry. Text hashing, which projects original texts into compact binary hash codes, is a crucial method for this task. By using binary codes, the semantic similarity computation for text pairs is significantly accelerated via fast Hamming distance calculations, and storage costs are greatly reduced. With the advancement of deep learning, deep text hashing has demonstrated significant advantages over traditional, data-independent hashing techniques. By leveraging deep neural networks, these methods can learn compact and semantically rich binary representations directly from data, overcoming the performance limitations of earlier approaches. This survey investigates current deep text hashing methods by categorizing them based on their core components: semantic extraction, hash code quality preservation, and other key technologies. We then present a detailed evaluation schema with results on several popular datasets, followed by a discussion of practical applications and open-source tools for implementation. Finally, we conclude by discussing key challenges and future research directions, including the integration of deep text hashing with large language models to further advance the field. The project for this survey can be accessed at https://github.com/hly1998/DeepTextHashing.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2025-10-31T06:51:37+00:00",
      "updated": "2025-10-31T06:51:37+00:00",
      "pdf_url": "https://arxiv.org/pdf/2510.27232v1",
      "file": "papers/2510.27232v1.pdf"
    },
    {
      "arxiv_id": "2510.27141v3",
      "title": "Compass: General Filtered Search across Vector and Structured Data",
      "authors": [
        {
          "name": "Chunxiao Ye"
        },
        {
          "name": "Xiao Yan"
        },
        {
          "name": "Eric Lo"
        }
      ],
      "abstract": "The increasing prevalence of hybrid vector and relational data necessitates efficient, general support for queries that combine high-dimensional vector search with complex relational filtering. However, existing filtered search solutions are fundamentally limited by specialized indices, which restrict arbitrary filtering and hinder integration with general-purpose DBMSs. This work introduces \\textsc{Compass}, a unified framework that enables general filtered search across vector and structured data without relying on new index designs. Compass leverages established index structures -- such as HNSW and IVF for vector attributes, and B+-trees for relational attributes -- implementing a principled cooperative query execution strategy that coordinates candidate generation and predicate evaluation across modalities. Uniquely, Compass maintains generality by allowing arbitrary conjunctions, disjunctions, and range predicates, while ensuring robustness even with highly-selective or multi-attribute filters. Comprehensive empirical evaluations demonstrate that Compass consistently outperforms NaviX, the only existing performant general framework, across diverse hybrid query workloads. It also matches the query throughput of specialized single-attribute indices in their favorite settings with only a single attribute involved, all while maintaining full generality and DBMS compatibility. Overall, Compass offers a practical and robust solution for achieving truly general filtered search in vector database systems.",
      "primary_category": "cs.DB",
      "categories": [
        "cs.DB",
        "cs.IR"
      ],
      "published": "2025-10-31T03:36:14+00:00",
      "updated": "2025-11-11T08:58:14+00:00",
      "pdf_url": "https://arxiv.org/pdf/2510.27141v3",
      "file": "papers/2510.27141v3.pdf"
    },
    {
      "arxiv_id": "2510.26861v2",
      "title": "Evaluating Perspectival Biases in Cross-Modal Retrieval",
      "authors": [
        {
          "name": "Teerapol Saengsukhiran"
        },
        {
          "name": "Peerawat Chomphooyod"
        },
        {
          "name": "Narabodee Rodjananant"
        },
        {
          "name": "Chompakorn Chaksangchaichot"
        },
        {
          "name": "Patawee Prakrankamanant"
        },
        {
          "name": "Witthawin Sripheanpol"
        },
        {
          "name": "Pak Lovichit"
        },
        {
          "name": "Sarana Nutanong"
        },
        {
          "name": "Ekapol Chuangsuwanich"
        }
      ],
      "abstract": "Multimodal retrieval systems are expected to operate in a semantic space, agnostic to the language or cultural origin of the query. In practice, however, retrieval outcomes systematically reflect perspectival biases: deviations shaped by linguistic prevalence and cultural associations. We study two such biases. First, prevalence bias refers to the tendency to favor entries from prevalent languages over semantically faithful entries in image-to-text retrieval. Second, association bias refers to the tendency to favor images culturally associated with the query over semantically correct ones in text-to-image retrieval. Results show that explicit alignment is a more effective strategy for mitigating prevalence bias. However, association bias remains a distinct and more challenging problem. These findings suggest that achieving truly equitable multimodal systems requires targeted strategies beyond simple data scaling and that bias arising from cultural association may be treated as a more challenging problem than one arising from linguistic prevalence.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.CL"
      ],
      "published": "2025-10-30T16:31:36+00:00",
      "updated": "2025-11-03T07:40:26+00:00",
      "pdf_url": "https://arxiv.org/pdf/2510.26861v2",
      "file": "papers/2510.26861v2.pdf"
    },
    {
      "arxiv_id": "2510.26178v1",
      "title": "ReaKase-8B: Legal Case Retrieval via Knowledge and Reasoning Representations with LLMs",
      "authors": [
        {
          "name": "Yanran Tang"
        },
        {
          "name": "Ruihong Qiu"
        },
        {
          "name": "Xue Li"
        },
        {
          "name": "Zi Huang"
        }
      ],
      "abstract": "Legal case retrieval (LCR) is a cornerstone of real-world legal decision making, as it enables practitioners to identify precedents for a given query case. Existing approaches mainly rely on traditional lexical models and pretrained language models to encode the texts of legal cases. Yet there are rich information in the relations among different legal entities as well as the crucial reasoning process that uncovers how legal facts and legal issues can lead to judicial decisions. Such relational reasoning process reflects the distinctive characteristics of each case that can distinguish one from another, mirroring the real-world judicial process. Naturally, incorporating such information into the precise case embedding could further enhance the accuracy of case retrieval. In this paper, a novel ReaKase-8B framework is proposed to leverage extracted legal facts, legal issues, legal relation triplets and legal reasoning for effective legal case retrieval. ReaKase-8B designs an in-context legal case representation learning paradigm with a fine-tuned large language model. Extensive experiments on two benchmark datasets from COLIEE 2022 and COLIEE 2023 demonstrate that our knowledge and reasoning augmented embeddings substantially improve retrieval performance over baseline models, highlighting the potential of integrating legal reasoning into legal case retrieval systems. The code has been released on https://github.com/yanran-tang/ReaKase-8B.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2025-10-30T06:35:36+00:00",
      "updated": "2025-10-30T06:35:36+00:00",
      "pdf_url": "https://arxiv.org/pdf/2510.26178v1",
      "file": "papers/2510.26178v1.pdf"
    },
    {
      "arxiv_id": "2510.25718v1",
      "title": "Retrieval-Augmented Search for Large-Scale Map Collections with ColPali",
      "authors": [
        {
          "name": "Jamie Mahowald"
        },
        {
          "name": "Benjamin Charles Germain Lee"
        }
      ],
      "abstract": "Multimodal approaches have shown great promise for searching and navigating digital collections held by libraries, archives, and museums. In this paper, we introduce map-RAS: a retrieval-augmented search system for historic maps. In addition to introducing our framework, we detail our publicly-hosted demo for searching 101,233 map images held by the Library of Congress. With our system, users can multimodally query the map collection via ColPali, summarize search results using Llama 3.2, and upload their own collections to perform inter-collection search. We articulate potential use cases for archivists, curators, and end-users, as well as future work with our system in both machine learning and the digital humanities. Our demo can be viewed at: http://www.mapras.com.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.DL"
      ],
      "published": "2025-10-29T17:27:21+00:00",
      "updated": "2025-10-29T17:27:21+00:00",
      "pdf_url": "https://arxiv.org/pdf/2510.25718v1",
      "file": "papers/2510.25718v1.pdf"
    },
    {
      "arxiv_id": "2510.25621v1",
      "title": "FARSIQA: Faithful and Advanced RAG System for Islamic Question Answering",
      "authors": [
        {
          "name": "Mohammad Aghajani Asl"
        },
        {
          "name": "Behrooz Minaei Bidgoli"
        }
      ],
      "abstract": "The advent of Large Language Models (LLMs) has revolutionized Natural Language Processing, yet their application in high-stakes, specialized domains like religious question answering is hindered by challenges like hallucination and unfaithfulness to authoritative sources. This issue is particularly critical for the Persian-speaking Muslim community, where accuracy and trustworthiness are paramount. Existing Retrieval-Augmented Generation (RAG) systems, relying on simplistic single-pass pipelines, fall short on complex, multi-hop queries requiring multi-step reasoning and evidence aggregation. To address this gap, we introduce FARSIQA, a novel, end-to-end system for Faithful Advanced Question Answering in the Persian Islamic domain. FARSIQA is built upon our innovative FAIR-RAG architecture: a Faithful, Adaptive, Iterative Refinement framework for RAG. FAIR-RAG employs a dynamic, self-correcting process: it adaptively decomposes complex queries, assesses evidence sufficiency, and enters an iterative loop to generate sub-queries, progressively filling information gaps. Operating on a curated knowledge base of over one million authoritative Islamic documents, FARSIQA demonstrates superior performance. Rigorous evaluation on the challenging IslamicPCQA benchmark shows state-of-the-art performance: the system achieves a remarkable 97.0% in Negative Rejection - a 40-point improvement over baselines - and a high Answer Correctness score of 74.3%. Our work establishes a new standard for Persian Islamic QA and validates that our iterative, adaptive architecture is crucial for building faithful, reliable AI systems in sensitive domains.",
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "published": "2025-10-29T15:25:34+00:00",
      "updated": "2025-10-29T15:25:34+00:00",
      "pdf_url": "https://arxiv.org/pdf/2510.25621v1",
      "file": "papers/2510.25621v1.pdf"
    },
    {
      "arxiv_id": "2510.25488v1",
      "title": "Generalized Pseudo-Relevance Feedback",
      "authors": [
        {
          "name": "Yiteng Tu"
        },
        {
          "name": "Weihang Su"
        },
        {
          "name": "Yujia Zhou"
        },
        {
          "name": "Yiqun Liu"
        },
        {
          "name": "Fen Lin"
        },
        {
          "name": "Qin Liu"
        },
        {
          "name": "Qingyao Ai"
        }
      ],
      "abstract": "Query rewriting is a fundamental technique in information retrieval (IR). It typically employs the retrieval result as relevance feedback to refine the query and thereby addresses the vocabulary mismatch between user queries and relevant documents. Traditional pseudo-relevance feedback (PRF) and its vector-based extension (VPRF) improve retrieval performance by leveraging top-retrieved documents as relevance feedback. However, they are constructed based on two major hypotheses: the relevance assumption (top documents are relevant) and the model assumption (rewriting methods need to be designed specifically for particular model architectures). While recent large language models (LLMs)-based generative relevance feedback (GRF) enables model-free query reformulation, it either suffers from severe LLM hallucination or, again, relies on the relevance assumption to guarantee the effectiveness of rewriting quality. To overcome these limitations, we introduce an assumption-relaxed framework: \\textit{Generalized Pseudo Relevance Feedback} (GPRF), which performs model-free, natural language rewriting based on retrieved documents, not only eliminating the model assumption but also reducing dependence on the relevance assumption. Specifically, we design a utility-oriented training pipeline with reinforcement learning to ensure robustness against noisy feedback. Extensive experiments across multiple benchmarks and retrievers demonstrate that GPRF consistently outperforms strong baselines, establishing it as an effective and generalizable framework for query rewriting.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2025-10-29T13:08:35+00:00",
      "updated": "2025-10-29T13:08:35+00:00",
      "pdf_url": "https://arxiv.org/pdf/2510.25488v1",
      "file": "papers/2510.25488v1.pdf"
    },
    {
      "arxiv_id": "2511.00072v1",
      "title": "LookSync: Large-Scale Visual Product Search System for AI-Generated Fashion Looks",
      "authors": [
        {
          "name": "Pradeep M"
        },
        {
          "name": "Ritesh Pallod"
        },
        {
          "name": "Satyen Abrol"
        },
        {
          "name": "Muthu Raman"
        },
        {
          "name": "Ian Anderson"
        }
      ],
      "abstract": "Generative AI is reshaping fashion by enabling virtual looks and avatars making it essential to find real products that best match AI-generated styles. We propose an end-to-end product search system that has been deployed in a real-world, internet scale which ensures that AI-generated looks presented to users are matched with the most visually and semantically similar products from the indexed vector space. The search pipeline is composed of four key components: query generation, vectorization, candidate retrieval, and reranking based on AI-generated looks. Recommendation quality is evaluated using human-judged accuracy scores. The system currently serves more than 350,000 AI Looks in production per day, covering diverse product categories across global markets of over 12 million products. In our experiments, we observed that across multiple annotators and categories, CLIP outperformed alternative models by a small relative margin of 3--7\\% in mean opinion scores. These improvements, though modest in absolute numbers, resulted in noticeably better user perception matches, establishing CLIP as the most reliable backbone for production deployment.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "published": "2025-10-29T12:30:54+00:00",
      "updated": "2025-10-29T12:30:54+00:00",
      "pdf_url": "https://arxiv.org/pdf/2511.00072v1",
      "file": "papers/2511.00072v1.pdf"
    },
    {
      "arxiv_id": "2510.25428v1",
      "title": "Alibaba International E-commerce Product Search Competition DcuRAGONs Team Technical Report",
      "authors": [
        {
          "name": "Thang-Long Nguyen-Ho"
        },
        {
          "name": "Minh-Khoi Pham"
        },
        {
          "name": "Hoang-Bao Le"
        }
      ],
      "abstract": "This report details our methodology and results developed for the Multilingual E-commerce Search Competition. The problem aims to recognize relevance between user queries versus product items in a multilingual context and improve recommendation performance on e-commerce platforms. Utilizing Large Language Models (LLMs) and their capabilities in other tasks, our data-centric method achieved the highest score compared to other solutions during the competition. Final leaderboard is publised at https://alibaba-international-cikm2025.github.io. The source code for our project is published at https://github.com/nhtlongcs/e-commerce-product-search.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "published": "2025-10-29T11:50:52+00:00",
      "updated": "2025-10-29T11:50:52+00:00",
      "pdf_url": "https://arxiv.org/pdf/2510.25428v1",
      "file": "papers/2510.25428v1.pdf"
    },
    {
      "arxiv_id": "2510.25401v2",
      "title": "The novel vector database",
      "authors": [
        {
          "name": "Tom. Lou"
        }
      ],
      "abstract": "On-disk graph-based indexes are widely used in approximate nearest neighbor (ANN) search systems for large-scale, high-dimensional vectors. However, traditional coupled storage methods, which store vectors within the index, are inefficient for index updates. Coupled storage incurs excessive redundant vector reads and writes when updating the graph topology, leading to significant invalid I/O. To address this issue, we propose a decoupled storage architecture. Experimental results show that the decoupled architecture improves update speed by 10.05x for insertions and 6.89x for deletions, while the three-stage query and incremental reordering enhance query efficiency by 2.66x compared to the traditional coupled architecture.",
      "primary_category": "cs.DB",
      "categories": [
        "cs.DB",
        "cs.IR"
      ],
      "published": "2025-10-29T11:20:10+00:00",
      "updated": "2025-12-11T21:14:45+00:00",
      "pdf_url": "https://arxiv.org/pdf/2510.25401v2",
      "file": "papers/2510.25401v2.pdf"
    },
    {
      "arxiv_id": "2510.25220v1",
      "title": "GReF: A Unified Generative Framework for Efficient Reranking via Ordered Multi-token Prediction",
      "authors": [
        {
          "name": "Zhijie Lin"
        },
        {
          "name": "Zhuofeng Li"
        },
        {
          "name": "Chenglei Dai"
        },
        {
          "name": "Wentian Bao"
        },
        {
          "name": "Shuai Lin"
        },
        {
          "name": "Enyun Yu"
        },
        {
          "name": "Haoxiang Zhang"
        },
        {
          "name": "Liang Zhao"
        }
      ],
      "abstract": "In a multi-stage recommendation system, reranking plays a crucial role in modeling intra-list correlations among items. A key challenge lies in exploring optimal sequences within the combinatorial space of permutations. Recent research follows a two-stage (generator-evaluator) paradigm, where a generator produces multiple feasible sequences, and an evaluator selects the best one. In practice, the generator is typically implemented as an autoregressive model. However, these two-stage methods face two main challenges. First, the separation of the generator and evaluator hinders end-to-end training. Second, autoregressive generators suffer from inference efficiency. In this work, we propose a Unified Generative Efficient Reranking Framework (GReF) to address the two primary challenges. Specifically, we introduce Gen-Reranker, an autoregressive generator featuring a bidirectional encoder and a dynamic autoregressive decoder to generate causal reranking sequences. Subsequently, we pre-train Gen-Reranker on the item exposure order for high-quality parameter initialization. To eliminate the need for the evaluator while integrating sequence-level evaluation during training for end-to-end optimization, we propose post-training the model through Rerank-DPO. Moreover, for efficient autoregressive inference, we introduce ordered multi-token prediction (OMTP), which trains Gen-Reranker to simultaneously generate multiple future items while preserving their order, ensuring practical deployment in real-time recommender systems. Extensive offline experiments demonstrate that GReF outperforms state-of-the-art reranking methods while achieving latency that is nearly comparable to non-autoregressive models. Additionally, GReF has also been deployed in a real-world video app Kuaishou with over 300 million daily active users, significantly improving online recommendation quality.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2025-10-29T06:54:42+00:00",
      "updated": "2025-10-29T06:54:42+00:00",
      "pdf_url": "https://arxiv.org/pdf/2510.25220v1",
      "file": "papers/2510.25220v1.pdf"
    },
    {
      "arxiv_id": "2510.25160v2",
      "title": "Model-Document Protocol for AI Search",
      "authors": [
        {
          "name": "Hongjin Qian"
        },
        {
          "name": "Zheng Liu"
        }
      ],
      "abstract": "AI search depends on linking large language models (LLMs) with vast external knowledge sources. Yet web pages, PDF files, and other raw documents are not inherently LLM-ready: they are long, noisy, and unstructured. Conventional retrieval methods treat these documents as verbatim text and return raw passages, leaving the burden of fragment assembly and contextual reasoning to the LLM. This gap underscores the need for a new retrieval paradigm that redefines how models interact with documents.\n  We introduce the Model-Document Protocol (MDP), a general framework that formalizes how raw text is bridged to LLMs through consumable knowledge representations. Rather than treating retrieval as passage fetching, MDP defines multiple pathways that transform unstructured documents into task-specific, LLM-ready inputs. These include agentic reasoning, which curates raw evidence into coherent context; memory grounding, which accumulates reusable notes to enrich reasoning; and structured leveraging, which encodes documents into formal representations such as graphs or key-value caches. All three pathways share the same goal: ensuring that what reaches the LLM is not raw fragments but compact, structured knowledge directly consumable for reasoning.\n  As an instantiation, we present MDP-Agent, which realizes the protocol through an agentic process: constructing document-level gist memories for global coverage, performing diffusion-based exploration with vertical exploitation to uncover layered dependencies, and applying map-reduce style synthesis to integrate large-scale evidence into compact yet sufficient context. Experiments on information-seeking benchmarks demonstrate that MDP-Agent outperforms baselines, validating both the soundness of the MDP framework and the effectiveness of its agentic instantiation.",
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "published": "2025-10-29T04:29:17+00:00",
      "updated": "2025-10-30T08:52:17+00:00",
      "pdf_url": "https://arxiv.org/pdf/2510.25160v2",
      "file": "papers/2510.25160v2.pdf"
    },
    {
      "arxiv_id": "2510.25025v2",
      "title": "Secure Retrieval-Augmented Generation against Poisoning Attacks",
      "authors": [
        {
          "name": "Zirui Cheng"
        },
        {
          "name": "Jikai Sun"
        },
        {
          "name": "Anjun Gao"
        },
        {
          "name": "Yueyang Quan"
        },
        {
          "name": "Zhuqing Liu"
        },
        {
          "name": "Xiaohua Hu"
        },
        {
          "name": "Minghong Fang"
        }
      ],
      "abstract": "Large language models (LLMs) have transformed natural language processing (NLP), enabling applications from content generation to decision support. Retrieval-Augmented Generation (RAG) improves LLMs by incorporating external knowledge but also introduces security risks, particularly from data poisoning, where the attacker injects poisoned texts into the knowledge database to manipulate system outputs. While various defenses have been proposed, they often struggle against advanced attacks. To address this, we introduce RAGuard, a detection framework designed to identify poisoned texts. RAGuard first expands the retrieval scope to increase the proportion of clean texts, reducing the likelihood of retrieving poisoned content. It then applies chunk-wise perplexity filtering to detect abnormal variations and text similarity filtering to flag highly similar texts. This non-parametric approach enhances RAG security, and experiments on large-scale datasets demonstrate its effectiveness in detecting and mitigating poisoning attacks, including strong adaptive attacks.",
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR",
        "cs.IR",
        "cs.LG"
      ],
      "published": "2025-10-28T22:54:19+00:00",
      "updated": "2025-11-10T03:50:42+00:00",
      "pdf_url": "https://arxiv.org/pdf/2510.25025v2",
      "file": "papers/2510.25025v2.pdf"
    },
    {
      "arxiv_id": "2510.24652v1",
      "title": "Optimizing Retrieval for RAG via Reinforced Contrastive Learning",
      "authors": [
        {
          "name": "Jiawei Zhou"
        },
        {
          "name": "Lei Chen"
        }
      ],
      "abstract": "As retrieval-augmented generation (RAG) becomes increasingly widespread, the role of information retrieval (IR) is shifting from retrieving information for human users to retrieving contextual knowledge for artificial intelligence (AI) systems, where relevance becomes difficult to define or annotate beforehand. To address this challenge, we propose R3, a Retrieval framework optimized for RAG through trialand-feedback Reinforced contrastive learning. Unlike prior approaches that rely on annotated or synthetic data for supervised fine-tuning, R3 enables the retriever to dynamically explore and optimize relevance within the RAG environment. During training, the retrieved results interact with the environment to produce contrastive signals that automatically guide the retriever's self-improvement. Extensive experiments across diverse tasks demonstrate that R3 improves RAG performance by 5.2% over the original retriever and surpasses state-of-the-art retrievers by 4.9%, while achieving comparable results to LLM-augmented retrieval and RAG systems built on post-trained or instruction-tuned LLMs. It is both efficient and practical, requiring only 4 GPUs and completing training within a single day.",
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.IR"
      ],
      "published": "2025-10-28T17:18:30+00:00",
      "updated": "2025-10-28T17:18:30+00:00",
      "pdf_url": "https://arxiv.org/pdf/2510.24652v1",
      "file": "papers/2510.24652v1.pdf"
    },
    {
      "arxiv_id": "2510.24402v1",
      "title": "Metadata-Driven Retrieval-Augmented Generation for Financial Question Answering",
      "authors": [
        {
          "name": "Michail Dadopoulos"
        },
        {
          "name": "Anestis Ladas"
        },
        {
          "name": "Stratos Moschidis"
        },
        {
          "name": "Ioannis Negkakis"
        }
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) struggles on long, structured financial filings where relevant evidence is sparse and cross-referenced. This paper presents a systematic investigation of advanced metadata-driven Retrieval-Augmented Generation (RAG) techniques, proposing and evaluating a novel, multi-stage RAG architecture that leverages LLM-generated metadata. We introduce a sophisticated indexing pipeline to create contextually rich document chunks and benchmark a spectrum of enhancements, including pre-retrieval filtering, post-retrieval reranking, and enriched embeddings, benchmarked on the FinanceBench dataset. Our results reveal that while a powerful reranker is essential for precision, the most significant performance gains come from embedding chunk metadata directly with text (\"contextual chunks\"). Our proposed optimal architecture combines LLM-driven pre-retrieval optimizations with these contextual embeddings to achieve superior performance. Additionally, we present a custom metadata reranker that offers a compelling, cost-effective alternative to commercial solutions, highlighting a practical trade-off between peak performance and operational efficiency. This study provides a blueprint for building robust, metadata-aware RAG systems for financial document analysis.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CE"
      ],
      "published": "2025-10-28T13:16:36+00:00",
      "updated": "2025-10-28T13:16:36+00:00",
      "pdf_url": "https://arxiv.org/pdf/2510.24402v1",
      "file": "papers/2510.24402v1.pdf"
    },
    {
      "arxiv_id": "2510.23544v1",
      "title": "LimRank: Less is More for Reasoning-Intensive Information Reranking",
      "authors": [
        {
          "name": "Tingyu Song"
        },
        {
          "name": "Yilun Zhao"
        },
        {
          "name": "Siyue Zhang"
        },
        {
          "name": "Chen Zhao"
        },
        {
          "name": "Arman Cohan"
        }
      ],
      "abstract": "Existing approaches typically rely on large-scale fine-tuning to adapt LLMs for information reranking tasks, which is computationally expensive. In this work, we demonstrate that modern LLMs can be effectively adapted using only minimal, high-quality supervision. To enable this, we design LIMRANK-SYNTHESIZER, a reusable and open-source pipeline for generating diverse, challenging, and realistic reranking examples. Using this synthetic data, we fine-tune our reranker model, LIMRANK. We evaluate LIMRANK on two challenging benchmarks, i.e., BRIGHT for reasoning-intensive retrieval and FollowIR for instruction-following retrieval. Our experiments demonstrate that LIMRANK achieves competitive performance, while being trained on less than 5% of the data typically used in prior work. Further ablation studies demonstrate the effectiveness of LIMRANK-SYNTHESIZER and the strong generalization capabilities of LIMRANK across downstream tasks, including scientific literature search and retrieval-augmented generation for knowledge-intensive problem solving.",
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.IR"
      ],
      "published": "2025-10-27T17:19:37+00:00",
      "updated": "2025-10-27T17:19:37+00:00",
      "pdf_url": "https://arxiv.org/pdf/2510.23544v1",
      "file": "papers/2510.23544v1.pdf"
    },
    {
      "arxiv_id": "2510.23224v1",
      "title": "Accurate and Scalable Multimodal Pathology Retrieval via Attentive Vision-Language Alignment",
      "authors": [
        {
          "name": "Hongyi Wang"
        },
        {
          "name": "Zhengjie Zhu"
        },
        {
          "name": "Jiabo Ma"
        },
        {
          "name": "Fang Wang"
        },
        {
          "name": "Yue Shi"
        },
        {
          "name": "Bo Luo"
        },
        {
          "name": "Jili Wang"
        },
        {
          "name": "Qiuyu Cai"
        },
        {
          "name": "Xiuming Zhang"
        },
        {
          "name": "Yen-Wei Chen"
        },
        {
          "name": "Lanfen Lin"
        },
        {
          "name": "Hao Chen"
        }
      ],
      "abstract": "The rapid digitization of histopathology slides has opened up new possibilities for computational tools in clinical and research workflows. Among these, content-based slide retrieval stands out, enabling pathologists to identify morphologically and semantically similar cases, thereby supporting precise diagnoses, enhancing consistency across observers, and assisting example-based education. However, effective retrieval of whole slide images (WSIs) remains challenging due to their gigapixel scale and the difficulty of capturing subtle semantic differences amid abundant irrelevant content. To overcome these challenges, we present PathSearch, a retrieval framework that unifies fine-grained attentive mosaic representations with global-wise slide embeddings aligned through vision-language contrastive learning. Trained on a corpus of 6,926 slide-report pairs, PathSearch captures both fine-grained morphological cues and high-level semantic patterns to enable accurate and flexible retrieval. The framework supports two key functionalities: (1) mosaic-based image-to-image retrieval, ensuring accurate and efficient slide research; and (2) multi-modal retrieval, where text queries can directly retrieve relevant slides. PathSearch was rigorously evaluated on four public pathology datasets and three in-house cohorts, covering tasks including anatomical site retrieval, tumor subtyping, tumor vs. non-tumor discrimination, and grading across diverse organs such as breast, lung, kidney, liver, and stomach. External results show that PathSearch outperforms traditional image-to-image retrieval frameworks. A multi-center reader study further demonstrates that PathSearch improves diagnostic accuracy, boosts confidence, and enhances inter-observer agreement among pathologists in real clinical scenarios. These results establish PathSearch as a scalable and generalizable retrieval solution for digital pathology.",
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.IR"
      ],
      "published": "2025-10-27T11:22:28+00:00",
      "updated": "2025-10-27T11:22:28+00:00",
      "pdf_url": "https://arxiv.org/pdf/2510.23224v1",
      "file": "papers/2510.23224v1.pdf"
    },
    {
      "arxiv_id": "2510.23018v2",
      "title": "Improving Product Search Relevance with EAR-MP: A Solution for the CIKM 2025 AnalytiCup",
      "authors": [
        {
          "name": "JaeEun Lim"
        },
        {
          "name": "Soomin Kim"
        },
        {
          "name": "Jaeyong Seo"
        },
        {
          "name": "Iori Ono"
        },
        {
          "name": "Qimu Ran"
        },
        {
          "name": "Jae-woong Lee"
        }
      ],
      "abstract": "Multilingual e-commerce search is challenging due to linguistic diversity and the noise inherent in user-generated queries. This paper documents the solution employed by our team (EAR-MP) for the CIKM 2025 AnalytiCup, which addresses two core tasks: Query-Category (QC) relevance and Query-Item (QI) relevance. Our approach first normalizes the multilingual dataset by translating all text into English, then mitigates noise through extensive data cleaning and normalization. For model training, we build on DeBERTa-v3-large and improve performance with label smoothing, self-distillation, and dropout. In addition, we introduce task-specific upgrades, including hierarchical token injection for QC and a hybrid scoring mechanism for QI. Under constrained compute, our method achieves competitive results, attaining an F1 score of 0.8796 on QC and 0.8744 on QI. These findings underscore the importance of systematic data preprocessing and tailored training strategies for building robust, resource-efficient multilingual relevance systems.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2025-10-27T05:32:13+00:00",
      "updated": "2025-10-31T01:07:46+00:00",
      "pdf_url": "https://arxiv.org/pdf/2510.23018v2",
      "file": "papers/2510.23018v2.pdf"
    },
    {
      "arxiv_id": "2510.22739v1",
      "title": "REVISION:Reflective Intent Mining and Online Reasoning Auxiliary for E-commerce Visual Search System Optimization",
      "authors": [
        {
          "name": "Yiwen Tang"
        },
        {
          "name": "Qiuyu Zhao"
        },
        {
          "name": "Zenghui Sun"
        },
        {
          "name": "Jinsong Lan"
        },
        {
          "name": "Xiaoyong Zhu"
        },
        {
          "name": "Bo Zheng"
        },
        {
          "name": "Kaifu Zhang"
        }
      ],
      "abstract": "In Taobao e-commerce visual search, user behavior analysis reveals a large proportion of no-click requests, suggesting diverse and implicit user intents. These intents are expressed in various forms and are difficult to mine and discover, thereby leading to the limited adaptability and lag in platform strategies. This greatly restricts users' ability to express diverse intents and hinders the scalability of the visual search system. This mismatch between user implicit intent expression and system response defines the User-SearchSys Intent Discrepancy. To alleviate the issue, we propose a novel framework REVISION. This framework integrates offline reasoning mining with online decision-making and execution, enabling adaptive strategies to solve implicit user demands. In the offline stage, we construct a periodic pipeline to mine discrepancies from historical no-click requests. Leveraging large models, we analyze implicit intent factors and infer optimal suggestions by jointly reasoning over query and product metadata. These inferred suggestions serve as actionable insights for refining platform strategies. In the online stage, REVISION-R1-3B, trained on the curated offline data, performs holistic analysis over query images and associated historical products to generate optimization plans and adaptively schedule strategies across the search pipeline. Our framework offers a streamlined paradigm for integrating large models with traditional search systems, enabling end-to-end intelligent optimization across information aggregation and user interaction. Experimental results demonstrate that our approach improves the efficiency of implicit intent mining from large-scale search logs and significantly reduces the no-click rate.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "published": "2025-10-26T16:15:50+00:00",
      "updated": "2025-10-26T16:15:50+00:00",
      "pdf_url": "https://arxiv.org/pdf/2510.22739v1",
      "file": "papers/2510.22739v1.pdf"
    },
    {
      "arxiv_id": "2510.22733v2",
      "title": "E2Rank: Your Text Embedding can Also be an Effective and Efficient Listwise Reranker",
      "authors": [
        {
          "name": "Qi Liu"
        },
        {
          "name": "Yanzhao Zhang"
        },
        {
          "name": "Mingxin Li"
        },
        {
          "name": "Dingkun Long"
        },
        {
          "name": "Pengjun Xie"
        },
        {
          "name": "Jiaxin Mao"
        }
      ],
      "abstract": "Text embedding models serve as a fundamental component in real-world search applications. By mapping queries and documents into a shared embedding space, they deliver competitive retrieval performance with high efficiency. However, their ranking fidelity remains limited compared to dedicated rerankers, especially recent LLM-based listwise rerankers, which capture fine-grained query-document and document-document interactions. In this paper, we propose a simple yet effective unified framework E2Rank, means Efficient Embedding-based Ranking (also means Embedding-to-Rank), which extends a single text embedding model to perform both high-quality retrieval and listwise reranking through continued training under a listwise ranking objective, thereby achieving strong effectiveness with remarkable efficiency. By applying cosine similarity between the query and document embeddings as a unified ranking function, the listwise ranking prompt, which is constructed from the original query and its candidate documents, serves as an enhanced query enriched with signals from the top-K documents, akin to pseudo-relevance feedback (PRF) in traditional retrieval models. This design preserves the efficiency and representational quality of the base embedding model while significantly improving its reranking performance. Empirically, E2Rank achieves state-of-the-art results on the BEIR reranking benchmark and demonstrates competitive performance on the reasoning-intensive BRIGHT benchmark, with very low reranking latency. We also show that the ranking training process improves embedding performance on the MTEB benchmark. Our findings indicate that a single embedding model can effectively unify retrieval and reranking, offering both computational efficiency and competitive ranking accuracy.",
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "published": "2025-10-26T16:04:48+00:00",
      "updated": "2025-10-31T03:47:20+00:00",
      "pdf_url": "https://arxiv.org/pdf/2510.22733v2",
      "file": "papers/2510.22733v2.pdf"
    },
    {
      "arxiv_id": "2510.22694v1",
      "title": "Windsock is Dancing: Adaptive Multimodal Retrieval-Augmented Generation",
      "authors": [
        {
          "name": "Shu Zhao"
        },
        {
          "name": "Tianyi Shen"
        },
        {
          "name": "Nilesh Ahuja"
        },
        {
          "name": "Omesh Tickoo"
        },
        {
          "name": "Vijaykrishnan Narayanan"
        }
      ],
      "abstract": "Multimodal Retrieval-Augmented Generation (MRAG) has emerged as a promising method to generate factual and up-to-date responses of Multimodal Large Language Models (MLLMs) by incorporating non-parametric knowledge from external knowledge bases. However, existing MRAG approaches suffer from static retrieval strategies, inflexible modality selection, and suboptimal utilization of retrieved information, leading to three critical challenges: determining when to retrieve, what modality to incorporate, and how to utilize retrieved information effectively. To address these challenges, we introduce Windsock, a query-dependent module making decisions on retrieval necessity and modality selection, effectively reducing computational overhead and improving response quality. Additionally, we propose Dynamic Noise-Resistance (DANCE) Instruction Tuning, an adaptive training strategy that enhances MLLMs' ability to utilize retrieved information while maintaining robustness against noise. Moreover, we adopt a self-assessment approach leveraging knowledge within MLLMs to convert question-answering datasets to MRAG training datasets. Extensive experiments demonstrate that our proposed method significantly improves the generation quality by 17.07% while reducing 8.95% retrieval times.",
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.CL",
        "cs.IR"
      ],
      "published": "2025-10-26T14:36:16+00:00",
      "updated": "2025-10-26T14:36:16+00:00",
      "pdf_url": "https://arxiv.org/pdf/2510.22694v1",
      "file": "papers/2510.22694v1.pdf"
    },
    {
      "arxiv_id": "2510.22681v1",
      "title": "Diversification as Risk Minimization",
      "authors": [
        {
          "name": "Rikiya Takehi"
        },
        {
          "name": "Fernando Diaz"
        },
        {
          "name": "Tetsuya Sakai"
        }
      ],
      "abstract": "Users tend to remember failures of a search session more than its many successes. This observation has led to work on search robustness, where systems are penalized if they perform very poorly on some queries. However, this principle of robustness has been overlooked within a single query. An ambiguous or underspecified query (e.g., ``jaguar'') can have several user intents, where popular intents often dominate the ranking, leaving users with minority intents unsatisfied. Although the diversification literature has long recognized this issue, existing metrics only model the average relevance across intents and provide no robustness guarantees. More surprisingly, we show theoretically and empirically that many well-known diversification algorithms are no more robust than a naive, non-diversified algorithm. To address this critical gap, we propose to frame diversification as a risk-minimization problem. We introduce VRisk, which measures the expected risk faced by the least-served fraction of intents in a query. Optimizing VRisk produces a robust ranking, reducing the likelihood of poor user experiences. We then propose VRisker, a fast greedy re-ranker with provable approximation guarantees. Finally, experiments on NTCIR INTENT-2, TREC Web 2012, and MovieLens show the vulnerability of existing methods. VRisker reduces worst-case intent failures by up to 33% with a minimal 2% drop in average performance.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2025-10-26T13:51:45+00:00",
      "updated": "2025-10-26T13:51:45+00:00",
      "pdf_url": "https://arxiv.org/pdf/2510.22681v1",
      "file": "papers/2510.22681v1.pdf"
    },
    {
      "arxiv_id": "2510.22670v1",
      "title": "Tools are under-documented: Simple Document Expansion Boosts Tool Retrieval",
      "authors": [
        {
          "name": "Xuan Lu"
        },
        {
          "name": "Haohang Huang"
        },
        {
          "name": "Rui Meng"
        },
        {
          "name": "Yaohui Jin"
        },
        {
          "name": "Wenjun Zeng"
        },
        {
          "name": "Xiaoyu Shen"
        }
      ],
      "abstract": "Large Language Models (LLMs) have recently demonstrated strong capabilities in tool use, yet progress in tool retrieval remains hindered by incomplete and heterogeneous tool documentation. To address this challenge, we introduce Tool-DE, a new benchmark and framework that systematically enriches tool documentation with structured fields to enable more effective tool retrieval, together with two dedicated models, Tool-Embed and Tool-Rank. We design a scalable document expansion pipeline that leverages both open- and closed-source LLMs to generate, validate, and refine enriched tool profiles at low cost, producing large-scale corpora with 50k instances for embedding-based retrievers and 200k for rerankers. On top of this data, we develop two models specifically tailored for tool retrieval: Tool-Embed, a dense retriever, and Tool-Rank, an LLM-based reranker. Extensive experiments on ToolRet and Tool-DE demonstrate that document expansion substantially improves retrieval performance, with Tool-Embed and Tool-Rank achieving new state-of-the-art results on both benchmarks. We further analyze the contribution of individual fields to retrieval effectiveness, as well as the broader impact of document expansion on both training and evaluation. Overall, our findings highlight both the promise and limitations of LLM-driven document expansion, positioning Tool-DE, along with the proposed Tool-Embed and Tool-Rank, as a foundation for future research in tool retrieval.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2025-10-26T13:17:01+00:00",
      "updated": "2025-10-26T13:17:01+00:00",
      "pdf_url": "https://arxiv.org/pdf/2510.22670v1",
      "file": "papers/2510.22670v1.pdf"
    },
    {
      "arxiv_id": "2510.22344v1",
      "title": "FAIR-RAG: Faithful Adaptive Iterative Refinement for Retrieval-Augmented Generation",
      "authors": [
        {
          "name": "Mohammad Aghajani Asl"
        },
        {
          "name": "Majid Asgari-Bidhendi"
        },
        {
          "name": "Behrooz Minaei-Bidgoli"
        }
      ],
      "abstract": "While Retrieval-Augmented Generation (RAG) mitigates hallucination and knowledge staleness in Large Language Models (LLMs), existing frameworks often falter on complex, multi-hop queries that require synthesizing information from disparate sources. Current advanced RAG methods, employing iterative or adaptive strategies, lack a robust mechanism to systematically identify and fill evidence gaps, often propagating noise or failing to gather a comprehensive context. We introduce FAIR-RAG, a novel agentic framework that transforms the standard RAG pipeline into a dynamic, evidence-driven reasoning process. At its core is an Iterative Refinement Cycle governed by a module we term Structured Evidence Assessment (SEA). The SEA acts as an analytical gating mechanism: it deconstructs the initial query into a checklist of required findings and audits the aggregated evidence to identify confirmed facts and, critically, explicit informational gaps. These gaps provide a precise signal to an Adaptive Query Refinement agent, which generates new, targeted sub-queries to retrieve missing information. This cycle repeats until the evidence is verified as sufficient, ensuring a comprehensive context for a final, strictly faithful generation. We conducted experiments on challenging multi-hop QA benchmarks, including HotpotQA, 2WikiMultiHopQA, and MusiQue. In a unified experimental setup, FAIR-RAG significantly outperforms strong baselines. On HotpotQA, it achieves an F1-score of 0.453 -- an absolute improvement of 8.3 points over the strongest iterative baseline -- establishing a new state-of-the-art for this class of methods on these benchmarks. Our work demonstrates that a structured, evidence-driven refinement process with explicit gap analysis is crucial for unlocking reliable and accurate reasoning in advanced RAG systems for complex, knowledge-intensive tasks.",
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "published": "2025-10-25T15:59:33+00:00",
      "updated": "2025-10-25T15:59:33+00:00",
      "pdf_url": "https://arxiv.org/pdf/2510.22344v1",
      "file": "papers/2510.22344v1.pdf"
    },
    {
      "arxiv_id": "2510.22264v1",
      "title": "PatenTEB: A Comprehensive Benchmark and Model Family for Patent Text Embedding",
      "authors": [
        {
          "name": "Iliass Ayaou"
        },
        {
          "name": "Denis Cavallucci"
        }
      ],
      "abstract": "Patent text embeddings enable prior art search, technology landscaping, and patent analysis, yet existing benchmarks inadequately capture patent-specific challenges. We introduce PatenTEB, a comprehensive benchmark comprising 15 tasks across retrieval, classification, paraphrase, and clustering, with 2.06 million examples. PatenTEB employs domain-stratified splits, domain specific hard negative mining, and systematic coverage of asymmetric fragment-to-document matching scenarios absent from general embedding benchmarks. We develop the patembed model family through multi-task training, spanning 67M to 344M parameters with context lengths up to 4096 tokens. External validation shows strong generalization: patembed-base achieves state-of-the-art on MTEB BigPatentClustering.v2 (0.494 V-measure vs. 0.445 previous best), while patembed-large achieves 0.377 NDCG@100 on DAPFAM. Systematic ablations reveal that multi-task training improves external generalization despite minor benchmark costs, and that domain-pretrained initialization provides consistent advantages across task families. All resources will be made available at https://github.com/iliass-y/patenteb. Keywords: patent retrieval, sentence embeddings, multi-task learning, asymmetric retrieval, benchmark evaluation, contrastive learning.",
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "published": "2025-10-25T12:01:46+00:00",
      "updated": "2025-10-25T12:01:46+00:00",
      "pdf_url": "https://arxiv.org/pdf/2510.22264v1",
      "file": "papers/2510.22264v1.pdf"
    },
    {
      "arxiv_id": "2510.22242v1",
      "title": "PaperAsk: A Benchmark for Reliability Evaluation of LLMs in Paper Search and Reading",
      "authors": [
        {
          "name": "Yutao Wu"
        },
        {
          "name": "Xiao Liu"
        },
        {
          "name": "Yunhao Feng"
        },
        {
          "name": "Jiale Ding"
        },
        {
          "name": "Xingjun Ma"
        }
      ],
      "abstract": "Large Language Models (LLMs) increasingly serve as research assistants, yet their reliability in scholarly tasks remains under-evaluated. In this work, we introduce PaperAsk, a benchmark that systematically evaluates LLMs across four key research tasks: citation retrieval, content extraction, paper discovery, and claim verification. We evaluate GPT-4o, GPT-5, and Gemini-2.5-Flash under realistic usage conditions-via web interfaces where search operations are opaque to the user. Through controlled experiments, we find consistent reliability failures: citation retrieval fails in 48-98% of multi-reference queries, section-specific content extraction fails in 72-91% of cases, and topical paper discovery yields F1 scores below 0.32, missing over 60% of relevant literature. Further human analysis attributes these failures to the uncontrolled expansion of retrieved context and the tendency of LLMs to prioritize semantically relevant text over task instructions. Across basic tasks, the LLMs display distinct failure behaviors: ChatGPT often withholds responses rather than risk errors, whereas Gemini produces fluent but fabricated answers. To address these issues, we develop lightweight reliability classifiers trained on PaperAsk data to identify unreliable outputs. PaperAsk provides a reproducible and diagnostic framework for advancing the reliability evaluation of LLM-based scholarly assistance systems.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "published": "2025-10-25T10:11:29+00:00",
      "updated": "2025-10-25T10:11:29+00:00",
      "pdf_url": "https://arxiv.org/pdf/2510.22242v1",
      "file": "papers/2510.22242v1.pdf"
    },
    {
      "arxiv_id": "2510.22215v1",
      "title": "Hybrid-Vector Retrieval for Visually Rich Documents: Combining Single-Vector Efficiency and Multi-Vector Accuracy",
      "authors": [
        {
          "name": "Juyeon Kim"
        },
        {
          "name": "Geon Lee"
        },
        {
          "name": "Dongwon Choi"
        },
        {
          "name": "Taeuk Kim"
        },
        {
          "name": "Kijung Shin"
        }
      ],
      "abstract": "Retrieval over visually rich documents is essential for tasks such as legal discovery, scientific search, and enterprise knowledge management. Existing approaches fall into two paradigms: single-vector retrieval, which is efficient but coarse, and multi-vector retrieval, which is accurate but computationally expensive. To address this trade-off, we propose HEAVEN, a two-stage hybrid-vector framework. In the first stage, HEAVEN efficiently retrieves candidate pages using a single-vector method over Visually-Summarized Pages (VS-Pages), which assemble representative visual layouts from multiple pages. In the second stage, it reranks candidates with a multi-vector method while filtering query tokens by linguistic importance to reduce redundant computations. To evaluate retrieval systems under realistic conditions, we also introduce ViMDOC, the first benchmark for visually rich, multi-document, and long-document retrieval. Across four benchmarks, HEAVEN attains 99.87% of the Recall@1 performance of multi-vector models on average while reducing per-query computation by 99.82%, achieving efficiency and accuracy. Our code and datasets are available at: https://github.com/juyeonnn/HEAVEN",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.CV"
      ],
      "published": "2025-10-25T08:27:37+00:00",
      "updated": "2025-10-25T08:27:37+00:00",
      "pdf_url": "https://arxiv.org/pdf/2510.22215v1",
      "file": "papers/2510.22215v1.pdf"
    }
  ]
}